{"title":"Hadoop组件基础","uid":"e742771fc0750ee9de279875153316db","slug":"Hadoop组件基础","date":"2018-12-27T13:51:36.000Z","updated":"2022-08-22T08:37:18.230Z","comments":true,"path":"api/articles/Hadoop组件基础.json","keywords":null,"cover":"http://browser9.qhimg.com/bdm/480_296_0/t0105c03978f0adef4b.jpg","content":"<h1 id=\"Vi命令\"><a href=\"#Vi命令\" class=\"headerlink\" title=\"Vi命令\"></a>Vi命令</h1><p><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image1.png\">{width&#x3D;”6.809942038495188in”<br>height&#x3D;”4.260115923009624in”}</p>\n<h1 id=\"HDFS\"><a href=\"#HDFS\" class=\"headerlink\" title=\"HDFS\"></a>HDFS</h1><p><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image2.png\">{width&#x3D;”5.768055555555556in”<br>height&#x3D;”2.9347222222222222in”}</p>\n<p><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image3.png\">{width&#x3D;”5.768055555555556in”<br>height&#x3D;”2.886419510061242in”}</p>\n<p><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image4.png\">{width&#x3D;”5.768055555555556in”<br>height&#x3D;”2.8211089238845144in”}</p>\n<p><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image5.png\">{width&#x3D;”5.768055555555556in”<br>height&#x3D;”2.7393919510061244in”}</p>\n<h1 id=\"Hadoop\"><a href=\"#Hadoop\" class=\"headerlink\" title=\"Hadoop\"></a>Hadoop</h1><p><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image6.png\">{width&#x3D;”5.768055555555556in”<br>height&#x3D;”2.9402777777777778in”}</p>\n<p>图中涉及的技术名词解释如下：</p>\n<ol>\n<li>Sqoop：</li>\n</ol>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>sqoop是一款开源的工具，主要用于在Hadoop(Hive)与传统的数据库(mysql)间进行数据的传递，可以将一个关系型数据库（例如：MySQL<br>,Oracle<br>等）中的数据导进到Hadoop的HDFS中，也可以将HDFS的数据导进到关系型数据库中。</p></blockquote>\n<p>2）Flume：</p>\n<p>Flume是Cloudera提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，Flume支持在日志系统中定制各类数据发送方，用于收集数据；同时，Flume提供对数据进行简单处理，并写到各种数据接受方（可定制）的能力。</p>\n<p>3）Kafka：</p>\n<p>Kafka是一种高吞吐量的分布式发布订阅消息系统，有如下特性：</p>\n<p>（1）通过O(1)的磁盘数据结构提供消息的持久化，这种结构对于即使数以TB的消息存储也能够保持长时间的稳定性能。</p>\n<p>（2）高吞吐量：即使是非常普通的硬件Kafka也可以支持每秒数百万的消息</p>\n<p>（3）支持通过Kafka服务器和消费机集群来分区消息。</p>\n<p>（4）支持Hadoop并行数据加载。</p>\n<p>4）Storm：</p>\n<p>Storm为分布式实时计算提供了一组通用原语，可被用于”流处理”之中，实时处理消息并更新数据库。这是管理队列及工作者集群的另一种方式。Storm也可被用于”连续计算”（continuous<br>computation），对数据流做连续查询，在计算时就将结果以流的形式输出给用户。</p>\n<p>5）Spark：</p>\n<p>Spark是当前最流行的开源大数据内存计算框架。可以基于Hadoop上存储的大</p>\n<p>数据进行计算。</p>\n<p>6）Oozie：</p>\n<p>Oozie是一个管理Hdoop作业（job）的工作流程调度管理系统。Oozie协调作业就是通过时间（频率）和有效数据触发当前的Oozie工作流程。</p>\n<p>7）Hbase：</p>\n<p>HBase是一个分布式的、面向列的开源数据库。HBase不同于一般的关系数据库，它是一个适合于非结构化数据存储的数据库。</p>\n<p>8）Hive：</p>\n<p>hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的sql查询功能，可以将sql语句转换为MapReduce任务进行运行。其优点是学习成本低，可以通过类SQL语句快速实现简单的MapReduce统计，不必开发专门的MapReduce应用，十分适合数据仓库的统计分析。</p>\n<p>10）R语言：</p>\n<p>R是用于统计分析、绘图的语言和操作环境。R是属于GNU系统的一个自由、免费、源代码开放的软件，它是一个用于统计计算和统计制图的优秀工具。</p>\n<p>11）Mahout:</p>\n<p>Apache<br>Mahout是个可扩展的机器学习和数据挖掘库，当前Mahout支持主要的4个用例：</p>\n<p>推荐挖掘：搜集用户动作并以此给用户推荐可能喜欢的事物。</p>\n<p>聚集：收集文件并进行相关文件分组。</p>\n<p>分类：从现有的分类文档中学习，寻找文档中的相似特征，并为无标签的文档进行正确的归类。</p>\n<p>频繁项集挖掘：将一组项分组，并识别哪些个别项会经常一起出现。</p>\n<p>12）ZooKeeper：</p>\n<p>Zookeeper是Google的Chubby一个开源的实现。它是一个针对大型分布式系统的可靠协调系统，提供的功能包括：配置维护、名字服务、分布式同步、组服务等。ZooKeeper的目标就是封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。</p>\n<h2 id=\"MapReduce优缺点\"><a href=\"#MapReduce优缺点\" class=\"headerlink\" title=\"MapReduce优缺点\"></a>MapReduce优缺点</h2><p><strong>1.2.1</strong> 优点</p>\n<p><strong>1</strong>）<strong>MapReduce</strong>易于编程。它简单的实现一些接口，就可以完成一个分布式程序，这个分布式程序可以分布到大量廉价的PC机器上运行。也就是说你写一个分布式程序，跟写一个简单的串行程序是一模一样的。就是因为这个特点使得MapReduce编程变得非常流行。</p>\n<p><strong>2</strong>）良好的扩展性。当你的计算资源不能得到满足的时候，你可以通过简单的增加机器来扩展它的计算能力。</p>\n<p><strong>3</strong>）高容错性。MapReduce设计的初衷就是使程序能够部署在廉价的PC机器上，这就要求它具有很高的容错性。比如其中一台机器挂了，它可以把上面的计算任务转移到另外一个节点上运行，不至于这个任务运行失败，而且这个过程不需要人工参与，而完全是由Hadoop内部完成的。</p>\n<p><strong>4</strong>）适合<strong>PB</strong>级以上海量数据的离线处理。这里加红字体离线处理，说明它适合离线处理而不适合在线处理。比如像毫秒级别的返回一个结果，MapReduce很难做到。</p>\n<p><strong>1.2.2</strong> 缺点</p>\n<p><strong>MapReduce</strong>不擅长做实时计算、流式计算、<strong>DAG</strong>（有向图）计算。</p>\n<p><strong>1</strong>）实时计算。MapReduce无法像Mysql一样，在毫秒或者秒级内返回结果。</p>\n<p><strong>2</strong>）流式计算。流式计算的输入数据是动态的，而MapReduce的输入数据集是静态的，不能动态变化。这是因为MapReduce自身的设计特点决定了数据源必须是静态的。</p>\n<p><strong>3</strong>）<strong>DAG</strong>（有向图）计算。多个应用程序存在依赖关系，后一个应用程序的输入为前一个的输出。在这种情况下，MapReduce并不是不能做，而是使用后，每个MapReduce作业的输出结果都会写入到磁盘，会造成大量的磁盘IO，导致性能非常的低下。</p>\n<p><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image7.png\" alt=\"C:\\\\Users\\\\admin.Unis-164\\\\Desktop\\\\MapReduce.PNG\">{width&#x3D;”5.756944444444445in”<br>height&#x3D;”2.8784722222222223in”}</p>\n<h2 id=\"MapReduce开发总结\"><a href=\"#MapReduce开发总结\" class=\"headerlink\" title=\"MapReduce开发总结\"></a>MapReduce开发总结</h2><p>在编写mapreduce程序时，需要考虑的几个方面：</p>\n<p>1）输入数据接口：InputFormat</p>\n<p>默认使用的实现类是：TextInputFormat</p>\n<p>TextInputFormat的功能逻辑是：一次读一行文本，然后将该行的起始偏移量作为key，行内容作为value返回。</p>\n<p>KeyValueTextInputFormat每一行均为一条记录，被分隔符分割为key，value。默认分隔符是tab（\\t）。</p>\n<p>NlineInputFormat按照指定的行数N来划分切片。</p>\n<p>CombineTextInputFormat可以把多个小文件合并成一个切片处理，提高处理效率。</p>\n<p>用户还可以自定义InputFormat。</p>\n<p>2）逻辑处理接口：Mapper</p>\n<p>用户根据业务需求实现其中三个方法：map() setup() cleanup()</p>\n<p>3）Partitioner分区</p>\n<p>有默认实现HashPartitioner，逻辑是根据key的哈希值和numReduces来返回一个分区号；key.hashCode()&amp;Integer.MAXVALUE<br>% numReduces</p>\n<p>如果业务上有特别的需求，可以自定义分区。</p>\n<p>4）Comparable排序</p>\n<p>当我们用自定义的对象作为key来输出时，就必须要实现WritableComparable接口，重写其中的compareTo()方法。</p>\n<p>部分排序：对最终输出的每一个文件进行内部排序。</p>\n<p>全排序：对所有数据进行排序，通常只有一个Reduce。</p>\n<p>二次排序：排序的条件有两个。</p>\n<p>5）Combiner合并</p>\n<p>Combiner合并可以提高程序执行效率，减少io传输。但是使用时必须不能影响原有的业务处理结果。</p>\n<p>6）reduce端分组：Groupingcomparator</p>\n<p>reduceTask拿到输入数据（一个partition的所有数据）后，首先需要对数据进行分组，其分组的默认原则是key相同，然后对每一组kv数据调用一次reduce()方法，并且将这一组kv中的第一个kv的key作为参数传给reduce的key，将这一组数据的value的迭代器传给reduce()的values参数。</p>\n<p>利用上述这个机制，我们可以实现一个高效的分组取最大值的逻辑。</p>\n<p>自定义一个bean对象用来封装我们的数据，然后改写其compareTo方法产生倒序排序的效果。然后自定义一个Groupingcomparator，将bean对象的分组逻辑改成按照我们的业务分组id来分组（比如订单号）。这样，我们要取的最大值就是reduce()方法中传进来key。</p>\n<p>7）逻辑处理接口：Reducer</p>\n<p>用户根据业务需求实现其中三个方法：reduce() setup() cleanup()</p>\n<p>8）输出数据接口：OutputFormat</p>\n<p>默认实现类是TextOutputFormat，功能逻辑是：将每一个KV对向目标文本文件中输出为一行。</p>\n<p>SequenceFileOutputFormat将它的输出写为一个顺序文件。如果输出需要作为后续MapReduce任务的输入，这便是一种好的输出格式，因为它的格式紧凑，很容易被压缩。</p>\n<p>用户还可以自定义OutputFormat。</p>\n<h2 id=\"Hadoop数据压缩\"><a href=\"#Hadoop数据压缩\" class=\"headerlink\" title=\"Hadoop数据压缩\"></a>Hadoop数据压缩</h2><p>压缩<strong>Mapreduce</strong>的一种优化策略：通过压缩编码对<strong>Mapper</strong>或者<strong>Reducer</strong>的输出进行压缩，以减少磁盘<strong>IO</strong>，提高MR程序运行速度（但相应增加了cpu运算负担）。</p>\n<p>注意：压缩特性运用得当能提高性能，但运用不当也可能降低性能。</p>\n<p>基本原则：</p>\n<p>（1）运算密集型的job，少用压缩</p>\n<p>（2）IO密集型的job，多用压缩</p>\n<h2 id=\"Yarn\"><a href=\"#Yarn\" class=\"headerlink\" title=\"Yarn\"></a>Yarn</h2><p><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image8.png\">{width&#x3D;”6.264702537182852in”<br>height&#x3D;”2.9716983814523186in”}</p>\n<p><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image9.png\">{width&#x3D;”6.298482064741907in”<br>height&#x3D;”3.122700131233596in”}</p>\n<p><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image10.png\">{width&#x3D;”6.071529965004374in”<br>height&#x3D;”3.061349518810149in”}</p>\n<p><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image11.png\">{width&#x3D;”5.988567366579177in”<br>height&#x3D;”3.0490791776027995in”}</p>\n<h3 id=\"Scheduler\"><a href=\"#Scheduler\" class=\"headerlink\" title=\"Scheduler\"></a>Scheduler</h3><p><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image12.png\">{width&#x3D;”5.7545067804024495in”<br>height&#x3D;”2.6687160979877516in”}</p>\n<p><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image13.png\">{width&#x3D;”5.768055555555556in”<br>height&#x3D;”2.845833333333333in”}</p>\n<p><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image14.png\">{width&#x3D;”5.768055555555556in”<br>height&#x3D;”2.8555555555555556in”}</p>\n<h3 id=\"任务的推测执行\"><a href=\"#任务的推测执行\" class=\"headerlink\" title=\"任务的推测执行\"></a>任务的推测执行</h3><p>1）作业完成时间取决于最慢的任务完成时间</p>\n<p>一个作业由若干个Map任务和Reduce任务构成。因硬件老化、软件Bug等，某些任务可能运行非常慢。</p>\n<p>典型案例：系统中有99%的Map任务都完成了，只有少数几个Map老是进度很慢，完不成，怎么办？</p>\n<p>2）推测执行机制：</p>\n<p>发现拖后腿的任务，比如某个任务运行速度远慢于任务平均速度。为拖后腿任务启动一个备份任务，同时运行。谁先运行完，则采用谁的结果。</p>\n<p>3）执行推测任务的前提条件</p>\n<p>（1）每个task只能有一个备份任务；</p>\n<p>（2）当前job已完成的task必须不小于0.05（5%）</p>\n<p>（3）开启推测执行参数设置。Hadoop2.7.2<br>mapred-site.xml文件中默认是打开的。</p>\n<p>&lt;name&gt;mapreduce.map.speculative&lt;&#x2F;name&gt;</p>\n<p>&lt;value&gt;true&lt;&#x2F;value&gt;</p>\n<p>&lt;name&gt;mapreduce.reduce.speculative&lt;&#x2F;name&gt;</p>\n<p>&lt;value&gt;true&lt;&#x2F;value&gt;</p>\n<p>4）<strong>不能启用</strong>推测执行机制情况</p>\n<p>（1）任务间存在严重的负载倾斜；need调整MR！！！</p>\n<p>（2）特殊任务，比如任务向数据库中写数据。</p>\n<p>5）算法原理：</p>\n<p><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image15.png\">{width&#x3D;”5.768055555555556in”<br>height&#x3D;”2.8in”}</p>\n<h1 id=\"Hadoop-企业优化\"><a href=\"#Hadoop-企业优化\" class=\"headerlink\" title=\"Hadoop 企业优化 \"></a>Hadoop 企业优化 </h1><h2 id=\"6-1-MapReduce-跑的慢的原因\"><a href=\"#6-1-MapReduce-跑的慢的原因\" class=\"headerlink\" title=\"6.1 MapReduce 跑的慢的原因\"></a>6.1 MapReduce 跑的慢的原因</h2><p>Mapreduce 程序效率的瓶颈在于两点：</p>\n<p>1）计算机性能</p>\n<p>CPU、内存、磁盘健康、网络</p>\n<p>2）I&#x2F;O 操作优化</p>\n<p>（1）数据倾斜</p>\n<p>（2）map和reduce数设置不合理 (切片，diskIO速度256M&#x2F;s256M&#x2F;块；测试)</p>\n<p>（3）map运行时间太长，导致reduce等待过久<br>（run完的map可先进入reduce，慎用！）</p>\n<p>（4）小文件过多（IO慢）</p>\n<p>（5）大量的不可分块的超大文件（&gt;buffer80%，需要不断溢写）</p>\n<p>（6）spill次数过多</p>\n<p>（7）merge次数过多等。</p>\n<h2 id=\"6-2-MapReduce优化方法\"><a href=\"#6-2-MapReduce优化方法\" class=\"headerlink\" title=\"6.2 MapReduce优化方法\"></a>6.2 MapReduce优化方法</h2><p>MapReduce优化方法主要从六个方面考虑：数据输入、Map阶段、Reduce阶段、IO传输、数据倾斜问题和常用的调优参数。</p>\n<h3 id=\"6-2-1-数据输入\"><a href=\"#6-2-1-数据输入\" class=\"headerlink\" title=\"6.2.1 数据输入\"></a>6.2.1 数据输入</h3><p>（1）合并小文件：在执行mr任务前将小文件进行合并，大量的小文件会产生大量的map任务，增大map任务装载次数+耗尽namenode内存，而任务的装载比较耗时，从而导致mr运行较慢。</p>\n<p>（2）采用CombineTextInputFormat切片优化来作为输入，解决输入端大量小文件场景。</p>\n<h3 id=\"6-2-2-Map阶段\"><a href=\"#6-2-2-Map阶段\" class=\"headerlink\" title=\"6.2.2 Map阶段\"></a>6.2.2 Map阶段</h3><p><strong>1</strong>）减少溢写（<strong>spill</strong>）次数：通过调整io.sort.mb及sort.spill.percent参数值，增大触发spill的内存上限，减少spill次数，从而减少磁盘IO。</p>\n<p><strong>2</strong>）减少合并（<strong>merge</strong>）次数：通过调整io.sort.factor参数，增大merge的文件数目，减少merge的次数，从而缩短mr处理时间。</p>\n<p>3）在map之后，不影响业务逻辑前提下，先进行<strong>combine</strong>处理，减少I&#x2F;O。</p>\n<h3 id=\"6-2-3-Reduce阶段\"><a href=\"#6-2-3-Reduce阶段\" class=\"headerlink\" title=\"6.2.3 Reduce阶段\"></a>6.2.3 Reduce阶段</h3><p><strong>1</strong>）合理设置<strong>map</strong>和<strong>reduce</strong>数：两个都不能设置太少，也不能设置太多。太少，会导致task等待，延长处理时间；太多，会导致map、reduce任务间竞争资源，造成处理超时等错误。</p>\n<p><strong>2</strong>）设置<strong>map</strong>、<strong>reduce</strong>共存：调整slowstart.completedmaps参数，使map运行到一定程度后，reduce也开始运行，减少reduce的等待时间。</p>\n<p><strong>3</strong>）规避使用<strong>reduce</strong>：因为reduce在用于连接数据集的时候将会产生大量的网络消耗。</p>\n<p><strong>4</strong>）合理设置<strong>reduce</strong>端的<strong>buffer</strong>：默认情况下，数据达到一个阈值的时候，buffer中的数据就会写入磁盘，然后reduce会从磁盘中获得所有的数据。也就是说，buffer和reduce是没有直接关联的，中间多个一个写磁盘-&gt;读磁盘的过程，既然有这个弊端，那么就可以通过参数来配置，使得buffer中的一部分数据可以直接输送到reduce，从而减少IO开销：mapred.job.reduce.input.buffer.percent，默认为0.0。当值大于0的时候，会<strong>保留指定比例的内存读buffer中的数据直接拿给reduce使用</strong>（减少溢写）。这样一来，设置buffer<strong>需要内存</strong>，读取数据需要内存，reduce计算也要内存，所以要根据作业的运行情况进行调整。</p>\n<h3 id=\"6-2-4-IO传输\"><a href=\"#6-2-4-IO传输\" class=\"headerlink\" title=\"6.2.4 IO传输\"></a>6.2.4 IO传输</h3><p><strong>1</strong>）采用数据压缩的方式，减少网络IO的的时间。安装Snappy和LZO(index,格式splitable)压缩编码器。</p>\n<p><strong>2</strong>）使用<strong>SequenceFile</strong>二进制文件。(字节紧密，省校验)</p>\n<h3 id=\"6-2-5-数据倾斜问题\"><a href=\"#6-2-5-数据倾斜问题\" class=\"headerlink\" title=\"6.2.5 数据倾斜问题\"></a>6.2.5 数据倾斜问题</h3><p>1）数据倾斜现象</p>\n<p>数据频率倾斜——某一个区域的数据量要远远大于其他区域。</p>\n<p>数据大小倾斜——部分记录的大小远远大于平均值。</p>\n<p>2）如何收集倾斜数据</p>\n<p>+————————————————————–+<br>| 在reduce方法中加入记录map输出键的详细情况的功能。            |<br>|                                                              |<br>| public static final String MAX_VALUES &#x3D; &quot;skew.maxvalues&quot;; |<br>|                                                              |<br>| private int maxValueThreshold;                               |<br>|                                                              |<br>| @Override                                                   |<br>|                                                              |<br>| public void configure(JobConf job) {                         |<br>|                                                              |<br>| maxValueThreshold &#x3D; job.getInt(MAX_VALUES, 100);            |<br>|                                                              |<br>| }                                                            |<br>|                                                              |<br>| @Override                                                   |<br>|                                                              |<br>| public void reduce(Text key, Iterator&lt;Text&gt; values,        |<br>|                                                              |<br>| OutputCollector&lt;Text, Text&gt; output,                        |<br>|                                                              |<br>| Reporter reporter) throws IOException {                      |<br>|                                                              |<br>| int i &#x3D; 0;                                                   |<br>|                                                              |<br>| while (values.hasNext()) {                                   |<br>|                                                              |<br>| values.next();                                               |<br>|                                                              |<br>| i++;                                                         |<br>|                                                              |<br>| }                                                            |<br>|                                                              |<br>| if (++i &gt; maxValueThreshold) {                              |<br>|                                                              |<br>| log.info(&quot;Received &quot; + i + &quot; values for key &quot; + key);    |<br>|                                                              |<br>| }                                                            |<br>|                                                              |<br>| }                                                            |<br>+————————————————————–+<br>|                                                              |<br>+————————————————————–+</p>\n<p>3）减少数据倾斜的方法</p>\n<p><strong>方法1：抽样和范围分区</strong></p>\n<p>可以通过对原始数据进行<strong>抽样</strong>得到的结果集来预设分区边界值。</p>\n<p>方法<strong>2</strong>：<strong>自定义分区</strong></p>\n<p>基于输出键的背景知识进行自定义分区。例如，如果map输出键的单词来源于一本书，且其中某几个专业词汇较多。那么就可以自定义分区将这这些专业词汇发送给固定的一部分reduce实例。而将其他的都发送给剩余的reduce实例。</p>\n<p>方法<strong>3</strong>：<strong>Combine</strong></p>\n<p>使用Combine可以大量地减小数据倾斜。在可能的情况下，combine的目的就是聚合并精简数据。</p>\n<p>方法<strong>4</strong>：采用<strong>Map Join</strong>，尽量避免<strong>Reduce Join</strong>。</p>\n<h3 id=\"6-2-6-常用的调优参数\"><a href=\"#6-2-6-常用的调优参数\" class=\"headerlink\" title=\"6.2.6 常用的调优参数\"></a>6.2.6 常用的调优参数</h3><p>1）资源相关参数</p>\n<p>+———————————–+———————————–+<br>| （1）以下参数是在用户自己的mr应用程序中配置就可以生效（mapr | 参数说明 |<br>| ed-default.xml）配置参数          |                                   |<br>+———————————–+———————————–+<br>| mapreduce.map.memory.mb           | 一个Map                           |<br>|                                   | Task可使用的资源上限（单位:MB），默认为1024。如果Map |<br>|                                   |                                   |<br>|                                   | Task实际使用的资源量超过该值，则会被强制杀死。 |<br>+———————————–+———————————–+<br>| mapreduce.reduce.memory.mb        | 一个Reduce                        |<br>|                                   | Task可使用的资源上限（单位:MB），默认为1024。如果Red |<br>|                                   | uceTask实际使用的资源量超过该值，则会被强制杀死。 |<br>+———————————–+———————————–+<br>| mapreduce.map.cpu.vcores          | 每个Map task可使用的最多cpu       |<br>|                                   | core数目，默认值: 1               |<br>+———————————–+———————————–+<br>| mapreduce.reduce.cpu.vcores       | 每个Reduce task可使用的最多cpu    |<br>|                                   | core数目，默认值: 1               |<br>+———————————–+———————————–+<br>| mapreduce.reduce.shuffle.parallel | 每个reduce去map中拿数据的并行数。默认值是5 |<br>| copies                            |                                   |<br>+———————————–+———————————–+<br>| mapreduce.reduce.shuffle.merge.pe | buffer中的数据达到多少比例开始写入磁盘。默认值0.66 |<br>| rcent                             |                                   |<br>|                                   |                                   |<br>| 可提高                            |                                   |<br>+———————————–+———————————–+<br>| mapreduce.reduce.shuffle.input.bu | buffer大小占reduce可用内存的比例。默认值0.7 |<br>| ffer.percent                      |                                   |<br>+———————————–+———————————–+<br>| mapreduce.reduce.input.buffer.per | 指定多少比例的内存用来存放buffer中的数据，默认值是0.0 |<br>| cent                              |                                   |<br>+———————————–+———————————–+</p>\n<p>（2）应该在yarn启动之前就配置在服务器的配置文件中才能生效（yarn-default.xml）</p>\n<hr>\n<p>  配置参数                                     参数说明<br>  yarn.scheduler.minimum-allocation-mb1024     给应用程序container分配的最小内存<br>  yarn.scheduler.maximum-allocation-mb8192     给应用程序container分配的最大内存<br>  yarn.scheduler.minimum-allocation-vcores1    每个container申请的最小CPU核数<br>  yarn.scheduler.maximum-allocation-vcores32   每个container申请的最大CPU核数<br>  yarn.nodemanager.resource.memory-mb 8192     给containers分配的最大<strong>物理内存</strong></p>\n<hr>\n<p>（3）shuffle性能优化的关键参数，应在yarn启动之前就配置好（mapred-default.xml）</p>\n<hr>\n<p>  配置参数                               参数说明<br>  mapreduce.task.io.sort.mb 100          shuffle的环形缓冲区大小，默认100m<br>  mapreduce.map.sort.spill.percent 0.8   环形缓冲区溢出的阈值，默认80%</p>\n<hr>\n<p>2）容错相关参数(mapreduce性能优化)</p>\n<hr>\n<p>  配置参数                       参数说明<br>  mapreduce.map.maxattempts      每个Map Task最大重试次数，一旦重试参数超过该值，则认为Map Task运行失败，默认值：4。<br>  mapreduce.reduce.maxattempts   每个Reduce Task最大重试次数，一旦重试参数超过该值，则认为Reduce Task运行失败，默认值：4。<br>  <strong>mapreduce.task.timeout</strong>     Task超时时间，经常需要设置的一个参数，该参数表达的意思为：如果一个task在一定时间内没有任何进入，即不会读取新的数据，也没有输出数据，则认为该task处于<strong>block状态</strong>，可能是卡住了，也许永远会卡住，为了防止因为用户程序永远block住不退出，则强制设置了一个该超时时间（单位毫秒），默认是600000**(10分钟)<strong>。如果你的</strong>程序对每条输入数据的处理时间过长（比如会访问数据库，通过网络拉取数据等）**，建议将该参数调大，该参数过小常出现的错误提示是”AttemptID:attempt_14267829456721_123456_m_000224_0 Timed out after 300 secsContainer killed by the ApplicationMaster.”。</p>\n<hr>\n<h2 id=\"6-3-HDFS小文件优化方法\"><a href=\"#6-3-HDFS小文件优化方法\" class=\"headerlink\" title=\"6.3 HDFS小文件优化方法\"></a>6.3 HDFS小文件优化方法</h2><p><strong>6.3.1 HDFS</strong>小文件弊端</p>\n<p>HDFS上每个文件都要在namenode上建立一个索引，这个索引的大小约为150byte，这样当小文件比较多的时候，就会产生很多的索引文件，一方面会大量占用namenode的内存空间，另一方面就是索引文件过大使得索引速度变慢。</p>\n<h3 id=\"6-3-2-解决方案\"><a href=\"#6-3-2-解决方案\" class=\"headerlink\" title=\"6.3.2 解决方案\"></a>6.3.2 解决方案</h3><p>1）Hadoop Archive:</p>\n<p>是一个高效地将小文件放入HDFS块中的文件存档工具，它能够将多个小文件打包成一个HAR文件，这样就减少了namenode的内存使用。</p>\n<p>2）Sequence file：</p>\n<p>sequence<br>file由一系列的二进制key&#x2F;value组成，如果key为文件名，value为文件内容，则可以将大批小文件合并成一个大文件。</p>\n<p>3）CombineFileInputFormat：</p>\n<p>CombineFileInputFormat是一种新的inputformat，用于将多个文件合并成一个单独的split，另外，它会考虑数据的存储位置。</p>\n<p>4）开启JVM重用</p>\n<p>对于大量小文件Job，可以<strong>开启JVM重用</strong>会<strong>减少45%运行时间</strong>。</p>\n<p>JVM重用理解：一个map运行一个jvm，重用的话，一个map在jvm上运行完毕后，jvm继续运行其他map。</p>\n<p>具体设置：mapreduce.job.jvm.numtasks值在10-20之间。</p>\n<h1 id=\"Zookeeper\"><a href=\"#Zookeeper\" class=\"headerlink\" title=\"Zookeeper\"></a>Zookeeper</h1><p>Zookeeper是一个开源的分布式的，为分布式应用提供协调服务的Apache项目。</p>\n<p><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image16.png\">{width&#x3D;”5.768055555555556in”<br>height&#x3D;”3.040277777777778in”}</p>\n<p>Server写，Client读</p>\n<p>1）Zookeeper：一个领导者（leader），多个跟随者（follower）组成的集群。</p>\n<p>2）Leader负责进行投票的发起和决议，更新系统状态。</p>\n<p>3）Follower用于接收客户请求并向客户端返回结果，在选举Leader过程中参与投票。</p>\n<p>4）集群中只要有(奇数个)半数以上节点存活，Zookeeper集群就能正常服务。</p>\n<p>5）全局数据一致：每个server保存一份相同的数据副本，client无论连接到哪个server，数据都是一致的。</p>\n<p>6）更新请求顺序进行，来自同一个client的更新请求按其发送顺序依次执行。</p>\n<p>7）数据更新原子性，一次数据更新要么成功，要么失败。</p>\n<p>8）实时性，在一定时间范围内，client能读到最新数据。</p>\n<p>ZooKeeper数据模型的结构与Unix文件系统很类似，整体上可以看作是一棵树（stat结构体），每个节点称做一个ZNode。每一个ZNode默认能够存储1MB的数据，每个ZNode都可以通过其路径唯一标识。</p>\n<p>提供的服务包括：统一命名(域名)服务、统一配置管理(config<br>center)、统一集群管理(Register+watch)、服务器节点动态上下线、软负载均衡LB等。</p>\n<p>LB：1个域名，n个（IP）servers(选访问量min)</p>\n<h2 id=\"配置参数解读\"><a href=\"#配置参数解读\" class=\"headerlink\" title=\"配置参数解读\"></a>配置参数解读</h2><p>解读zoo.cfg文件中参数含义</p>\n<p>1）tickTime&#x3D;2000：通信心跳数，Zookeeper服务器心跳时间，单位毫秒 2s</p>\n<p>Zookeeper使用的基本时间，服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每个tickTime时间就会发送一个心跳，时间单位为毫秒。</p>\n<p>它用于心跳机制，并且设置最小的session超时时间为两倍心跳时间。(<strong>session的最小超</strong></p>\n<p><strong>时时间是2*tickTime</strong>)</p>\n<p>2）initLimit&#x3D;10：Leader和Follower初始通信时限 20s</p>\n<p>集群中的follower跟随者服务器与leader领导者服务器之间初始连接时能容忍的最多心跳数（tickTime的数量），用它来限定集群中的Zookeeper服务器连接到Leader的时限。</p>\n<p>投票选举新leader的初始化时间</p>\n<p>Follower在启动过程中，会从Leader同步所有最新数据，然后确定自己能够对外服务的起始状态。</p>\n<p>Leader允许Follower在initLimit时间内完成这个工作。</p>\n<p>3）syncLimit&#x3D;5：Leader和Follower同步通信时限 10s</p>\n<p>集群中Leader与Follower之间的最大响应时间单位，假如响应超过syncLimit *<br>tickTime，Leader认为Follower死掉，从服务器列表中删除Follower。</p>\n<p>在运行过程中，Leader负责与ZK集群中所有机器进行通信，例如通过一些心跳检测机制，来检测机器的存活状态。</p>\n<p>如果L发出心跳包在syncLimit之后，还没有从F那收到响应，那么就认为这个F已经不在线了。</p>\n<p>4）dataDir：数据文件目录+数据持久化路径</p>\n<p>保存内存数据库快照信息的位置，如果没有其他说明，更新的事务日志也保存到数据库。</p>\n<p><strong>5）</strong>clientPort&#x3D;[2181：]{.underline}客户端连接端口，监听客户端连接的端口</p>\n<h2 id=\"分布式安装部署\"><a href=\"#分布式安装部署\" class=\"headerlink\" title=\"分布式安装部署\"></a>分布式安装部署</h2><p>2）配置zoo.cfg文件</p>\n<p>（1）具体配置</p>\n<p>dataDir&#x3D;&#x2F;opt&#x2F;module&#x2F;zookeeper-3.4.10&#x2F;zkData</p>\n<p>增加如下配置</p>\n<p>#######################cluster##########################</p>\n<p>server.2&#x3D;hadoop102:2888:3888</p>\n<p>server.3&#x3D;hadoop103:2888:3888</p>\n<p>server.4&#x3D;hadoop104:2888:3888</p>\n<p>（2）配置参数解读</p>\n<p>Server.A&#x3D;B:C:D。</p>\n<p>A是一个数字，表示这个是第几号服务器；</p>\n<p>B是这个服务器的ip地址&#x2F;hostname；</p>\n<p>C是这个服务器与集群中的Leader服务器交换信息的端口；2888</p>\n<p>D是万一集群中的Leader服务器挂了，需要一个端口来重新进行选举，选出一个新的Leader，而这个端口就是用来执行选举时服务器相互通信的端口。3888</p>\n<p>集群模式下配置一个文件myid，这个文件在dataDir目录下，这个文件里面有一个数据就是A的值，[Zookeeper启动时读取此文件，拿到里面的数据与zoo.cfg里面的配置信息比较从而判断到底是哪个server。]{.underline}</p>\n<p>3）集群操作</p>\n<p>（1）在&#x2F;opt&#x2F;module&#x2F;zookeeper-3.4.10&#x2F;zkData目录下创建一个<strong>myid</strong>的文件</p>\n<p>touch myid</p>\n<p>添加myid文件，注意一定要在linux里面创建，在notepad++里面很可能乱码</p>\n<p>（2）编辑myid文件</p>\n<p>vi myid</p>\n<p>在文件中添加与server对应的编号：如2</p>\n<p>（3）拷贝配置好的zookeeper到其他机器上</p>\n<p>scp -r zookeeper-3.4.10&#x2F; root@hadoop103.atguigu.com:&#x2F;opt&#x2F;app&#x2F;</p>\n<p>scp -r zookeeper-3.4.10&#x2F; root@hadoop104.atguigu.com:&#x2F;opt&#x2F;app&#x2F;</p>\n<p>并分别修改myid文件中内容为3、4</p>\n<p>（4）分别启动zookeeper</p>\n<p>（5）查看状态</p>\n<p>[root@hadoop102 zookeeper-3.4.10]# bin&#x2F;zkServer.sh status</p>\n<p>Follower&#x2F;leader</p>\n<h2 id=\"Zookeeper内部原理\"><a href=\"#Zookeeper内部原理\" class=\"headerlink\" title=\"Zookeeper内部原理 \"></a>Zookeeper内部原理 </h2><h2 id=\"3-1-选举机制\"><a href=\"#3-1-选举机制\" class=\"headerlink\" title=\"3.1 选举机制\"></a>3.1 选举机制</h2><p>1）半数机制（Paxos<br>协议）：集群中半数以上机器存活，集群可用。所以zookeeper适合装在奇数台机器上。</p>\n<p>2）Zookeeper虽然在配置文件中并没有指定master和slave。但是，zookeeper工作时，是有一个节点为leader，其他则为follower，Leader是通过内部的选举机制临时产生的。</p>\n<p>3）以一个简单的例子来说明整个选举的过程。</p>\n<p>假设有五台服务器组成的zookeeper集群，它们的id从1-5，同时它们都是最新启动的，也就是没有历史数据，在存放数据量这一点上，都是一样的。假设这些服务器依序启动，来看看会发生什么。</p>\n<p>（1）服务器1启动，此时只有它一台服务器启动了，它发出去的报<strong>投自己</strong>没有任何响应，所以它的选举状态一直是LOOKING状态。</p>\n<p>（2）服务器2启动，它与最开始启动的服务器1进行通信，互相交换自己的选举结果，由于两者都没有历史数据，所以**[id值较大的服务器2胜出]{.underline}<strong>，但是由于没有达到</strong>超过半数以上<strong>的服务器都</strong>同意选举**它(这个例子中的半数以上是3)，所以服务器1、2还是继续保持LOOKING状态。</p>\n<p>（3）服务器3启动，根据前面的理论分析，服务器[3成为服务器1、2、3中的老大]{.underline}，而与上面不同的是，此时[有三台服务器选举了它]{.underline}，所以它成为了这次选举的leader。</p>\n<p>（4）服务器4启动，根据前面的分析，理论上服务器4应该是服务器1、2、3、4中最大的，但是由于前面已经有半数以上的服务器选举了服务器3，所以它只能接收当小弟的命了。</p>\n<p>（5）服务器5启动，同4一样当小弟。</p>\n<h2 id=\"3-2-节点类型\"><a href=\"#3-2-节点类型\" class=\"headerlink\" title=\"3.2 节点类型\"></a>3.2 节点类型</h2><p>1）Znode有两种类型：</p>\n<p>短暂（ephemeral）：客户端和服务器端断开连接后，创建的节点自己删除</p>\n<p>持久（persistent）：客户端和服务器端断开连接后，创建的节点不删除</p>\n<p>2）Znode有四种形式的目录节点（默认是persistent ）</p>\n<p>（1）持久化目录节点（PERSISTENT）</p>\n<p>客户端与zookeeper断开连接后，该节点依旧存在。</p>\n<p>（2）持久化顺序编号目录节点（PERSISTENT_SEQUENTIAL）</p>\n<p>客户端与zookeeper断开连接后，该节点依旧存在，只是Zookeeper给该节点名称进行顺序编号（不重复）。</p>\n<p>（3）临时目录节点（EPHEMERAL）</p>\n<p>客户端与zookeeper断开连接后，该节点被删除。动态上下线</p>\n<p>（4）临时顺序编号目录节点（<strong>EPHEMERAL_SEQUENTIAL</strong>）<strong>多用，实现znode动态上下线！</strong></p>\n<p>客户端与zookeeper断开连接后，该节点被删除，只是Zookeeper给该节点名称进行顺序编号。</p>\n<p>3）创建znode时设置顺序标识，znode名称后会附加一个值，<strong>顺序号</strong>是一个单调递增的计数器，由父节点维护</p>\n<p>4）在分布式系统中，顺序号可以被用于为<strong>所有的事件进行全局排序</strong>，这样[客户端可以通过顺序号推断事件的顺序]{.underline}</p>\n<p><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image17.png\">{width&#x3D;”6.912146762904637in”<br>height&#x3D;”3.254717847769029in”}</p>\n<p><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image18.png\">{width&#x3D;”6.983436132983377in”<br>height&#x3D;”3.3301891951006124in”}</p>\n<h1 id=\"Hive\"><a href=\"#Hive\" class=\"headerlink\" title=\"Hive\"></a>Hive</h1><h2 id=\"一-Hive-基本概念\"><a href=\"#一-Hive-基本概念\" class=\"headerlink\" title=\"一 Hive 基本概念\"></a><strong>一</strong> Hive <strong>基本概念</strong></h2><h3 id=\"1-1-什么是-Hive\"><a href=\"#1-1-什么是-Hive\" class=\"headerlink\" title=\"1.1 什么是 Hive\"></a>1.1 <strong>什么是</strong> Hive</h3><p>Hive：由 Facebook 开源用于解决海量结构化日志的数据统计。</p>\n<p>Hive 是基于 Hadoop<br>的一个数据仓库DW工具，可以将结构化的数据文件映射为一张表，并</p>\n<p>提供类 SQL 查询功能。</p>\n<p>本质是：将 HQL 转化成 MapReduce 程序</p>\n<p>1）Hive 处理的数据存储在 HDFS</p>\n<p>2）Hive 分析数据底层的实现是 MapReduce</p>\n<p>3）执行程序运行在 Yarn 上</p>\n<h3 id=\"1-2-Hive-的优缺点\"><a href=\"#1-2-Hive-的优缺点\" class=\"headerlink\" title=\"1.2 Hive 的优缺点\"></a>1.2 Hive <strong>的优缺点</strong></h3><p>1.2.1 <strong>优点</strong></p>\n<p>1）操作接口采用类 SQL 语法，提供快速开发的能力（简单、容易上手）</p>\n<p>2）避免了去写 MapReduce，减少开发人员的学习成本。</p>\n<p>3）Hive 的执行延迟比较高，因此 Hive<br>常用于数据分析，对实时性要求不高的场合；</p>\n<p>4）Hive 优势在于处理大数据，对于处理小数据没有优势，因为 Hive<br>的执行延迟比较高。<strong>场景：凌晨日活、月活、回流，分析后给mysql</strong></p>\n<p>5）Hive 支持用户自定义函数，用户可以根据自己的需求来实现自己的函数。</p>\n<p>1.2.2 <strong>缺点</strong></p>\n<p>1）Hive 的 HQL 表达能力有限</p>\n<p>（1）迭代式算法无法表达</p>\n<p>（2）数据挖掘方面不擅长</p>\n<p>2）Hive 的效率比较低</p>\n<p>（1）Hive 自动生成的 MapReduce 作业，通常情况下不够智能化</p>\n<p>（2）Hive 调优比较困难，粒度较粗</p>\n<h3 id=\"1-3-Hive-架构原理\"><a href=\"#1-3-Hive-架构原理\" class=\"headerlink\" title=\"1.3 Hive 架构原理\"></a>1.3 Hive <strong>架构原理</strong></h3><p>Hive 架构</p>\n<p><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image19.png\">{width&#x3D;”3.6904636920384952in”<br>height&#x3D;”3.2835826771653545in”}</p>\n<p>如图中所示，Hive<br>通过给用户提供的一系列交互接口，接收到用户的指令(SQL)，使用自己的<br>Driver，结合元数据(MetaStore)，将这些指令翻译成 MapReduce，提交到 Hadoop<br>中</p>\n<p>执行，最后，将执行返回的结果输出到用户交互接口。</p>\n<p>1）用户接口：Client</p>\n<p>CLI（hive shell）、JDBC&#x2F;ODBC(java 访问 hive)、WEBUI（浏览器访问 hive）</p>\n<p>2）元数据：Metastore</p>\n<p>元数据包括：表名、表所属的数据库（默认是<br>default）、表的拥有者、列&#x2F;分区字段、表的类型（是否是外部表）、表的数据所在目录等；</p>\n<p>默认存储在自带的 derby 数据库中，推荐使用 MySQL 存储 Metastore</p>\n<p>3）Hadoop</p>\n<p>使用 HDFS 进行存储，使用 MapReduce 进行计算。</p>\n<p>4）驱动器：Driver</p>\n<p>（1）解析器（SQL Parser）：将 SQL 字符串转换成抽象语法树<br>AST，这一步一般都用第三方工具库完成，比如 antlr；对 AST<br>进行语法分析，比如表是否存在、字段是否存在、SQL 语义是否有误。</p>\n<p>（2）编译器（Physical Plan）：将 AST 编译生成逻辑执行计划。</p>\n<p>（3）优化器（Query Optimizer）：对逻辑执行计划进行优化。</p>\n<p>（4）执行器（Execution）：把逻辑执行计划转换成可以运行的物理计划。对于<br>Hive 来说，就是 MR&#x2F;Spark。</p>\n<h3 id=\"1-4-Hive-和数据库比较\"><a href=\"#1-4-Hive-和数据库比较\" class=\"headerlink\" title=\"1.4 Hive 和数据库比较\"></a>1.4 Hive <strong>和数据库比较</strong></h3><p>由于 Hive 采用了类似 SQL 的查询语言 HQL(Hive Query Language)<br>，因此很容易将 Hive 理解为数据库。其实从结构上来看，Hive<br>和数据库除了拥有类似的查询语言，再无类似之处。本文将从多个方面来阐述<br>Hive 和数据库的差异。数据库可以用在 Online 的应用中，但是 Hive<br>是为数据仓库而设计的，清楚这一点，有助于从应用角度理解 Hive 的特性。</p>\n<p>1.4.1 <strong>查询语言</strong></p>\n<p>由于 SQL 被广泛的应用在数据仓库中，因此，专门针对 Hive 的特性设计了类<br>SQL 的</p>\n<p>查询语言 HQL。熟悉 SQL 开发的开发者可以很方便的使用 Hive 进行开发。</p>\n<p>1.4.2 <strong>数据存储位置</strong></p>\n<p>Hive 是建立在 Hadoop 之上的，所有 Hive 的数据都是存储在 HDFS<br>中的。而数据库则可以将数据保存在块设备或者本地文件系统中。</p>\n<p>1.4.3 <strong>数据更新</strong></p>\n<p>由于 Hive<br>是针对数据仓库应用设计的，而数据仓库的内容是读多写少的。因此，Hive中不支持对数据的改写和添加，所有的数据都是在加载的时候确定好的。而数据库中的数据通常是需要经常进行修改的，因此可以使用<br>INSERT INTO … VALUES 添加数据，使用 UPDATE … SET 修改数据。</p>\n<p>1.4.4 <strong>索引</strong></p>\n<p>Hive<br>在加载数据的过程中不会对数据进行任何处理，甚至不会对数据进行扫描，因此也没有对数据中的某些<br>Key 建立索引。Hive<br>要访问数据中满足条件的特定值时，需要暴力扫描整个数据，因此访问延迟较高。由于<br>MapReduce 的引入， Hive<br>可以并行访问数据，因此即使没有索引，<a href=\"http://lib.csdn.net/base/hadoop\">[对于大数据量]{.underline}</a>的访问，Hive<br>仍然可以体现出优势。数据库中，通常会针对一个或者几个列建立索引，因此对于少量的特定条件的数据的访问，数据库可以有很高的效率，较低的延迟。由于数据的访问延迟较高，决定了<br>Hive 不适合在线数据查询。</p>\n<p>1.4.5 <strong>执行</strong></p>\n<p>Hive 中大多数查询的执行是通过 Hadoop 提供的 MapReduce<br>来实现的。而数据库通常有自己的执行引擎。</p>\n<p>1.4.6 <strong>执行延迟</strong></p>\n<p>Hive<br>在查询数据的时候，由于没有索引，需要扫描整个表，因此延迟较高。另外一个导致<br>Hive 执行延迟高的因素是 MapReduce 框架。由于 MapReduce<br>本身具有较高的延迟，因此在利用 MapReduce 执行 Hive<br>查询时，也会有较高的延迟。相对的，数据库的执行延迟较低。当然，这个低是有条件的，即数据规模较小，当数据规模大到超过数据库的处理能力的时候，Hive<br>的并行计算显然能体现出优势。</p>\n<p>1.4.7 <strong>可扩展性</strong></p>\n<p>由于 Hive 是建立在 Hadoop 之上的，因此 Hive 的可扩展性是和 Hadoop<br>的可扩展性是一致的（世界上最大的 Hadoop 集群在 Yahoo!，2009 年的规模在<br>4000 台节点左右）。而数据库由于 ACID<br>语义的严格限制，扩展行非常有限。目前最先进的并行数据库<br><a href=\"http://lib.csdn.net/base/oracle\">[Oracle]{.underline}</a><br>在理论上的扩展能力也只有 100 台左右。</p>\n<p>1.4.8 <strong>数据规模</strong></p>\n<p>由于 Hive 建立在集群上并可以利用 MapReduce<br>进行并行计算，因此可以支持很大规模的数据；对应的，数据库可以支持的数据规模较小。</p>\n<p>适合处理大量数据：凌晨日活、月活、回流，分析后给mysql</p>\n<h2 id=\"6-5-排序\"><a href=\"#6-5-排序\" class=\"headerlink\" title=\"6.5 排序 \"></a>6.5 <strong>排序</strong> </h2><h3 id=\"6-5-1-全局排序（Order-By）\"><a href=\"#6-5-1-全局排序（Order-By）\" class=\"headerlink\" title=\"6.5.1 全局排序（Order By）\"></a>6.5.1 <strong>全局排序（</strong>Order By<strong>）</strong></h3><p>Order By：全局排序，一个 MapReduce</p>\n<p>1）使用 ORDER BY 子句排序</p>\n<p>ASC（ascend）: 升序（默认）</p>\n<p>DESC（descend）: 降序</p>\n<p>2）ORDER BY 子句在 SELECT 语句的结尾。</p>\n<p>3）案例实操</p>\n<p>（1）查询员工信息按工资升序排列</p>\n<p>hive (default)&gt; select * from emp order by sal;</p>\n<p>（2）查询员工信息按工资降序排列</p>\n<p>hive (default)&gt; select * from emp order by sal desc;</p>\n<h3 id=\"6-5-4-每个-MapReduce-内部排序（Sort-By）\"><a href=\"#6-5-4-每个-MapReduce-内部排序（Sort-By）\" class=\"headerlink\" title=\"6.5.4 每个 MapReduce 内部排序（Sort By）\"></a>6.5.4 <strong>每个</strong> MapReduce <strong>内部排序（</strong>Sort By<strong>）</strong></h3><p>Sort By：每个 MapReduce 内部进行排序，对全局结果集来说不是排序。</p>\n<p>1）设置 reduce 个数</p>\n<p>hive (default)&gt; set mapreduce.job.reduces&#x3D;3;</p>\n<p>2）查看设置 reduce 个数</p>\n<p>hive (default)&gt; set mapreduce.job.reduces;</p>\n<p>3）根据部门编号降序查看员工信息</p>\n<p>hive (default)&gt; select * from emp sort by deptno desc;</p>\n<p>4）将查询结果导入到文件中（按照部门编号降序排序）</p>\n<p>hive (default)&gt; insert overwrite local directory<br>&#39;&#x2F;opt&#x2F;module&#x2F;datas&#x2F;sortby-result&#39; select * from emp sort by deptno<br>desc;</p>\n<h3 id=\"6-5-5-分区排序（Distribute-By…sort-by…）\"><a href=\"#6-5-5-分区排序（Distribute-By…sort-by…）\" class=\"headerlink\" title=\"6.5.5 分区排序（Distribute By…sort by…）\"></a>6.5.5 <strong>分区排序（</strong>Distribute By…sort by…<strong>）</strong></h3><p>Distribute By：类似 MR 中 partition，进行分区，结合 sort by 使用。</p>\n<p>注意，Hive 要求 DISTRIBUTE BY 语句要写在 SORT BY 语句之前。</p>\n<p>对于 distribute by 进行测试，一定要分配多 reduce 进行处理，否则无法看到<br>distribute by的效果。</p>\n<p>案例实操：</p>\n<p>（1）先按照部门编号分区，再按照员工编号降序排序。<br><strong>相当于自定义partitioner!!!!!</strong></p>\n<p>hive (default)&gt; set mapreduce.job.reduces&#x3D;3;</p>\n<p>hive (default)&gt; insert overwrite local directory<br>&#39;&#x2F;opt&#x2F;module&#x2F;datas&#x2F;distribute-result&#39; select * from emp distribute by<br>deptno sort by empno desc;</p>\n<h3 id=\"6-5-6-Cluster-By\"><a href=\"#6-5-6-Cluster-By\" class=\"headerlink\" title=\"6.5.6 Cluster By\"></a>6.5.6 Cluster By</h3><p>当 [distribute by 和 sorts by 字段相同]{.underline}时，可以使用 cluster<br>by 方式。</p>\n<p>cluster by 除了具有 distribute by 的功能外还兼具 sort by<br>的功能。但是排序<strong>只能是倒序排序</strong>，不能指定排序规则为 ASC 或者 DESC。</p>\n<p>1）以下两种写法等价</p>\n<p>select * from emp cluster by deptno;</p>\n<p>select * from emp distribute by <strong>deptno</strong> sort by <strong>deptno</strong>;</p>\n<p>注意：按照部门编号分区，不一定就是固定死的数值，可以是 20 号和 30<br>号部门分到一</p>\n<p>个分区里面去。</p>\n<h2 id=\"6-6-分桶及抽样查询\"><a href=\"#6-6-分桶及抽样查询\" class=\"headerlink\" title=\"6.6 分桶及抽样查询 \"></a><strong>6.6</strong> 分桶及抽样查询 </h2><h3 id=\"6-6-1-分桶表数据存储\"><a href=\"#6-6-1-分桶表数据存储\" class=\"headerlink\" title=\"6.6.1 分桶表数据存储\"></a><strong>6.6.1</strong> 分桶表数据存储</h3><p>partition分区针对的是数据的存储路径；分桶针对的是数据文件。</p>\n<p>分区提供一个隔离数据和优化查询的便利方式。不过，并非所有的数据集都可形成合理</p>\n<p>的分区，特别是之前所提到过的要确定合适的划分大小这个疑虑。</p>\n<p>分桶是将数据集分解成更容易管理的若干部分的另一个技术。</p>\n<p>1）先创建分桶表，通过直接导入数据文件的方式</p>\n<p>（0）数据准备</p>\n<p>student.txt</p>\n<p>（1）创建分桶表</p>\n<p>create table stu_buck(id int, name string)</p>\n<p>clustered by(id)</p>\n<p>into 4 buckets</p>\n<p>row format delimited fields terminated by &#39;\\t&#39;;</p>\n<p>（2）查看表结构</p>\n<p>hive (default)&gt; desc formatted stu_buck;</p>\n<p><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image20.png\">{width&#x3D;”5.388888888888889in”<br>height&#x3D;”1.0555555555555556in”}<img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image21.png\">{width&#x3D;”5.305555555555555in”<br>height&#x3D;”0.7222222222222222in”}</p>\n<p>Num Buckets: 4</p>\n<p>（3）导入数据到分桶表中</p>\n<p>hive (default)&gt; load data local inpath<br>&#39;&#x2F;opt&#x2F;module&#x2F;datas&#x2F;student.txt&#39; into table stu_buck;</p>\n<p>（4）查看创建的分桶表中是否分成 4 个桶</p>\n<p>发现并没有分成 4 个桶。是什么原因呢？</p>\n<p>2）创建分桶表时，数据通过子查询的方式导入</p>\n<p>（1）先建一个普通的 stu 表</p>\n<p>create table stu(id int, name string)</p>\n<p>row format delimited fields terminated by &#39;\\t&#39;;</p>\n<p>（2）向普通的 stu 表中导入数据</p>\n<p>load data local inpath &#39;&#x2F;opt&#x2F;module&#x2F;datas&#x2F;student.txt&#39; into table stu;</p>\n<p>（3）清空 stu_buck 表中数据</p>\n<p>truncate table stu_buck;</p>\n<p>select * from stu_buck;</p>\n<p>（4）导入数据到分桶表，通过子查询的方式</p>\n<p>insert into table stu_buck</p>\n<p>select id, name from stu cluster by(id);</p>\n<p>（5）发现还是只有一个分桶</p>\n<p>（6）需要设置一个属性</p>\n<p>hive (default)&gt;set hive.enforce.bucketing&#x3D;true;</p>\n<p>hive (default)&gt; set mapreduce.job.reduces&#x3D;-1;</p>\n<p>hive (default)&gt;insert into table stu_buck</p>\n<p><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image22.png\">{width&#x3D;”5.291666666666667in”<br>height&#x3D;”1.6388888888888888in”}select id, name from stu cluster by(id);</p>\n<p>dept_partition分区表分folders（&#x2F;month&#x3D;201707&#x2F;），stu_buck:分数据文件0000002_0.txt……</p>\n<p>（7）查询分桶的数据</p>\n<p>hive (default)&gt; select * from stu_buck;</p>\n<p>OK</p>\n<p>stu_buck.id stu_buck.name</p>\n<p>1001 ss1</p>\n<p>1005 ss5</p>\n<p>1009 ss9</p>\n<p>1012 ss12</p>\n<p>1016 ss16</p>\n<p>1002 ss2</p>\n<p>1006 ss6</p>\n<p>1013 ss13</p>\n<p>1003 ss3</p>\n<p>1007 ss7</p>\n<p>1010 ss10</p>\n<p>1014 ss14</p>\n<p>1004 ss4</p>\n<p>1008 ss8</p>\n<p>1011 ss11</p>\n<p>1015 ss15</p>\n<h3 id=\"6-6-2-分桶抽样查询\"><a href=\"#6-6-2-分桶抽样查询\" class=\"headerlink\" title=\"6.6.2 分桶抽样查询\"></a>6.6.2 <strong>分桶抽样查询</strong></h3><p><strong>不可分割的大数据集，有null&#x2F;脏数据</strong></p>\n<p>对于非常大的数据集，有时用户需要使用的是一个具有代表性的查询结果而不是全部结</p>\n<p>果。Hive 可以通过对表进行抽样来满足这个需求。</p>\n<p>查询表 stu_buck 中的数据。</p>\n<p>hive (default)&gt; select * from stu_buck tablesample(bucket 1 out of 4<br>on id);</p>\n<p>注：tablesample 是抽样语句，语法：TABLESAMPLE(BUCKET x OUT OF y) 。</p>\n<p>y 必须是 table 总 bucket 数的<strong>倍数或者因子</strong>。hive 根据 y<br>的大小，决定抽样的比例。例如，table 总共分了 4 份，当 y&#x3D;2<br>时，抽取(4&#x2F;2&#x3D;)2 个 bucket 的数据，当 y&#x3D;8 时，[抽取(**4&#x2F;**8&#x3D;)1&#x2F;2个<br>bucket]{.underline} 的数据。</p>\n<p>x 表示[<strong>从</strong>哪个 bucket <strong>开始</strong>]{.underline}抽取。例如，table 总<br>bucket 数为 4，tablesample(bucket 4 out of 4)，表示总共抽取（4&#x2F;4&#x3D;）1 个<br>bucket 的数据，抽取第 4 个 bucket 的数据。 注意：x 的值必须小于等于 y<br>的值，否则</p>\n<p>FAILED: SemanticException [Error 10061]: Numerator should not be<br>bigger than</p>\n<p>denominator in sample clause for table stu_buck</p>\n<h3 id=\"6-6-3-数据块抽样\"><a href=\"#6-6-3-数据块抽样\" class=\"headerlink\" title=\"6.6.3 数据块抽样\"></a>6.6.3 <strong>数据块抽样</strong></h3><p>Hive<br>提供了另外一种按照百分比进行抽样的方式，这种是基于行数的，按照输入路径</p>\n<p>下的数据块百分比进行的抽样。</p>\n<p>hive (default)&gt; select * from stu tablesample(0.1 percent) ;<br>128M的0.1%</p>\n<p>提示：这种抽样方式不一定适用于所有的文件格式。另外，这种抽样的<strong>最小抽样单元是</strong></p>\n<p><strong>一个 HDFS 数据块128M</strong>。因此，如果表的数据大小小于普通的块大小 128M<br>的话，那么将会返回所有行。</p>\n<h2 id=\"8-5-文件存储格式\"><a href=\"#8-5-文件存储格式\" class=\"headerlink\" title=\"8.5 文件存储格式 \"></a><strong>8.5</strong> 文件存储格式 </h2><p>Hive 支持的存储数的格式主要有：TEXTFILE 、SEQUENCEFILE、ORC、PARQUET。</p>\n<p>stored as …</p>\n<h3 id=\"width-x3D-”7-146527777777778in”-height-x3D-”2-6375in”-8-5-1-列式存储和行式存储\"><a href=\"#width-x3D-”7-146527777777778in”-height-x3D-”2-6375in”-8-5-1-列式存储和行式存储\" class=\"headerlink\" title=\"{width&#x3D;”7.146527777777778in” height&#x3D;”2.6375in”}8.5.1 列式存储和行式存储\"></a><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image23.jpeg\">{width&#x3D;”7.146527777777778in” height&#x3D;”2.6375in”}<strong>8.5.1</strong> 列式存储和行式存储</h3><p>上图左边为逻辑表，右边第一个为行式存储，第二个为列式存储。</p>\n<p>行存储的特点：<br>查询满足条件的<strong>一整行</strong>数据的时候，列存储则需要去每个聚集的字段找到对应的每个列的值，行存储只需要找到其中一个值，其余的值都在相邻地方，所以此时行存储查询的速度更快。</p>\n<p>列存储的特点：<br>因为每个字段的数据聚集存储，在查询只需要少数几个字段的时候，能大大减少读取的数据量；<strong>每个字段的数据类型一定是相同的</strong>，列式存储可以**针对性的设计更好的设计压缩算法。<br>**</p>\n<p>**TEXTFILE 和 SEQUENCEFILE 的存储格式都是基于行存储的； **</p>\n<p>**ORC 和 PARQUET 是基于列式存储的。 **</p>\n<h3 id=\"8-5-2-TextFile-格式\"><a href=\"#8-5-2-TextFile-格式\" class=\"headerlink\" title=\"8.5.2 TextFile 格式\"></a>8.5.2 TextFile <strong>格式</strong></h3><p>默认格式，数据[不做压缩，磁盘开销大，数据解析开销大]{.underline}。可结合<br>Gzip、Bzip2 使用(系</p>\n<p>统自动检查，执行查询时自动解压)，但使用这种方式，hive<br>不会对数据进行切分，从而无法对数据进行并行操作。</p>\n<h3 id=\"8-5-3-Orc-格式\"><a href=\"#8-5-3-Orc-格式\" class=\"headerlink\" title=\"8.5.3 Orc 格式\"></a>8.5.3 Orc <strong>格式</strong></h3><p>Orc (Optimized Row Columnar)是 hive 0.11 版里引入的新的存储格式。</p>\n<p><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image24.png\">{width&#x3D;”4.125in”<br>height&#x3D;”5.1007206911636045in”}</p>\n<p>可以看到每个 Orc 文件由 1 个或多个 stripe 组成，每个 stripe 250MB<br>大小，这个 Stripe实际相当于 RowGroup 概念，不过大小由<br>4MB-&gt;250MB，这样应该能提升顺序读的吞吐率。每个 Stripe<br>里由三部分组成，分别是 Index Data,Row Data,Stripe Footer：</p>\n<p>1）Index Data：一个轻量级的 index，默认是每隔 1W<br>行做一个索引。这里做的索引应该只是记录某行的各字段在 Row Data 中的<br>offset。</p>\n<p>2）Row<br>Data：存的是具体的数据，先取部分行，然后<strong>对这些行按列进行存储</strong>。对每个列进行了编码，分成多个<br>Stream 来存储。</p>\n<p>3）<strong>Stripe Footer</strong>：存的是各个 Stream<br>的类型，长度等信息。每个文件有一个 <strong>File Footer</strong>，这里面存的是每个<br>Stripe 的行数，每个 Column 的数据类型信息等；每个文件的<strong>尾部是一个<br>PostScript</strong>，这里面记录了整个文件的压缩类型以及<br>FileFooter的长度信息等。【在读取文件时，会 seek 到文件尾部读<br>PostScript，从里面解析到 File Footer长度，再读<br>FileFooter，从里面解析到各个 Stripe 信息，再读各个<br>Stripe，即<strong>从后往前读</strong>。】</p>\n<h3 id=\"8-5-4-Parquet-格式\"><a href=\"#8-5-4-Parquet-格式\" class=\"headerlink\" title=\"8.5.4 Parquet 格式\"></a>8.5.4 Parquet <strong>格式</strong></h3><p>Parquet 是面向分析型业务的列式存储格式，由 Twitter 和 Cloudera<br>合作开发，2015 年 5月从 Apache 的孵化器里毕业成为 Apache 顶级项目。</p>\n<p>Parquet<br>文件是以二进制方式存储的，所以是不可以直接读取的，文件中包括该文件的数据和元数据，因此<br>Parquet 格式文件是<strong>自解析</strong>的。通常情况下，在存储 Parquet<br>数据的时候会按照 Block 大小设置行组的大小，由于一般情况下每一个 Mapper<br>任务处理数据的最小单位是一个 Block，这样可以把每一个行组由一个 Mapper<br>任务处理，增大任务执行并行度。Parquet 文件的格式如下图所示。</p>\n<p><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image25.png\">{width&#x3D;”6.522916666666666in”<br>height&#x3D;”4.885416666666667in”}</p>\n<p>上图展示了一个 Parquet<br>文件的内容，一个文件中可以存储多个行组，文件的首位都是</p>\n<p>该文件的 Magic Code，用于校验它是否是一个 Parquet 文件，Footer length<br>记录了文件元数据的大小，通过该值和文件长度可以计算出元数据的偏移量，文件的元数据中包括每一个<strong>行组</strong>的元数据信息和该文件存储数据的<br>Schema<br>信息。除了文件中每一个行组的元数据，每一<strong>页</strong>的开始都会存储该页的元数据，在<br>Parquet<br>中，有三种类型的页：<strong>数据页、字典页和索引页</strong>。数据页用于存储当前行组中该列的值，字典页存储该列值的编码字典，<strong>每一个列块中最多包含一个字典页</strong>，索引页用来存储当前行组下该列的索引，目前<br>Parquet 中还不支持索引页。</p>\n<p>**TEXTFILE 和 SEQUENCEFILE 的存储格式都是基于行存储的； **</p>\n<p><strong>ORC 和 PARQUET 是基于列式存储的。</strong></p>\n<p>8.6.2 测试存储和压缩</p>\n<p>2）创建一个 SNAPPY 压缩的 ORC 存储方式</p>\n<p>（1）建表语句</p>\n<p>create table log_orc_snappy(</p>\n<p>track_time string,</p>\n<p>url string,</p>\n<p>session_id string,</p>\n<p>referer string,</p>\n<p>ip string,</p>\n<p>end_user_id string,</p>\n<p>city_id string</p>\n<p>)</p>\n<p>row format delimited fields terminated by &#39;\\t&#39;</p>\n<p>stored as orc **tblproperties (&quot;orc.compress&quot;&#x3D;&quot;SNAPPY&quot;); **</p>\n<p>（2）插入数据</p>\n<p>insert into table log_orc_snappy select * from log_text ;</p>\n<p>（3）查看插入后数据</p>\n<p>dfs -du -h &#x2F;user&#x2F;hive&#x2F;warehouse&#x2F;log_orc_snappy&#x2F; ;</p>\n<p>orc 存储文件默认采用 ZLIB 压缩。比 snappy 压缩的小。</p>\n<p><strong>4</strong>）存储方式和压缩总结：</p>\n<p>在实际的项目开发当中，**hive 表的数据存储格式一般选择：orc 或<br>parquet（小）。压缩方式一般选择（快）snappy不可切，lzo可切。 **</p>\n<h1 id=\"九-Hive企业级调优\"><a href=\"#九-Hive企业级调优\" class=\"headerlink\" title=\"九 Hive企业级调优 \"></a>九 <strong>Hive</strong>企业级调优 </h1><h2 id=\"9-1-Fetch-抓取\"><a href=\"#9-1-Fetch-抓取\" class=\"headerlink\" title=\"9.1 Fetch 抓取 \"></a>9.1 Fetch <strong>抓取</strong> </h2><p>Fetch 抓取是指，Hive 中对某些情况的查询可以不必使用 MapReduce<br>计算。例如：SELECT * FROM employees;在这种情况下，Hive 可以简单地读取<br>employee 对应的存储目录下的文件，然后输出查询结果到控制台。</p>\n<p>在 hive-default.xml.template 文件中 hive.fetch.task.conversion 默认是<br>more，老版本 hive默认是 minimal，该属性修改为 more<br>以后，在全局查找、字段查找、limit 查找等都不走mapreduce。</p>\n<p>&lt;property&gt;</p>\n<p>&lt;name&gt;hive.fetch.task.conversion&lt;&#x2F;name&gt;</p>\n<p>&lt;value&gt;more&lt;&#x2F;value&gt;</p>\n<p>&lt;description&gt;</p>\n<p>Expects one of [none, minimal, more].</p>\n<p>Some select queries can be converted to single FETCH task minimizing<br>latency.</p>\n<p>Currently the query should be single sourced not having any subquery and<br>should not</p>\n<p>have</p>\n<p>any aggregations or distincts (which incurs RS), lateral views and<br>joins.</p>\n<p>0. none : disable hive.fetch.task.conversion</p>\n<p>1. minimal : SELECT STAR, FILTER on partition columns, LIMIT only</p>\n<p>2. more : SELECT, FILTER, LIMIT only (support TABLESAMPLE and virtual</p>\n<p>columns)</p>\n<p>&lt;&#x2F;description&gt;</p>\n<p>&lt;&#x2F;property&gt;</p>\n<p>案例实操：</p>\n<p>1）把 hive.fetch.task.conversion 设置成 none，然后执行查询语句，都会执行<br>mapreduce程序。</p>\n<p>hive (default)&gt; set hive.fetch.task.conversion&#x3D;none;</p>\n<p>hive (default)&gt; select * from emp;</p>\n<p>hive (default)&gt; select ename from emp;</p>\n<p>hive (default)&gt; select ename from emp limit 3;</p>\n<p>2）把 hive.fetch.task.conversion 设置成<br>more，然后执行查询语句，如下查询方式都不会执行 mapreduce 程序。</p>\n<p>hive (default)&gt; set hive.fetch.task.conversion&#x3D;more;</p>\n<p>hive (default)&gt; select * from emp;</p>\n<p>hive (default)&gt; select ename from emp;</p>\n<p>hive (default)&gt; select ename from emp limit 3;</p>\n<h2 id=\"9-2-本地模式\"><a href=\"#9-2-本地模式\" class=\"headerlink\" title=\"9.2 本地模式 \"></a>9.2 <strong>本地模式</strong> </h2><p>大多数的 Hadoop Job 是需要 Hadoop<br>提供的完整的可扩展性来处理大数据集的。不过，有时 Hive<br>的输入数据量是非常小的。在这种情况下，为查询触发执行任务时消耗可能会比实际<br>job 的执行时间要多的多。对于大多数这种情况，Hive<br>可以通过本地模式在单台机器上处理所有的任务。对于小数据集，执行时间可以明显被缩短。</p>\n<p>用户可以通过设置 hive.exec.mode.local.auto 的值为 true，来让 Hive<br>在适当的时候自动启动这个优化。</p>\n<p>set hive.exec.mode.local.auto&#x3D;true; &#x2F;&#x2F;开启本地 mr</p>\n<p>&#x2F;&#x2F;设置 local mr 的最大输入数据量，当输入数据量小于这个值时采用 local mr<br>的方式，</p>\n<p>默认为 134217728，即 128M</p>\n<p>set hive.exec.mode.local.auto.inputbytes.max&#x3D;50000000;</p>\n<p>&#x2F;&#x2F;设置 local mr 的最大输入文件个数，</p>\n<p>当输入文件个数小于这个值时采用 local mr 的方式，</p>\n<p>默认为 4</p>\n<p>set hive.exec.mode.local.auto.input.files.max&#x3D;10;</p>\n<p>案例实操：</p>\n<p>1）开启本地模式，并执行查询语句</p>\n<p>hive (default)&gt; set hive.exec.mode.local.auto&#x3D;true;</p>\n<p>hive (default)&gt; select * from emp cluster by deptno;</p>\n<p>Time taken: 1.328 seconds, Fetched: 14 row(s)</p>\n<p>2）关闭本地模式，并执行查询语句</p>\n<p>hive (default)&gt; set hive.exec.mode.local.auto&#x3D;false;</p>\n<p>hive (default)&gt; select * from emp cluster by deptno;</p>\n<p>Time taken: 20.09 seconds, Fetched: 14 row(s)</p>\n<h2 id=\"9-3-表的优化\"><a href=\"#9-3-表的优化\" class=\"headerlink\" title=\"9.3 表的优化 \"></a>9.3 <strong>表的优化</strong> </h2><h3 id=\"9-3-1-小表、大表-Join\"><a href=\"#9-3-1-小表、大表-Join\" class=\"headerlink\" title=\"9.3.1 小表、大表 Join\"></a>9.3.1 <strong>小表、大表</strong> Join</h3><p>将 key 相对分散，并且数据量<strong>小</strong>的<strong>表</strong>放在 <strong>join<br>的左边</strong>，这样可以有效减少内存溢出错误发生的几率；再进一步，可以使用<br>Group 让小的维度表（1000 条以下的记录条数）先进内存。在 map 端完成<br>reduce。</p>\n<p>实际测试发现：新版的 hive 已经对小表 JOIN 大表和大表 JOIN<br>小表进行了<strong>优化</strong>。小表放在左边和右边已经<strong>没有明显区别</strong>。</p>\n<p>案例实操</p>\n<p>（0）需求：测试大表 JOIN 小表和小表 JOIN 大表的效率</p>\n<p>（1）建大表、小表和 JOIN 后表的语句</p>\n<p>create table bigtable(id bigint, time bigint, uid string, keyword<br>string, url_rank int, click_num int, click_url string) row format<br>delimited fields terminated by &#39;\\t&#39;;</p>\n<p>create table smalltable(id bigint, time bigint, uid string, keyword<br>string, url_rank int, click_num int, click_url string) row format<br>delimited fields terminated by &#39;\\t&#39;;</p>\n<p>create table jointable(id bigint, time bigint, uid string, keyword<br>string, url_rank int, click_num int, click_url string) row format<br>delimited fields terminated by &#39;\\t&#39;;</p>\n<p>（2）分别向大表和小表中导入数据</p>\n<p>hive (default)&gt; load data local inpath &#39;&#x2F;opt&#x2F;module&#x2F;datas&#x2F;bigtable&#39;<br>into table bigtable;</p>\n<p>hive (default)&gt;load data local inpath &#39;&#x2F;opt&#x2F;module&#x2F;datas&#x2F;smalltable&#39;<br>into table smalltable;</p>\n<p>（3）关闭 mapjoin 功能（默认是打开的）</p>\n<p>set hive.auto.convert.join &#x3D; false;</p>\n<p>（4）执行小表 JOIN 大表语句</p>\n<p>insert overwrite table jointable</p>\n<p>select b.id, b.time, b.uid, b.keyword, b.url_rank, b.click_num,<br>b.click_url</p>\n<p>from smalltable s</p>\n<p>left join bigtable b</p>\n<p>on b.id &#x3D; s.id;</p>\n<p>Time taken: 35.921 seconds</p>\n<p>（5）执行大表 JOIN 小表语句</p>\n<p>insert overwrite table jointable</p>\n<p>select b.id, b.time, b.uid, b.keyword, b.url_rank, b.click_num,<br>b.click_url</p>\n<p>from bigtable b</p>\n<p>left join smalltable s</p>\n<p>on s.id &#x3D; b.id;</p>\n<p>Time taken: 34.196 seconds</p>\n<h3 id=\"9-3-2-大表-Join-大表\"><a href=\"#9-3-2-大表-Join-大表\" class=\"headerlink\" title=\"9.3.2 大表 Join 大表\"></a>9.3.2 <strong>大表</strong> Join <strong>大表</strong></h3><p>1）空 KEY 过滤</p>\n<p>有时 join 超时是因为某些 key 对应的<strong>数据太多</strong>，而相同 key<br>对应的数据都会发送到相同的 reducer<br>上，从而导致内存不够。此时我们应该仔细分析这些异常的<br>key，很多情况下，这些 key 对应的数据是异常数据，我们需要在 SQL<br>语句中进行过滤。例如 key 对应的<strong>字段为空</strong>，操作如下：</p>\n<p>案例实操</p>\n<p>（1）配置历史服务器</p>\n<p>配置 mapred-site.xml</p>\n<p>&lt;property&gt;</p>\n<p>&lt;name&gt;mapreduce.jobhistory.address&lt;&#x2F;name&gt;</p>\n<p>&lt;value&gt;hadoop102:10020&lt;&#x2F;value&gt;</p>\n<p>&lt;&#x2F;property&gt;</p>\n<p>&lt;property&gt;</p>\n<p>&lt;name&gt;mapreduce.jobhistory.webapp.address&lt;&#x2F;name&gt;</p>\n<p>&lt;value&gt;hadoop102:19888&lt;&#x2F;value&gt;</p>\n<p>&lt;&#x2F;property&gt;</p>\n<p>启动历史服务器</p>\n<p>sbin&#x2F;mr-jobhistory-daemon.sh start historyserver</p>\n<p>查看 jobhistory</p>\n<p><a href=\"http://192.168.1.102:19888/jobhistory\">http://192.168.1.102:19888/jobhistory\n</a></p>\n<p>（2）创建原始数据表、空 id 表、合并后数据表</p>\n<p>create table ori(id bigint, time bigint, uid string, keyword string,<br>url_rank int, click_num int, click_url string) row format delimited<br>fields terminated by &#39;\\t&#39;;</p>\n<p>create table nullidtable(id bigint, time bigint, uid string, keyword<br>string, url_rank int, click_num int, click_url string) row format<br>delimited fields terminated by &#39;\\t&#39;;</p>\n<p>create table jointable(id bigint, time bigint, uid string, keyword<br>string, url_rank int, click_num int, click_url string) row format<br>delimited fields terminated by &#39;\\t&#39;;</p>\n<p>（3）分别加载原始数据和空 id 数据到对应表中</p>\n<p>hive (default)&gt; load data local inpath &#39;&#x2F;opt&#x2F;module&#x2F;datas&#x2F;ori&#39; into<br>table ori;</p>\n<p>hive (default)&gt; load data local inpath &#39;&#x2F;opt&#x2F;module&#x2F;datas&#x2F;nullid&#39;<br>into table nullidtable;</p>\n<p>（4）测试不过滤空 id</p>\n<p>hive (default)&gt; insert overwrite table jointable</p>\n<p>select n.* from nullidtable n left join ori o on n.id &#x3D; o.id;</p>\n<p>Time taken: 42.038 seconds</p>\n<p>（5）测试过滤空 id</p>\n<p>hive (default)&gt; insert overwrite table jointable</p>\n<p>select n.* from [(select * from nullidtable where id is not null<br>)]{.underline} n left join ori o on n.id &#x3D; o.id;</p>\n<p>Time taken: 31.725 seconds</p>\n<p>2）空 key 转换</p>\n<p>有时虽然某个 key<br>为空对应的数据很多（进入同一个reduce中：数据倾斜），但是相应的数据不是异常数据，必须要包含在join<br>的结果中，此时我们可以给表 a 中 key<br>为空的字段赋一个<strong>随机的</strong>值，使得数据随机均匀地分到不同的 reducer<br>上。例如：</p>\n<p>案例实操：</p>\n<p>不随机分布空 <strong>null</strong> 值：</p>\n<p>（1）设置 5 个 reduce 个数</p>\n<p>set mapreduce.job.reduces &#x3D; 5;</p>\n<p>（2）JOIN 两张表</p>\n<p>insert overwrite table jointable</p>\n<p>select n.* from nullidtable n left join ori b on n.id &#x3D; b.id;</p>\n<p><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image26.png\">{width&#x3D;”6.689583333333333in”<br>height&#x3D;”2.8645833333333335in”}</p>\n<p>结果：可以看出来，出现了数据倾斜，某些 <strong>reducer</strong> 的资源消耗远大于其他<br><strong>reducer</strong>。</p>\n<p>随机分布空 null 值</p>\n<p>（1）设置 5 个 reduce 个数</p>\n<p>set mapreduce.job.reduces &#x3D; 5;</p>\n<p>（2）JOIN 两张表</p>\n<p>insert overwrite table jointable</p>\n<p>select n.* from nullidtable n full join ori o on</p>\n<p>[<strong>case when</strong> n.id is null <strong>then</strong> concat(&#39;hive&#39;, rand()) <strong>else</strong><br>n.id <strong>end</strong>]{.underline} &#x3D; o.id;</p>\n<p><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image27.png\">{width&#x3D;”6.725694444444445in”<br>height&#x3D;”2.7604166666666665in”}</p>\n<p>结果：可以看出来，消除了数据倾斜，负载均衡 <strong>reducer</strong> 的资源消耗</p>\n<h3 id=\"9-3-3-MapJoin\"><a href=\"#9-3-3-MapJoin\" class=\"headerlink\" title=\"9.3.3 MapJoin\"></a>9.3.3 MapJoin</h3><p>如果不指定 MapJoin 或者不符合 MapJoin 的条件，那么 Hive 解析器会将 Join<br>操作转换成Common Join，即：在 Reduce 阶段完成<br>join。容易发生数据倾斜。可以用 MapJoin 把小表全部加载到内存在 map 端进行<br>join，避免 reducer 处理。</p>\n<p>1）开启 MapJoin 参数设置：</p>\n<p>（1）设置自动选择 Mapjoin</p>\n<p>set hive.auto.convert.join &#x3D; true; 默认为 true</p>\n<p>（2）大表小表的阀值设置（默认 25M 以下认为是小表）：</p>\n<p>set hive.mapjoin.smalltable.filesize&#x3D;25000000;</p>\n<p>2）MapJoin 工作机制</p>\n<p><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image28.png\">{width&#x3D;”7.310951443569554in”<br>height&#x3D;”3.6875in”}</p>\n<p>案例实操：</p>\n<p>（1）开启 Mapjoin 功能</p>\n<p>set hive.auto.convert.join &#x3D; true; 默认为 true</p>\n<p>（2）执行小表 JOIN 大表语句</p>\n<p>insert overwrite table jointable</p>\n<p>select b.id, b.time, b.uid, b.keyword, b.url_rank, b.click_num,<br>b.click_url</p>\n<p>from smalltable s</p>\n<p>join bigtable b</p>\n<p>on s.id &#x3D; b.id;</p>\n<p>Time taken: 24.594 seconds</p>\n<p>（3）执行大表 JOIN 小表语句 （优化更多）</p>\n<p>insert overwrite table jointable</p>\n<p>select b.id, b.time, b.uid, b.keyword, b.url_rank, b.click_num,<br>b.click_url</p>\n<p>from bigtable b</p>\n<p>join smalltable s</p>\n<p>on s.id &#x3D; b.id;</p>\n<p>Time taken: 24.315 seconds</p>\n<h3 id=\"9-3-4-Group-By\"><a href=\"#9-3-4-Group-By\" class=\"headerlink\" title=\"9.3.4 Group By\"></a>9.3.4 Group By</h3><p>默认情况下，Map 阶段同一 Key 数据分发给一个 reduce，当一个 key<br>数据过大时就倾</p>\n<p>斜了。 方法一：Map join ；方法二：负载均衡</p>\n<p>并不是所有的聚合操作都需要在 Reduce 端完成，很多聚合操作都可以先在 Map<br>端进行</p>\n<p>部分聚合，最后在 Reduce 端得出最终结果。</p>\n<p>1）开启 Map 端聚合参数设置</p>\n<p>（1）是否在 Map 端进行聚合，默认为 True</p>\n<p>hive.map.aggr &#x3D; true</p>\n<p>（2）在 Map 端进行聚合操作的条目数目</p>\n<p>hive.groupby.mapaggr.checkinterval &#x3D; 100000</p>\n<p>（3）有数据倾斜的时候进行负载均衡（默认是 false）</p>\n<p>hive.groupby.skewindata &#x3D; true</p>\n<p>当选项设定为 true，生成的查询计划会有<strong>两个 MR Job</strong>。第一个 MR Job<br>中，Map 的输</p>\n<p>出结果会<strong>随机分布</strong>到 Reduce 中，每个 Reduce<br>做<strong>部分聚合</strong>操作，并输出结果，这样处理的结果是相同的 Group By Key<br>有可能被分发到不同的 Reduce 中，从而达到<strong>负载均衡</strong>的目的；第二个 MR<br>Job 再根据预处理的数据结果<strong>按照 Group By Key 分布</strong>到 Reduce<br>中（这个过程可以保证相同的 Group By Key 被分布到同一个 Reduce<br>中），最后完成<strong>最终的聚合</strong>操作。 （类似于：二级缓存）</p>\n<h3 id=\"9-3-5-Count-Distinct-去重统计\"><a href=\"#9-3-5-Count-Distinct-去重统计\" class=\"headerlink\" title=\"9.3.5 Count(Distinct) 去重统计\"></a>9.3.5 Count(Distinct) <strong>去重统计</strong></h3><p>数据量小的时候无所谓，数据量大的情况下，由于 <strong>COUNT DISTINCT</strong><br>操作需要用一个</p>\n<p>Reduce Task 来完成，这一个 Reduce 需要处理的数据量太大，就会导致整个 Job<br>很难完成，一般 COUNT DISTINCT 使用<strong>先 GROUP BY 再 COUNT</strong> 的方式替换：</p>\n<p>案例实操</p>\n<p>（1）创建一张大表</p>\n<p>hive (default)&gt; create table bigtable(id bigint, time bigint, uid<br>string, keyword string, url_rank int, click_num int, click_url<br>string) row format delimited fields terminated by &#39;\\t&#39;;</p>\n<p>（2）加载数据</p>\n<p>hive (default)&gt; load data local inpath &#39;&#x2F;opt&#x2F;module&#x2F;datas&#x2F;bigtable&#39;<br>into table bigtable;</p>\n<p>（3）设置 5 个 reduce 个数</p>\n<p>set mapreduce.job.reduces &#x3D; 5;</p>\n<p>（4）执行去重 id 查询</p>\n<p>hive (default)&gt; select <strong>count(distinct id)</strong> from bigtable;</p>\n<p>Stage-Stage-1: Map: 1 Reduce: 1 Cumulative CPU: 7.12 sec HDFS Read:</p>\n<p>120741990 HDFS Write: 7 SUCCESS</p>\n<p>Total MapReduce CPU Time Spent: 7 seconds 120 msec</p>\n<p>OK</p>\n<p>c0</p>\n<p>100001</p>\n<p>Time taken: 23.607 seconds, Fetched: 1 row(s)</p>\n<p>Time taken: 34.941 seconds, Fetched: 1 row(s)</p>\n<p>（5）采用 GROUP by 去重 id</p>\n<p>hive (default)&gt; select count(id) from [(select id from bigtable group<br>by id)]{.underline} a;</p>\n<p>Stage-Stage-1: Map: 1 Reduce: 5 Cumulative CPU: 17.53 sec HDFS Read:</p>\n<p>120752703 HDFS Write: 580 SUCCESS</p>\n<p>Stage-Stage-2: Map: 3 Reduce: 1 Cumulative CPU: 4.29 sec HDFS Read: 9409</p>\n<p>HDFS Write: 7 SUCCESS</p>\n<p>Total MapReduce CPU Time Spent: 21 seconds 820 msec</p>\n<p>OK</p>\n<p>_c0</p>\n<p>100001</p>\n<p>Time taken: 50.795 seconds, Fetched: 1 row(s)</p>\n<p>虽然会多用一个 Job 来完成，但在数据量大的情况下，这个绝对是值得的。</p>\n<h3 id=\"9-3-6-笛卡尔积\"><a href=\"#9-3-6-笛卡尔积\" class=\"headerlink\" title=\"9.3.6 笛卡尔积\"></a>9.3.6 <strong>笛卡尔积</strong></h3><p>尽量避免笛卡尔积，join 的时候不加 on 条件，或者无效的 on 条件，Hive<br>只能使用 1</p>\n<p>个 reducer 来完成笛卡尔积</p>\n<h3 id=\"9-3-7-行列过滤\"><a href=\"#9-3-7-行列过滤\" class=\"headerlink\" title=\"9.3.7 行列过滤\"></a>9.3.7 <strong>行列过滤</strong></h3><p>列处理：在 SELECT 中，只拿需要的列，如果有，尽量使用分区过滤，少用<br>SELECT *。</p>\n<p>行处理：在分区剪裁中，当使用外关联时，如果将副表的过滤条件写在 Where<br>后面，</p>\n<p>那么就会先全表关联，之后再过滤，不好。比如：</p>\n<p>案例实操：</p>\n<p>（1）测试先join关联两张表，再用 where 条件过滤</p>\n<p>hive (default)&gt; select o.id from bigtable b</p>\n<p>join ori o on o.id &#x3D; b.id</p>\n<p>where o.id &lt;&#x3D; 10;</p>\n<p>Time taken: 34.406 seconds, Fetched: 100 row(s)</p>\n<p>Time taken: 26.043 seconds, Fetched: 100 row(s)</p>\n<p>（2）通过子查询where后，再关联join表</p>\n<p>hive (default)&gt; select b.id from bigtable b</p>\n<p>join [(select id from ori where id &lt;&#x3D; 10 ) o]{.underline} on b.id &#x3D;<br>o.id;</p>\n<p>Time taken: 30.058 seconds, Fetched: 100 row(s)</p>\n<p>Time taken: 29.106 seconds, Fetched: 100 row(s)</p>\n<h3 id=\"9-3-8-动态分区调整\"><a href=\"#9-3-8-动态分区调整\" class=\"headerlink\" title=\"9.3.8 动态分区调整\"></a>9.3.8 <strong>动态分区调整</strong></h3><p>关系型数据库中，对分区表 Insert<br>数据时候，数据库自动会根据分区字段的值，将数据</p>\n<p>插入到相应的分区中，Hive 中也提供了类似的机制，即动态分区(Dynamic<br>Partition)，只不过，使用 Hive 的动态分区，需要进行相应的配置。</p>\n<p>1）开启动态分区参数设置</p>\n<p>（1）开启动态分区功能（默认 true，开启）</p>\n<p>hive.exec.dynamic.partition&#x3D;true</p>\n<p>（2）设置为非严格模式（动态分区的模式，默认<br>strict，表示必须指定至少一个分区为静态分区，nonstrict<br>模式表示允许所有的分区字段都可以使用动态分区。）</p>\n<p>hive.exec.dynamic.partition.mode&#x3D;nonstrict</p>\n<p>（3）在<strong>所有</strong>执行 MR 的节点上，最大<strong>一共</strong>可以创建多少个动态分区。</p>\n<p>hive.exec.max.dynamic.partitions&#x3D;1000</p>\n<p>（4）在<strong>每个</strong>执行 MR<br>的节点上，<strong>最大</strong>可以创建多少个动态分区。该参数<strong>需要根据实际</strong></p>\n<p><strong>的数据来设定</strong>。比如：源数据中包含了**[一年的数据，即 day 字段有 365<br>个值，那么该参数就需要设置成大于 365，如果使用默认值 100，则会报错。<br>]{.underline}**</p>\n<p>hive.exec.max.dynamic.partitions.pernode&#x3D;100</p>\n<p>（5）整个 MR Job 中，最大可以创建多少个 HDFS 文件。</p>\n<p>hive.exec.max.created.files&#x3D;100000</p>\n<p>（6）当有空分区生成时，是否抛出异常。一般不需要设置。</p>\n<p>hive.error.on.empty.partition&#x3D;false</p>\n<p>2）案例实操</p>\n<p>需求：</p>\n<p>将 ori 中的数据按照时间(如：20111230000008)，插入到目标表<br>ori_partitioned_target的相应分区中。</p>\n<p>（1）创建分区表</p>\n<p>create table ori_partitioned(id bigint, time bigint, uid string,<br>keyword string, url_rank int, click_num int, click_url string)</p>\n<p>partitioned by (p_time bigint)</p>\n<p>row format delimited fields terminated by &#39;\\t&#39;;</p>\n<p>（2）加载数据到分区表中</p>\n<p>hive (default)&gt; load data local inpath &#39;&#x2F;opt&#x2F;module&#x2F;datas&#x2F;ds1&#39; into<br>table ori_partitioned partition(p_time&#x3D;&#39;20111230000010&#39;) ;</p>\n<p>hive (default)&gt; load data local inpath &#39;&#x2F;opt&#x2F;module&#x2F;datas&#x2F;ds2&#39; into<br>table ori_partitioned partition(p_time&#x3D;&#39;20111230000011&#39;) ;</p>\n<p>（3）创建目标分区表</p>\n<p>create table ori_partitioned_target(id bigint, time bigint, uid<br>string, keyword string, url_rank int, click_num int, click_url<br>string) PARTITIONED BY (p_time STRING) row format delimited fields<br>terminated by &#39;\\t&#39;;</p>\n<p>（4）设置动态分区</p>\n<p>set hive.exec.dynamic.partition &#x3D; true;</p>\n<p>set hive.exec.dynamic.partition.mode &#x3D; nonstrict;</p>\n<p>set hive.exec.max.dynamic.partitions &#x3D; 1000;</p>\n<p>set hive.exec.max.dynamic.partitions.pernode &#x3D; 100;</p>\n<p>set hive.exec.max.created.files &#x3D; 100000;</p>\n<p>set hive.error.on.empty.partition &#x3D; false;</p>\n<p>hive (default)&gt; insert overwrite table ori_partitioned_target<br>partition (p_time) select id, time, uid, keyword, url_rank,<br>click_num, click_url, p_time from ori_partitioned;</p>\n<p>（5）查看目标分区表的分区情况</p>\n<p>hive (default)&gt; show partitions ori_partitioned_target;</p>\n<h3 id=\"9-3-9-分桶\"><a href=\"#9-3-9-分桶\" class=\"headerlink\" title=\"9.3.9 分桶\"></a>9.3.9 <strong>分桶</strong></h3><p>详见 6.6 章。</p>\n<h3 id=\"9-3-10-分区\"><a href=\"#9-3-10-分区\" class=\"headerlink\" title=\"9.3.10 分区\"></a>9.3.10 <strong>分区</strong></h3><p>详见 4.6 章。</p>\n<h2 id=\"9-4-数据倾斜\"><a href=\"#9-4-数据倾斜\" class=\"headerlink\" title=\"9.4 数据倾斜 \"></a>9.4 <strong>数据倾斜</strong> </h2><h3 id=\"9-4-1-合理设置-Map-数\"><a href=\"#9-4-1-合理设置-Map-数\" class=\"headerlink\" title=\"9.4.1 合理设置 Map 数\"></a>9.4.1 <strong>合理设置</strong> Map <strong>数</strong></h3><p><strong>1</strong>）通常情况下，作业会通过 <strong>input</strong> 的目录产生一个或者多个 <strong>map</strong><br>任务。 <strong>切片公式</strong></p>\n<p>主要的决定因素有：input 的文件总个数，input<br>的文件大小，集群设置的文件块大小。</p>\n<p><strong>2</strong>）是不是 <strong>map</strong> 数越多越好？</p>\n<p>答案是否定的。如果一个任务有很多小文件（远远小于块大小<br>128m），则每个小文件也会被当做一个块，用一个 map 任务来完成，而一个 map<br>任务启动和初始化的时间远远大于逻辑处理的时间，就会造成很大的资源浪费。而且，同时可执行的<br>map 数是受限的。</p>\n<p>**很多小文件IO密集型：减少 map 数 **</p>\n<p><strong>3</strong>）是不是保证每个 <strong>map</strong> 处理接近 <strong>128m</strong> 的文件块，就高枕无忧了？</p>\n<p>答案也是不一定。比如有一个 127m 的文件，正常会用一个 map<br>去完成，但这个文件只</p>\n<p>有一个或者两个小字段，却有几千万的记录，如果 map<br>处理的逻辑比较复杂，用一个 map任务去做，肯定也比较耗时。<br><strong>计算密集型：增加 map 数</strong></p>\n<p>针对上面的问题 2 和 3，我们需要采取两种方式来解决：即减少 map 数和增加<br>map 数；</p>\n<h3 id=\"9-4-2-小文件进行合并\"><a href=\"#9-4-2-小文件进行合并\" class=\"headerlink\" title=\"9.4.2 小文件进行合并\"></a><strong>9.4.2</strong> 小文件进行合并</h3><p>hadoop:CombineTextInputFormat</p>\n<p>在 map 执行前合并小文件，减少 map 数：CombineHiveInputFormat<br>具有对小文件进行</p>\n<p>合并的功能（系统默认的格式）。HiveInputFormat 没有对小文件合并功能。</p>\n<p>[set hive.input.format&#x3D;<br>org.apache.hadoop.hive.ql.io.CombineHiveInputFormat; ]{.underline}</p>\n<h3 id=\"9-4-3-复杂文件增加-Map-数\"><a href=\"#9-4-3-复杂文件增加-Map-数\" class=\"headerlink\" title=\"9.4.3 复杂文件增加 Map 数\"></a>9.4.3 <strong>复杂文件增加</strong> Map <strong>数</strong></h3><p>当 input 的文件都很大，任务逻辑复杂，map 执行非常慢的时候，可以考虑增加<br>Map</p>\n<p>数，来使得每个 map 处理的数据量减少，从而提高任务的执行效率。</p>\n<p>增加 map 的方法为：一个splite进入一个map</p>\n<p>computeSpliteSize(Math.max(minSize1,Math.min(maxSizelong最大值,blocksize128M)))&#x3D;blocksize&#x3D;128M<br>公式，**调整 maxSize 最大值。让 maxSize 最大值低于 blocksize 就可以增加<br>map 的个数。 **</p>\n<p>案例实操：</p>\n<p>（1）执行查询</p>\n<p>hive (default)&gt; select count(*) from emp;</p>\n<p>Hadoop job information for Stage-1: number of mappers: 1; number of<br>reducers: 1</p>\n<p>（2）设置最大切片值为 100 个字节</p>\n<p>hive (default)&gt; set mapreduce.input.fileinputformat.split.maxsize&#x3D;100;</p>\n<p>hive (default)&gt; select count(*) from emp;</p>\n<p>Hadoop job information for Stage-1: number of mappers: 6; number of<br>reducers: 1</p>\n<h3 id=\"9-4-4-合理设置-Reduce-数\"><a href=\"#9-4-4-合理设置-Reduce-数\" class=\"headerlink\" title=\"9.4.4 合理设置 Reduce 数\"></a>9.4.4 <strong>合理设置</strong> Reduce <strong>数</strong></h3><p><strong>1</strong>）调整 <strong>reduce</strong> 个数方法一</p>\n<p>（1）每个 Reduce 处理的数据量默认是 256MB</p>\n<p>hive.exec.reducers.bytes.per.reducer&#x3D;256000000</p>\n<p>（2）每个任务最大的 reduce 数，默认为 1009</p>\n<p>hive.exec.reducers.max&#x3D;1009</p>\n<p>（3）计算 reducer 数的公式</p>\n<p>N&#x3D;min(参数 2，总输入数据量&#x2F;参数 1)</p>\n<p><strong>2</strong>）调整 <strong>reduce</strong> 个数方法二</p>\n<p>在 hadoop 的 mapred-default.xml 文件中修改</p>\n<p>设置每个 job 的 Reduce 个数</p>\n<p>set mapreduce.job.reduces &#x3D; 15;</p>\n<p><strong>3</strong>）<strong>reduce</strong> 个数并不是越多越好</p>\n<p>1）过多的启动和初始化 reduce 也会消耗时间和资源；</p>\n<p>2）另外，有多少个<br>reduce，就会有多少个输出文件，如果生成了很多个小文件，那么</p>\n<p>如果这些小文件作为下一个任务的输入，则也会出现小文件过多的问题；</p>\n<p>在设置 reduce 个数的时候也需要考虑这两个原则：处理大数据量利用合适的<br>reduce 数；</p>\n<p>使单个 reduce 任务处理数据量大小要合适；</p>\n<h2 id=\"9-5-并行执行\"><a href=\"#9-5-并行执行\" class=\"headerlink\" title=\"9.5 并行执行 \"></a>9.5 <strong>并行执行</strong> </h2><p>Hdfs –put… -- &gt; 多个.edits文件</p>\n<p>Hive 会将一个查询转化成一个或者多个阶段。这样的阶段可以是 MapReduce<br>阶段、抽</p>\n<p>样阶段、合并阶段、limit 阶段。或者 Hive<br>执行过程中可能需要的其他阶段。默认情况下，Hive<br>一次只会执行一个阶段。不过，[某个特定的 job<br>可能包含众多的阶段，而这些阶段可能并非完全互相依赖的]{.underline}，也就是说有些阶段是可以并行执行的，这样可能使得整个<br>job 的执行时间缩短。不过，如果有更多的阶段可以并行执行，那么 job<br>可能就越快完成。</p>\n<p>通过设置参数 hive.exec.parallel 值为<br>true，就可以开启并发执行。不过，在共享集群中，需要注意下，如果 job<br>中并行阶段增多，那么集群利用率就会增加。</p>\n<p>set hive.exec.parallel&#x3D;true; &#x2F;&#x2F;打开任务并行执行</p>\n<p>set hive.exec.parallel.thread.number&#x3D;16; &#x2F;&#x2F;同一个 sql<br>允许最大并行度，默认为 8。</p>\n<p>当然，得是在<strong>系统资源</strong>比较空闲的时候才有优势，否则，没资源，并行也起不来。</p>\n<h2 id=\"9-6-严格模式\"><a href=\"#9-6-严格模式\" class=\"headerlink\" title=\"9.6 严格模式 \"></a>9.6 <strong>严格模式</strong> </h2><p>Hive<br>提供了一个严格模式，可以防止用户执行那些可能意向不到的不好的影响的查询。通过设置属性<br>hive.mapred.mode 值为默认是非严格模式 nonstrict 。开启严格模式需要修改<br>hive.mapred.mode 值为 strict，开启严格模式可以禁止 3 种类型的查询。</p>\n<p>hive-default.xml:</p>\n<p>&lt;property&gt;</p>\n<p>&lt;name&gt;hive.mapred.mode&lt;&#x2F;name&gt;</p>\n<p>&lt;value&gt;strict&lt;&#x2F;value&gt;</p>\n<p>&lt;description&gt;</p>\n<p>The mode in which the Hive operations are being performed.</p>\n<p>In strict mode, some risky queries are not allowed to run. They include:</p>\n<p>Cartesian Product.</p>\n<p>No partition being picked up for a query.</p>\n<p>Comparing bigints and strings.</p>\n<p>Comparing bigints and doubles.</p>\n<p>Orderby without limit.</p>\n<p>&lt;&#x2F;description&gt;</p>\n<p>&lt;&#x2F;property&gt;</p>\n<p>1）对于分区表，除非 [where<br>语句中含有分区字段过滤条件来限制范围]{.underline}，否则不允许执行。换句话说，就是用户<strong>不允许扫描所有分区</strong>。进行这个限制的原因是，通常分区表都拥有<strong>非常大的数据集，而且数据增加迅速</strong>。没有进行分区限制的查询可能会消耗令人不可接受的巨大资源来处理这个表。</p>\n<p>2）对于<strong>使用了 [order by 语句的查询，要求必须使用 limit]{.underline}</strong><br>语句。因为 order by 为了执行排序过程会将所有的结果数据分发到同一个<br>Reducer 中进行处理，强制要求用户增加这个 LIMIT语句可以防止 Reducer<br>额外执行很长一段时间。</p>\n<p>3）**[限制笛卡尔积]{.underline}的查询<strong>。对关系型数据库非常了解的用户可能期望在执行<br>JOIN 查询的时候不使用 ON 语句而是使用 where<br>语句，这样</strong>关系数据库的执行优化器**就可以高效地将WHERE 语句转化成那个<br>ON 语句。不幸的是，Hive<br>并不会执行这种优化，因此，如果表足够大，那么这个查询就会出现不可控的情况。</p>\n<h2 id=\"9-7-JVM-重用\"><a href=\"#9-7-JVM-重用\" class=\"headerlink\" title=\"9.7 JVM 重用 \"></a>9.7 JVM <strong>重用</strong> </h2><p>JVM 重用是 Hadoop 调优参数的内容，其对 Hive<br>的性能具有非常大的影响，特别是对</p>\n<p>于很难避免小文件的场景或 task<br>特别多的场景，这类场景大多数执行时间都很短。</p>\n<p>Hadoop 的默认配置通常是使用派生 JVM 来执行 map 和 Reduce 任务的。这时<br>JVM 的</p>\n<p>启动过程可能会造成相当大的开销，尤其是执行的 job 包含有成百上千 task<br>任务的情况。JVM重用可以使得 JVM 实例在同一个 job 中重新使用 N 次。N<br>的值可以在 Hadoop 的mapred-site.xml 文件中进行配置。通常在 10-20<br>之间，具体多少需要根据具体业务场景测试</p>\n<p>得出。</p>\n<p>&lt;property&gt;</p>\n<p>&lt;name&gt;mapreduce.job.jvm.numtasks&lt;&#x2F;name&gt;</p>\n<p>&lt;value&gt;10&lt;&#x2F;value&gt;</p>\n<p>&lt;description&gt;How many tasks to run per jvm. If set to -1, there is</p>\n<p>no limit.</p>\n<p>&lt;&#x2F;description&gt;</p>\n<p>&lt;&#x2F;property&gt;</p>\n<p>这个功能的缺点是，开启 JVM 重用将一直占用使用到的 task<br>插槽，以便进行重用，直</p>\n<p>到任务完成后才能释放。如果某个”不平衡的”job 中有某几个 reduce task<br>执行的时间要比其他 Reduce task<br>消耗的时间多的多(数据倾斜)的话，那么保留的插槽就会一直空闲着却无法被其他的job使用，直到所有的<br>task 都结束了才会释放。</p>\n<h2 id=\"9-8-推测执行\"><a href=\"#9-8-推测执行\" class=\"headerlink\" title=\"9.8 推测执行 \"></a>9.8 <strong>推测执行</strong> </h2><p>在分布式集群环境下，因为程序 Bug（包括 Hadoop 本身的<br>bug），负载不均衡或者资源分布不均等原因，会造成同一个作业的多个任务之间运行速度不一致，有些任务的运行速度可能明显慢于其他任务（比如一个作业的某个任务进度只有<br>50%，而其他所有任务已经运行完毕），则这些任务会拖慢作业的整体执行进度。为了避免这种情况发生，Hadoop<br>采用了推测执行（Speculative<br>Execution）机制，它根据一定的法则推测出”拖后腿”的任务，并为这样的任务启动一个备份任务，让该任务与原始任务同时处理同一份数据，并最终选用最先成功运行完成任务的计算结果作为最终结果。</p>\n<p>设置开启推测执行参数：Hadoop 的 mapred-site.xml 文件中进行配置</p>\n<p>&lt;property&gt;</p>\n<p>&lt;name&gt;mapreduce.map.speculative&lt;&#x2F;name&gt;</p>\n<p>&lt;value&gt;true&lt;&#x2F;value&gt;</p>\n<p>&lt;description&gt;If true, then multiple instances of some map tasks</p>\n<p>may be executed in parallel.&lt;&#x2F;description&gt;</p>\n<p>&lt;&#x2F;property&gt;</p>\n<p>&lt;property&gt;</p>\n<p>&lt;name&gt;mapreduce.reduce.speculative&lt;&#x2F;name&gt;</p>\n<p>&lt;value&gt;true&lt;&#x2F;value&gt;</p>\n<p>&lt;description&gt;If true, then multiple instances of some reduce tasks</p>\n<p>may be executed in parallel.&lt;&#x2F;description&gt;</p>\n<p>&lt;&#x2F;property&gt;</p>\n<p>不过 hive 本身也提供了配置项来控制 reduce-side 的推测执行：</p>\n<p>&lt;property&gt;</p>\n<p>&lt;name&gt;hive.mapred.reduce.tasks.speculative.execution&lt;&#x2F;name&gt;</p>\n<p>&lt;value&gt;true&lt;&#x2F;value&gt;</p>\n<p>&lt;description&gt;Whether speculative execution for reducers should be<br>turned on.</p>\n<p>&lt;&#x2F;description&gt;</p>\n<p>&lt;&#x2F;property&gt;</p>\n<p>关于调优这些推测执行变量，还很难给一个具体的建议。如果用户对于运行时的偏差非常敏感的话，那么可以将这些功能关闭掉。如果用户因为输入数据量很大而需要执行长时间的<br>map 或者 Reduce task 的话，那么启动推测执行造成的浪费是非常巨大的。</p>\n<h2 id=\"9-9-压缩\"><a href=\"#9-9-压缩\" class=\"headerlink\" title=\"9.9 压缩 \"></a>9.9 <strong>压缩</strong> </h2><p>详见第 8 章。</p>\n<h2 id=\"9-10-执行计划（Explain）\"><a href=\"#9-10-执行计划（Explain）\" class=\"headerlink\" title=\"9.10 执行计划（Explain） \"></a><strong>9.10</strong> 执行计划（<strong>Explain</strong>） </h2><p>1）基本语法</p>\n<p>EXPLAIN [EXTENDED | DEPENDENCY | AUTHORIZATION] query</p>\n<p>2）案例实操</p>\n<p>（1）查看下面这条语句的执行计划</p>\n<p>hive (default)&gt; explain select * from emp;</p>\n<p>hive (default)&gt; explain select deptno, avg(sal) avg_sal from emp group<br>by deptno;</p>\n<p>（2）查看详细执行计划</p>\n<p>hive (default)&gt; explain extended select * from emp;</p>\n<p>hive (default)&gt; explain extended select deptno, avg(sal) avg_sal from<br>emp group by deptno;</p>\n<h1 id=\"数据仓库\"><a href=\"#数据仓库\" class=\"headerlink\" title=\"数据仓库 \"></a>数据仓库 </h1><h2 id=\"11-1-什么是数据仓库\"><a href=\"#11-1-什么是数据仓库\" class=\"headerlink\" title=\"11.1 什么是数据仓库 \"></a><strong>11.1</strong> 什么是数据仓库 </h2><p>数据仓库，英文名称为 Data Warehouse，可简写为 DW 或<br>DWH。数据仓库，是[为企业所有级别的决策制定过程]{.underline}，提供所有类型数据支持的战略集合。它出于分析性报告和决策支持目的而创建。为需要业务智能的企业，提供指导业务流程改进、监视时间、成本、质量以及控制。</p>\n<h2 id=\"11-2-数据仓库能干什么？\"><a href=\"#11-2-数据仓库能干什么？\" class=\"headerlink\" title=\"11.2 数据仓库能干什么？ \"></a><strong>11.2</strong> 数据仓库能干什么？ </h2><p>1）[年度销售目标的指定]{.underline}，需要[根据以往的历史报表进行决策]{.underline}，不能拍脑袋。</p>\n<p>2）如何[优化业务流程 ]{.underline}</p>\n<p>例如：一个电商网站订单的完成包括：浏览、下单、支付、物流，其中物流环节可能和中通、申通、韵达等快递公司合作。快递公司每派送一个订单，都会有订单派送的确认时间，可以根据订单派送时间来分析哪个快递公司比较快捷高效，从而选择与哪些快递公司合作，剔除哪些快递公司，增加用户友好型。</p>\n<h2 id=\"11-3-数据仓库的特点\"><a href=\"#11-3-数据仓库的特点\" class=\"headerlink\" title=\"11.3 数据仓库的特点 \"></a><strong>11.3</strong> 数据仓库的特点 </h2><p><strong>1</strong>）数据仓库的数据是面向主题的 <strong>分类</strong></p>\n<p>与传统数据库面向应用进行数据组织的特点相对应，数据仓库中的数据是面向主题进行组织的。什么是主题呢？首先，主题是一个抽象的概念，是较高层次上企业信息系统中的数据综合、归类并进行分析利用的抽象。在逻辑意义上，它是对应企业中某一宏观分析领域所涉及的分析对象。面向主题的数据组织方式，就是在较高层次上对分析对象的数据的一个完整、一致的描述，能完整、统一地刻划各个分析对象所涉及的企业的各项数据，以及数据之间的联系。所谓较高层次是相对面向应用的数据组织方式而言的，是指按照主题进行数据组织的方式具有更高的数据抽象级别。</p>\n<p><strong>2</strong>）数据仓库的数据是集成的</p>\n<p>数据仓库的数据是从原有的分散的数据库数据抽取来的。操作型数据与 DSS<br>分析型数据之间差别甚大。第一，数据仓库的每一个主题所对应的源数据在原有的各分散数据库中有许多重复和不一致的地方，且来源于不同的联机系统的数据都和不同的应用逻辑捆绑在一起；第二，数据仓库中的综合数据不能从原有的数据库系统直接得到。因此在数据进入数据仓库之前，必然要经过统一与综合，这一步是数据仓库建设中最关键、最复杂的一步，所要完成的工作有：</p>\n<p>（1）要统一源数据中所有矛盾之处，如字段的同名异义、异名同义、单位不统一、字长不一致等。</p>\n<p>（2）进行数据综合和计算。数据仓库中的数据综合工作可以在从原有数据库抽取数据时生成，但许多是在数据仓库内部生成的，即进入数据仓库以后进行综合生成的。</p>\n<p><strong>3</strong>）数据仓库的数据是不可更新的 <strong>清洗再分类，不删</strong></p>\n<p>数据仓库的数据主要供企业决策分析之用，所涉及的数据操作主要是数据查询，一般情况下并不进行修改操作。数据仓库的[数据反映的是一段相当长的时间内历史数据的内容，是不同时点的数据库快照的集合，以及基于这些快照进行统计、综合和重组的导出数据，而不是联机处理的数据。]{.underline}数据库中进行联机处理的数据经过集成输入到数据仓库中，</p>\n<p>一旦数据仓库存放的数据已经超过数据仓库的数据存储期限，这些数据将从当前的数据仓库中删去。因为数据仓库只进行数据查询操作，所以数据仓库管理系统相比数据库管理系统而言要简单得多。数据库管理系统中许多技术难点，如完整性保护、并发控制等等，在数据仓库的管理中几乎可以省去。但是由于数据仓库的查询数据量往往很大，所以就对数据查询提出了更高的要求，它要求采用各种复杂的索引技术；同时由于数据仓库面向的是商业企业的高层管理者，他们会对数据查询的[界面友好性和数据表示]{.underline}提出更高的要求。</p>\n<p><strong>4</strong>）数据仓库的数据是随时间不断变化的</p>\n<p>数据仓库中的数据不可更新是针对应用来说的，也就是说，数据仓库的用户进行分析处理时是不进行数据更新操作的。但并不是说，在从数据集成输入数据仓库开始到最终被删除的整个数据生存周期中，所有的数据仓库数据都是永远不变的。数据仓库的数据是随时间的变化而不断变化的，这是数据仓库数据的第四个特征。这一特征表现在以下<br>3 方面：</p>\n<p>（1）数据仓库随时间变化不断增加新的数据内容。数据仓库系统必须不断捕捉<br>OLTP数据库中变化的数据，追加到数据仓库中去，也就是要不断地生成 OLTP<br>数据库的快照，经统一集成后增加到数据仓库中去；但对于确实不再变化的数据库快照，如果捕捉到新的变化数据，则只生成一个新的数据库快照增加进去，而不会对原有的数据库快照进行修改。</p>\n<p>（2）数据仓库随时间变化不断删去旧的数据内容。数据仓库的数据也有存储期限，一旦超过了这一期限，过期数据就要被删除。只是数据仓库内的数据时限要远远长于操作型环境中的数据时限。在操作型环境中一般只保存有<br>60~90 天的数据，而在数据仓库中则需要保存较长时限的数据（如 [5~10<br>年]{.underline}），以适应 DSS 进行趋势分析的要求。</p>\n<p>（3）数据仓库中包含有大量的综合数据，这些综合数据中很多跟时间有关，如数据经常按照时间段进行综合，或隔一定的时间片进行抽样等等。这些数据要随着时间的变化不断地进行重新综合。因此，数据仓库的数据特征都包含时间项，以标明数据的历史时期。</p>\n<h2 id=\"11-4-数据仓库发展历程\"><a href=\"#11-4-数据仓库发展历程\" class=\"headerlink\" title=\"11.4 数据仓库发展历程 \"></a><strong>11.4</strong> 数据仓库发展历程 </h2><p>数据仓库的发展大致经历了这样的三个过程：</p>\n<p><strong>1</strong>）简单报表阶段：这个阶段，系统的主要目标是解决一些日常的工作中业务人员需要的报表，以及生成一些简单的能够帮助领导进行决策所需要的汇总数据。这个阶段的大部分表现形式为数据库和前端报表工具。</p>\n<p><strong>2</strong>）数据集市阶段：这个阶段，主要是根据某个业务部门的需要，进行一定的数据的采集，整理，按照业务人员的需要，进行多维报表的展现，能够提供对特定业务指导的数据，并且能够提供特定的领导决策数据。</p>\n<p><strong>3</strong>）数据仓库阶段：这个阶段，主要是按照一定的**[数据模型]{.underline}**，对整个企业的数据进行采集，整理，并且能够按照各个业务部门的需要，提供跨部门的，完全一致的业务报表数据，能够通过数据仓库生成对业务具有指导性的数据，同时，为领导决策提供全面的数据支持。通过数据仓库建设的发展阶段，我们能够看出，数据仓库的建设和数据集市的建设的重要区别就在于数据模型的支持。因此，数据模型的建设，对于我们数据仓库的建设，有着决定性的意义。</p>\n<h2 id=\"11-5-数据库与数据仓库的区别\"><a href=\"#11-5-数据库与数据仓库的区别\" class=\"headerlink\" title=\"11.5 数据库与数据仓库的区别 \"></a><strong>11.5</strong> 数据库与数据仓库的区别 </h2><p>了解数据库与数据仓库的区别之前，首先掌握三个概念。数据库软件、数据库、数据仓库。</p>\n<p>数据库软件：是一种软件，可以看得见，可以操作。用来实现数据库逻辑功能。属于物理层。</p>\n<p>数据库：是一种逻辑概念，用来存放数据的仓库。通过数据库软件来实现。数据库由很多表组成，表是二维的，一张表里可以有很多字段。字段一字排开，对应的数据就一行一行写入表中。数据库的表，在于能够用二维表现多维关系。目前市面上流行的数据库都是二维数据库。如：Oracle、DB2、MySQL、Sybase、MS<br>SQL Server 等。</p>\n<p>数据仓库：是数据库概念的升级。从逻辑上理解，数据库和数据仓库没有区别，都是通过数据库软件实现的存放数据的地方，只不过从数据量来说，数据仓库要比数据库更庞大得多。数据仓库主要用于数据挖掘和数据分析，辅助领导做决策。</p>\n<p>在 IT<br>的架构体系中，数据库是必须存在的。必须要有地方存放数据。比如现在的网购，淘宝，京东等等。物品的存货数量，货品的价格，用户的账户余额之类的。这些数据都是存放在后台数据库中。或者最简单理解，我们现在微博，QQ<br>等账户的用户名和密码。在后台数据库必然有一张 user<br>表，字段起码有两个，即用户名和密<br>码，然后我们的数据就一行一行的存在表上面。当我们登录的时候，我们填写了用户名和密码，这些数据就会被传回到后台去，去跟表上面的数据匹配，匹配成功了，你就能登录了。匹配不成功就会报错说密码错误或者没有此用户名等。这个就是数据库，数据库在生产环境就是用来干活的。凡是跟业务应用挂钩的，我们都使用数据库。</p>\n<p>数据仓库则是 BI<br>下的其中一种技术。由于数据库是跟业务应用挂钩的，所以一个数据库不可能装下一家公司的所有数据。数据库的表设计往往是针对某一个应用进行设计的。比如刚才那个登录的功能，这张<br>user<br>表上就只有这两个字段，没有别的字段了。但是这张表符合应用，没有问题。但是这张表不符合分析。比如我想知道在哪个时间段，用户登录的量最多？哪个用户一年购物最多？诸如此类的指标。那就要重新设计数据库的表结构了。对于数据分析和数据挖掘，我们引入数据仓库概念。数据仓库的表结构是依照分析需求，分析维度，分析指标进行设计的。</p>\n<p>数据库与数据仓库的区别实际讲的是 OLTP 与 OLAP 的区别。</p>\n<p>操作型处理，叫联机事务处理 OLTP（On-Line Transaction<br>Processing），也可以称面向交易的处理系统，它是针对具体业务在数据库联机的日常操作，通常对少数记录进行查询、修改。用户较为关心操作的响应时间、数据的安全性、完整性和并发支持的用户数等问题。</p>\n<p>传统的数据库系统作为数据管理的主要手段，主要用于操作型处理。</p>\n<p>分析型处理，叫联机分析处理 OLAP（On-Line Analytical<br>Processing）一般针对某些主题的历史数据进行分析，支持管理决策。</p>\n<p><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image29.png\">{width&#x3D;”6.5in”<br>height&#x3D;”4.897222222222222in”}</p>\n<h2 id=\"11-6-数据仓库架构分层\"><a href=\"#11-6-数据仓库架构分层\" class=\"headerlink\" title=\"11.6 数据仓库架构分层 \"></a><strong>11.6</strong> 数据仓库架构分层 </h2><h3 id=\"11-6-1-数据仓库架构\"><a href=\"#11-6-1-数据仓库架构\" class=\"headerlink\" title=\"11.6.1 数据仓库架构\"></a>11.6.1 <strong>数据仓库架构</strong></h3><p>数据仓库标准上可以分为四层：ODS（临时存储层）、PDW（数据仓库层）、DM（数<img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image30.png\">{width&#x3D;”4.263888888888889in”<br>height&#x3D;”2.611111111111111in”}据集市层）、APP（应用层）。</p>\n<p>1）ODS 层：</p>\n<p>为临时存储层，是接口数据的临时存储区域，为后一步的数据处理做准备。一般来说</p>\n<p>ODS<br>层的数据和源系统的数据是同构的，主要目的是简化后续数据加工处理的工作。从数</p>\n<p>据粒度上来说 ODS 层的数据粒度是最细的。ODS<br>层的表通常包括两类，一个用于存储当前需要加载的数据，一个用于存储处理完后的历史数据。历史数据一般保存<br>3-6<br>个月后需要清除，以节省空间。但不同的项目要区别对待，如果源系统的数据量不大，可以保留更长的时间，甚至全量保存；</p>\n<p>2）PDW 层：</p>\n<p>为数据仓库层，PDW<br>层的数据应该是一致的、准确的、干净的数据，即对源系统数据进行了清洗（去除了杂质）后的数据。这一层的数据一般是遵循数据库第三范式的，其数据粒度通常和<br>ODS 的粒度相同。在 PDW 层会保存 BI 系统中所有的历史数据，例如保存<br>10年的数据。</p>\n<p>3）DM 层：</p>\n<p>为数据集市层，这层数据是面向主题来组织数据的，通常是星形或雪花结构的数据。从</p>\n<p>数据粒度来说，这层的数据是轻度汇总级的数据，已经不存在明细数据了。从数据的时间跨度来说，通常是<br>PDW<br>层的一部分，主要的目的是为了满足用户分析的需求，而从分析的角度来说，用户通常只需要分析近几年（如近三年的数据）的即可。从数据的广度来说，仍然覆盖了所有业务数据。</p>\n<p>4）APP 层：</p>\n<p>为应用层，这层数据是完全为了满足具体的分析需求而构建的数据，也是星形或雪花结构的数据。从数据粒度来说是高度汇总的数据。从数据的广度来说，则并不一定会覆盖所有业务数据，而是<br>DM 层数据的一个真子集，从某种意义上来说是 DM<br>层数据的一个重复。从极端情况来说，可以为每一张报表在 APP<br>层构建一个模型来支持，达到以空间换时间的目的。</p>\n<p>数据仓库的标准分层只是一个建议性质的标准，实际实施时需要根据实际情况确定数据仓库的分层，不同类型的数据也可能采取不同的分层方法。</p>\n<h3 id=\"11-6-2-为什么要对数据仓库分层？\"><a href=\"#11-6-2-为什么要对数据仓库分层？\" class=\"headerlink\" title=\"11.6.2 为什么要对数据仓库分层？\"></a><strong>11.6.2</strong> 为什么要对数据仓库分层？</h3><p>1）用空间换时间，通过大量的预处理来提升应用系统的用户体验（效率），因此数据</p>\n<p>仓库会存在大量冗余的数据。</p>\n<p>2）如果不分层的话，如果源业务系统的业务规则发生变化将会影响整个数据清洗过程，</p>\n<p>工作量巨大。</p>\n<p>3）通过数据分层管理可以简化数据清洗的过程，因为把原来一步的工作分到了多个步骤去完成，相当于把一个复杂的工作拆成了多个简单的工作，把一个大的黑盒变成了一个白盒，每一层的处理逻辑都相对简单和容易理解，这样我们比较容易保证每一个步骤的正确性，当数据发生错误的时候，往往我们只需要局部调整某个步骤即可。</p>\n<h2 id=\"11-7-元数据介绍\"><a href=\"#11-7-元数据介绍\" class=\"headerlink\" title=\"11.7 元数据介绍 \"></a>11.7 <strong>元数据介绍</strong> </h2><p>当需要了解某地企业及其提供的服务时，电话黄页的重要性就体现出来了。元数据（Metadata）类似于这样的电话黄页。</p>\n<ol>\n<li>元数据的定义</li>\n</ol>\n<p>数据仓库的元数据是关于数据仓库中数据的数据。</p>\n<p>它的作用类似于数据库管理系统的数据字典，保存了逻辑数据结构、文件、地址和索引等信息。广义上讲，在数据仓库中，元数据描述了数据仓库内数据的结构和建立方法的数据。<br>元数据是数据仓库管理系统的重要组成部分，元数据管理器是企业级数据仓库中的关键组件，贯穿数据仓库构建的整个过程，直接影响着数据仓库的构建、使用和维护。</p>\n<p>（1）构建数据仓库的主要步骤之一是<br>ETL。这时元数据将发挥重要的作用，它定义了源数据系统到数据仓库的映射、数据转换的规则、数据仓库的逻辑结构、数据更新的规则、</p>\n<p>数据导入历史记录以及装载周期等相关内容。数据抽取和转换的专家以及数据仓库管理员正是通过元数据高效地构建数据仓库。</p>\n<p>（2）用户在使用数据仓库时，通过元数据访问数据，明确数据项的含义以及定制报表。</p>\n<p>（3）数据仓库的规模及其复杂性离不开[正确的元数据管理]{.underline}，包括增加或移除外部数据</p>\n<p>源，改变数据清洗方法，控制出错的查询以及安排备份等。</p>\n<p>元数据可分为技术元数据和业务元数据。</p>\n<p>技术元数据为开发和管理数据仓库的 IT<br>人员使用，它描述了与数据仓库开发、管理和维护相关的数据，包括数据源信息、数据转换描述、数据仓库模型、数据清洗与更新规则、数据映射和访问权限等。</p>\n<p>而业务元数据为管理层和业务分析人员服务，从业务角度描述数据，包括商务术语、数据仓库中有什么数据、数据的位置和数据的可用性等，帮助业务人员更好地理解数据仓库中哪些数据是可用的以及如何使用。</p>\n<p>由上可见，元数据不仅定义了数据仓库中数据的模式、来源、抽取和转换规则等，而且是整个[数据仓库系统运行的基础]{.underline}，元数据把数据仓库系统中[各个松散的组件联系]{.underline}起来，组成<img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image31.jpeg\">{width&#x3D;”4.618055555555555in”<br>height&#x3D;”2.9270833333333335in”}了一个有机的整体，如图所示</p>\n<p>2）元数据的存储方式</p>\n<p>元数据有两种常见存储方式：一种是以数据集为基础，每一个数据集有对应的元数据文件，每一个元数据文件包含对应数据集的元数据内容；另一种存储方式是以数据库为基础，即元数据库。其中元数据文件由若干项组成，每一项表示元数据的一个要素，每条记录为数据集的元数据内容。</p>\n<p>上述存储方式各有优缺点，</p>\n<p>第一种存储方式的优点是调用数据时相应的元数据也作为一个独立的文件被传输，相对数据库有较强的独立性，在对元数据进行检索时可以利用数据库的功能实现，也可以把元数据文件调到其他数据库系统中操作；不足是如果每一数据集都对应一个元数据文档，在规模巨大的数据库中则会有大量的元数据文件，管理不方便。</p>\n<p>第二种存储方式下，元数据库中只有一个元数据文件，管理比较方便，添加或删除数据集，只要在该文件中添加或删除相应的记录项即可。在[获取某数据集的元数据时，因为实际得到的只是关系表格数据的一条记录，所以要求用户系统可以接受这种特定形式的数据]{.underline}。因此**[推荐]{.underline}**使用元数据库的方式。<br>元数据库用于[存储]{.underline}元数据，因此元数据库最好选用主流的关系数据库管理系统。元数据库还包含用于操作和查询元数据的机制。建立元数据库的主要好处是提供统一的数据结构和业务规则，易于把企业内部的多个数据集市有机地集成起来。目前，一些企业倾向建立多个数据集市，而不是一个集中的数据仓库，这时可以考虑在建立数据仓库（或数据集市）之前，先建立一个用于描述数据、服务应用集成的元数据库，做好数据仓库实施的初期支持工作，对后续开发和维护有很大的帮助。元数据库保证了数据仓库数据的一致性和准确性，为企业进行数据质量管理提供基础。</p>\n<p>3）元数据的作用</p>\n<p>在数据仓库中，元数据的主要作用如下。</p>\n<p>（1）描述哪些数据在数据仓库中，帮助决策分析者对数据仓库的内容定位。</p>\n<p>（2）定义数据进入数据仓库的方式，作为[数据汇总、映射和清洗的指南。<br>]{.underline}</p>\n<p>（3）记录[业务事件发生而随之进行]{.underline}的[数据抽取工作时间安排]{.underline}。</p>\n<p>（4）记录并检测系统数据一致性的要求和执行情况。</p>\n<p>（5）评估数据质量。</p>\n<h2 id=\"11-8-星型模型和雪花模型\"><a href=\"#11-8-星型模型和雪花模型\" class=\"headerlink\" title=\"11.8 星型模型和雪花模型 \"></a><strong>11.8</strong> 星型模型和雪花模型 </h2><p>在多维分析的商业智能解决方案中，根据事实表和维度表的关系，又可将常见的模型分为星型模型和雪花型模型。在设计逻辑型数据的模型的时候，就应考虑数据是按照星型模型还是雪花型模型进行组织。</p>\n<h3 id=\"11-8-1-星型模型\"><a href=\"#11-8-1-星型模型\" class=\"headerlink\" title=\"11.8.1 星型模型\"></a>11.8.1 <strong>星型模型</strong></h3><p>当所有维表都直接连接到”<br>事实表”上时，整个图解就像星星一样，故将该模型称为星型模型。</p>\n<p><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image32.png\">{width&#x3D;”6.5in”<br>height&#x3D;”3.582638888888889in”}星型架构是一种非正规化的结构，多维数据集的每一个维度都直接与事实表相连接，不存在渐变维度，所以数据有一定的冗余，如在地域维度表中，存在国家A省B的城市C以及国家<br>A 省 B 的城市 D 两条记录，那么[国家 A 和省 B<br>的信息分别存储了两次，即存在冗余。]{.underline}</p>\n<h3 id=\"11-8-2-雪花模型\"><a href=\"#11-8-2-雪花模型\" class=\"headerlink\" title=\"11.8.2 雪花模型\"></a>11.8.2 <strong>雪花模型</strong></h3><p>当有一个或多个维表没有直接连接到事实表上，而是通过其他维表连接到事实表上时，其图解就像多个雪花连接在一起，故称雪花模型。雪花模型是对星型模型的扩展。它对星型模型的维表进一步层次化，原有的各维表可能被扩展为小的事实表，形成一些局部的&quot;<br>层次&quot;<br>区域，这些被分解的表都连接到主维度表而不是事实表。如图所示，将地域维表又分解为国家，省份，城市等维表。它的优点是：通过最大限度地<strong>减少数据存储量</strong>以及<strong>联合较小的维表</strong>来改善查询性能。雪花型结构去除了数据冗余。</p>\n<p><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image33.png\">{width&#x3D;”6.5in”<br>height&#x3D;”3.3270833333333334in”}</p>\n<p>星型模型因为数据的冗余所以很多统计查询不需要做外部的连接，因此一般情况下效率比雪花型模型要高。星型结构不用考虑很多正规化的因素，设计与实现都比较简单。雪花型模型由于去除了冗余，有些统计就需要通过表的联接才能产生，所以效率不一定有星型模型高。正规化也是一种比较复杂的过程，相应的数据库结构设计、数据的<br>ETL、以及后期的维护都要复杂一些。</p>\n<p>因此在<strong>冗余可以接受</strong>的前提下，实际运用中<strong>星型</strong>模型使用更多，也更有效率。</p>\n<h3 id=\"11-8-3-星型模型和雪花模型对比\"><a href=\"#11-8-3-星型模型和雪花模型对比\" class=\"headerlink\" title=\"11.8.3 星型模型和雪花模型对比\"></a><strong>11.8.3</strong> 星型模型和雪花模型对比</h3><p>星形模型和雪花模型是数据仓库中常用到的两种方式，而它们之间的对比要从四个角度来进行讨论。</p>\n<p><strong>1</strong>）数据优化</p>\n<p>雪花模型使用的是规范化数据，也就是说数据在数据库内部是组织好的，以便消除冗余，因此它能够有效地减少数据量。通过引用完整性，其业务层级和维度都将存储在数据模型之中。</p>\n<p><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image34.jpeg\">{width&#x3D;”7.094444444444444in”<br>height&#x3D;”1.5833333333333333in”}</p>\n<p>雪花模型</p>\n<p>相比较而言，星形模型使用的是反规范化数据。在星形模型中，维度直接指的是事实<img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image35.jpeg\">{width&#x3D;”4.426388888888889in”<br>height&#x3D;”1.2555555555555555in”}表，业务层级不会通过维度之间的参照完整性来部署。</p>\n<p>星形模型</p>\n<p><strong>2</strong>）业务模型</p>\n<p>主键是一个单独的唯一键(数据属性)，为特殊数据所选择。在上面的例子中，Advertiser_ID<br>就将是一个主键。外键(参考属性)仅仅是一个表中的字段，用来匹配其他维度表中的主键。在我们所引用的例子中，Advertiser_ID<br>将是 Account_dimension 的一个外键。<br>在雪花模型中，数据模型的业务层级是由一个不同维度表主键-外键的关系来代表的。而在星形模型中，所有必要的维度表在事实表中都只拥有外键。</p>\n<p><strong>3</strong>）性能</p>\n<p>第三个区别在于性能的不同。雪花模型在维度表、事实表之间的连接很多，因此性能方面会比较低。举个例子，如果你想要知道<br>Advertiser 的详细信息，雪花模型就会请求许多信息，比如 Advertiser<br>Name、ID<br>以及那些广告主和客户表的地址需要连接起来，然后再与事实表连接。而星形模型的连接就少的多，在这个模型中，如果你需要上述信息，你只要将<br>Advertiser的维度表和事实表连接即可。</p>\n<p><strong>4</strong>）<strong>ETL</strong></p>\n<p>雪花模型加载数据集市，因此 ETL<br>操作在设计上更加复杂，而且由于附属模型的限制，不能并行化。<br>星形模型加载维度表，不需要在维度之间添加附属模型，因此 ETL<br>就相对简单，而且可以实现高度的并行化。</p>\n<p>总结</p>\n<p>雪花模型使得维度分析（多维、复杂关系）更加容易，比如”针对特定的广告主，有哪些客户或者公司是在线的?”星形模型用来做指标分析（单维）更适合，比如”给定的一个客户他们的收入是多少?”</p>\n<h1 id=\"Hive项目-Youtube-TopN查询\"><a href=\"#Hive项目-Youtube-TopN查询\" class=\"headerlink\" title=\"Hive项目: Youtube_TopN查询\"></a>Hive项目: Youtube_TopN查询</h1><h2 id=\"一、需求描述\"><a href=\"#一、需求描述\" class=\"headerlink\" title=\"一、需求描述 \"></a>一、需求描述 </h2><p>统计Youtube视频网站的常规指标，各种TopN指标：</p>\n<p>--统计视频观看数Top10</p>\n<p>--统计视频类别热度Top10</p>\n<p>--统计视频观看数Top20所属类别包含这Top20视频的个数</p>\n<p>--统计视频观看数Top50所关联视频的所属类别Rank</p>\n<p>--统计每个类别中的视频热度Top10</p>\n<p>--统计每个类别中视频流量Top10</p>\n<p>--统计上传视频最多的用户Top10以及他们上传的视频</p>\n<p>--统计每个类别视频观看数Top10</p>\n<h2 id=\"二、知识储备梳理\"><a href=\"#二、知识储备梳理\" class=\"headerlink\" title=\"二、知识储备梳理\"></a>二、知识储备梳理</h2><h3 id=\"2-1-UDAF行转列\"><a href=\"#2-1-UDAF行转列\" class=\"headerlink\" title=\"2.1 UDAF行转列\"></a>2.1 UDAF行转列</h3><p>行转列</p>\n<p>MySQL：group_concat</p>\n<p>虚拟机设置：处理器：虚拟化引擎：选中”虚拟化Intel VT-x&#x2F;EPT或AMD-V&#x2F;RVI(V)”</p>\n<p>能加快集群运行速度</p>\n<p>启动hadoop</p>\n<p>hive</p>\n<p>找不到metastore</p>\n<p>root</p>\n<p>centos6: service mysqld restart</p>\n<p>centos7: systemctl restart mysqld.service</p>\n<p>.tsv &#x2F;t分割 excel可以直接可以打开</p>\n<p>.csv ,分割</p>\n<p>把星座和血型一样的人归类到一起</p>\n<p>select</p>\n<p>t1.base,</p>\n<p>concat_ws(&#39;|&#39;, collect_set(t1.name)) name</p>\n<p>from</p>\n<p>(select</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>name,</p>\n<p>concat(constellation, &quot;,&quot;, blood_type) base</p></blockquote>\n<p>from</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>person_info) t1</p></blockquote>\n<p>group by</p>\n<p>t1.base;</p>\n<p>白羊座，A 猪八戒|孙悟空</p>\n<p>聚合函数 concat_ws(&#39;|&#39;, collect_set(column1)) name</p>\n<p>select</p>\n<p>条件列</p>\n<p>concat_ws(&#39;|&#39;, collect_set(别的列)) 别名</p>\n<p>from</p>\n<p>…</p>\n<p>Group by</p>\n<p>条件列</p>\n<h4 id=\"见Hive7-2：\"><a href=\"#见Hive7-2：\" class=\"headerlink\" title=\"见Hive7.2：\"></a>见Hive7.2：</h4><p>当 Hive<br>提供的内置函数无法满足你的业务处理需要时，此时就可以考虑使用用户自定义函数（UDF：user-defined<br>function）。</p>\n<p>3）根据用户自定义函数类别分为以下三种：</p>\n<p>（1）UDF（User-Defined-Function）</p>\n<p>一进一出</p>\n<p>（2）UDAF（User-Defined Aggregation Function） collect_set</p>\n<p>聚集函数，多进一出 处理多列</p>\n<p>类似于：count&#x2F;max&#x2F;min</p>\n<p>（3）UDTF（User-Defined Table-Generating Functions）</p>\n<p>一进多出</p>\n<p>如 lateral view explore()</p>\n<p>4）官方文档地址</p>\n<p><a href=\"https://cwiki.apache.org/confluence/display/Hive/HivePlugins\">https://cwiki.apache.org/confluence/display/Hive/HivePlugins</a></p>\n<p>5）编程步骤：</p>\n<p>（1）继承 org.apache.hadoop.hive.ql.UDF</p>\n<p>（2）需要实现 evaluate 函数；evaluate 函数支持重载；</p>\n<p>（3）在 hive 的命令行窗口创建函数</p>\n<p>a）添加 jar</p>\n<p>add jar linux_jar_path</p>\n<p>b）创建 function， 永久函数注册进MySQL元数据信息里</p>\n<p>create [temporary] function [dbname.]function_name AS<br>class_name;jar包全类名</p>\n<p>（4）在 hive 的命令行窗口删除函数</p>\n<p>Drop [temporary] function [if exists] [dbname.]function_name;</p>\n<p>6）注意事项</p>\n<p>（1）UDF 必须要有返回类型，可以返回 null，但是返回类型不能为 void；</p>\n<p><strong>7.3</strong> 自定义 <strong>UDF</strong> 函数开发案例</p>\n<p>1）创建一个 java 工程，并创建一个 lib 文件夹</p>\n<p>2）将 hive 的 jar 包解压后，将 apache-hive-1.2.1-bin\\lib 文件下的 jar<br>包都拷贝到 java 工程中。</p>\n<p>3）创建一个类</p>\n<p>package com.atguigu.hive;</p>\n<p>import org.apache.hadoop.hive.ql.exec.UDF;</p>\n<p>public class Lower extends UDF {</p>\n<p>public String evaluate (final String s) {</p>\n<p>if (s &#x3D;&#x3D; null) {</p>\n<p>return null;</p>\n<p>}</p>\n<p>return s.toString().toLowerCase();</p>\n<p>}</p>\n<p><strong>}</strong></p>\n<p>4）打成 jar 包上传到服务器&#x2F;opt&#x2F;module&#x2F;jars&#x2F;udf.jar</p>\n<p>5）将 jar 包添加到 hive 的 classpath</p>\n<p>hive (default)&gt; add jar &#x2F;opt&#x2F;module&#x2F;datas&#x2F;udf.jar;</p>\n<p>6）创建临时函数与开发好的 java class 关联</p>\n<p>hive (default)&gt; create temporary function <strong>my_lower</strong> as<br>&quot;com.atguigu.hive.Lower&quot;;</p>\n<p>7）即可在 hql 中使用自定义的函数 strip</p>\n<p>hive (default)&gt; select ename, <strong>my_lower(<strong>ename</strong>)</strong> lowername from<br>emp;</p>\n<h3 id=\"2-2-UDTF列转行\"><a href=\"#2-2-UDTF列转行\" class=\"headerlink\" title=\"2.2 UDTF列转行\"></a>2.2 UDTF列转行</h3><p><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image36.png\">{width&#x3D;”5.768055555555556in”<br>height&#x3D;”1.2277777777777779in”}</p>\n<p>create table movie_info(</p>\n<p>movie string,</p>\n<p>category array&lt;string&gt;)</p>\n<p>row format delimited fields terminated by &quot;\\t&quot;</p>\n<p>collection items terminated by &quot;,&quot;;</p>\n<p>load data local inpath &quot;movie_info.tsv&quot; into table movie_info;</p>\n<p>将电影分类中的数组数据展开</p>\n<p>select</p>\n<p>movie,</p>\n<p>category_name</p>\n<p>from</p>\n<p>movie_info lateral view explode(category) table_tmp as category_name;</p>\n<p>lateral侧写</p>\n<p>UDTF：explode(array&lt;&gt;)</p>\n<p>Table1 lateral view explode(column1 array&lt;&gt;) table2 as column2</p>\n<h3 id=\"2-3、数组操作\"><a href=\"#2-3、数组操作\" class=\"headerlink\" title=\"2.3、数组操作\"></a>2.3、数组操作</h3><p>“fields terminated by”：字段与字段之间的分隔符。</p>\n<p>“collection items terminated by”：一个字段中各个子元素item的分隔符。</p>\n<p>行存储转列存储转的是元数据 建索引</p>\n<h3 id=\"2-5、Hive分桶\"><a href=\"#2-5、Hive分桶\" class=\"headerlink\" title=\"2.5、Hive分桶\"></a>2.5、Hive分桶</h3><p>分区New dir&#x2F;file namenode增大</p>\n<p>Hive可以将表或者表的分区进一步组织成桶，以达到：</p>\n<p>1、数据取样效率更高</p>\n<p>2、数据处理效率更高</p>\n<p>桶通过对指定列进行哈希来实现，将一个列名下的数据切分为”一组桶”，每个桶都对应了一个该列名下的一个存储文件。</p>\n<h4 id=\"2-5-1、直接分桶\"><a href=\"#2-5-1、直接分桶\" class=\"headerlink\" title=\"2.5.1、直接分桶\"></a>2.5.1、直接分桶</h4><p>开始操作之前，需要将hive.enforce.bucketing属性设置为true，以标识Hive可以识别桶。</p>\n<p>create table music(</p>\n<p>id int,</p>\n<p>name string,</p>\n<p>size float)</p>\n<p>row format delimited</p>\n<p>fields terminated by &quot;\\t&quot;</p>\n<p>clustered by (id) into 4 buckets;</p>\n<p>将music表按照id将数据分成了4个桶，插入数据时，会对应4个reduce操作，输出4个文件。</p>\n<p>Id.hash%4</p>\n<p>Hashcode:hash+equal</p>\n<p>Set Map.key array index+datatype ???????????????????</p>\n<h4 id=\"2-5-2、在分区中分桶\"><a href=\"#2-5-2、在分区中分桶\" class=\"headerlink\" title=\"2.5.2、在分区中分桶\"></a>2.5.2、在分区中分桶</h4><p>当数据量过大，需要庞大分区数量时，可以考虑桶，因为分区数量太大的情况可能会导致文件系统挂掉，而且桶比分区有更高的查询效率。数据最终落在哪一个桶里，取决于clustered<br>by的那个列的值的hash数与桶的个数求余来决定。虽然有一定离散性，但不能保证每个桶中的数据量是一样的。</p>\n<p>create table music2(</p>\n<p>id int,</p>\n<p>name string,</p>\n<p>size float)</p>\n<p>partitioned by (date string)</p>\n<p>clustered by (id) sorted by(size) into 4 bucket</p>\n<p>row format delimited 两句话！！！！！！</p>\n<p>fields terminated by &quot;\\t&quot;;</p>\n<p>load data local inpath &#39;demo&#x2F;music.txt&#39; into table music2<br>partition(date&#x3D;&#39;2017-08-30&#39;);</p>\n<h3 id=\"3-6、业务分析\"><a href=\"#3-6、业务分析\" class=\"headerlink\" title=\"3.6、业务分析\"></a><strong>3.6</strong>、业务分析</h3><h4 id=\"3-6-4、统计视频观看数-Top50-所关联视频的所属类别的热度排名（最难）\"><a href=\"#3-6-4、统计视频观看数-Top50-所关联视频的所属类别的热度排名（最难）\" class=\"headerlink\" title=\"3.6.4、统计视频观看数 Top50 所关联视频的所属类别的热度排名（最难）\"></a><strong>3.6.4</strong>、统计视频观看数 <strong>Top50</strong> 所关联视频的所属类别的热度排名（最难）</h4><p>思路：</p>\n<p>1) 查询出观看数最多的前 50<br>个视频的所有信息(当然包含了每个视频对应的关联视频)，记</p>\n<p>为临时表 t1</p>\n<p>t1:观看数前 50 的视频</p>\n<p>select</p>\n<p>* relatedId</p>\n<p>from</p>\n<p>youtube_orc</p>\n<p>order by</p>\n<p>views</p>\n<p>desc</p>\n<p>limit 50;</p>\n<p>2) 将找到的 50 条视频信息的相关视频 relatedId 列转行，记为临时表 t2</p>\n<p>t2:将相关视频的 id 进行列转行操作</p>\n<p>select</p>\n<p>explode(relatedId) as videoId</p>\n<p>from t1;</p>\n<p>3) 将相关视频的 id 和 youtube_orc 表进行 inner join 操作</p>\n<p>t5:得到两列数据，一列是 category，一列是之前查询出来的相关视频 id</p>\n<p>(select</p>\n<p>distinct(t2.videoId),</p>\n<p>t3.category</p>\n<p>from</p>\n<p>t2 inner join youtube_<strong>orc t3</strong> on t2.videoId &#x3D; t3.videoId)</p>\n<p>t4 lateral view explode(category) t_catetory as <strong>category_name;</strong></p>\n<p>4) 按照视频类别进行分组，统计(类别热度:)每组视频个数，然后排行</p>\n<p>最终代码：</p>\n<p>select <strong>category_name</strong> as category, count(t5.videoId) as hot</p>\n<p>from (</p>\n<p>select videoId, category_name</p>\n<p>from (</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>select distinct(t2.videoId), t3.category</p>\n<p>from (</p>\n<p>select <strong>explode(relatedId)</strong> as videoId</p>\n<p>from ( select * relatedId from youtube_orc order by views desc limit<br>50) t1</p>\n<p>) t2 inner join youtube_orc t3 on t2.videoId &#x3D; t3.videoId</p></blockquote>\n<p>) t4 lateral view <strong>explode(category)</strong> t_category as category_name</p>\n<p>) t5</p>\n<p>group by category_name</p>\n<p>order by hot desc;</p>\n<h1 id=\"Sqoop\"><a href=\"#Sqoop\" class=\"headerlink\" title=\"Sqoop\"></a>Sqoop</h1><h2 id=\"一、Sqoop-简介\"><a href=\"#一、Sqoop-简介\" class=\"headerlink\" title=\"一、Sqoop 简介 \"></a><strong>一、</strong>Sqoop <strong>简介</strong> </h2><p>Apache Sqoop(TM)是一种旨在有效地在 Apache Hadoop<br>和诸如关系数据库等结构化数据存</p>\n<p>储之间传输大量数据的工具。</p>\n<p>Sqoop 于 2012 年 3 月孵化出来，现在是一个顶级的 Apache 项目。</p>\n<p>最新的稳定版本是 1.4.6。Sqoop2 的最新版本是 1.99.7。请注意，1.99.7 与<br>1.4.6 不兼容，且没有特征不完整，它并不打算用于生产部署。</p>\n<h2 id=\"二、Sqoop-原理\"><a href=\"#二、Sqoop-原理\" class=\"headerlink\" title=\"二、Sqoop 原理 \"></a><strong>二、</strong>Sqoop <strong>原理</strong> </h2><p>将导入或导出命令翻译成 mapreduce 程序来实现。</p>\n<p>在翻译出的 mapreduce 中主要是对 inputformat 和 outputformat 进行定制。</p>\n<h1 id=\"Flume\"><a href=\"#Flume\" class=\"headerlink\" title=\"Flume\"></a>Flume</h1><h2 id=\"一、Flume-简介\"><a href=\"#一、Flume-简介\" class=\"headerlink\" title=\"一、Flume 简介 \"></a><strong>一、</strong>Flume <strong>简介</strong> </h2><p>1) Flume<br>提供一个[分布式的，可靠的]{.underline}，对[大数据量的日志进行高效收集、聚集、移动]{.underline}的服务，Flume<br>只能在 Unix 环境下运行。</p>\n<p>2) Flume 基于流式架构，容错性强，也很灵活简单。</p>\n<p>3) Flume、Kafka 用来实时进行数据收集，Spark、Storm<br>用来实时处理数据，impala 用来实时查询。</p>\n<p>data传输效率70M&#x2F;s以下，data请求次数25w-50w QPS以内可靠，or大量丢包<br>改源码定制</p>\n<p>实时抽取本地磁盘数据，传到HDFS</p>\n<p>内存数据写入kafka集群（端口），分发到HDFS</p>\n<p>过程中.tmp</p>\n<p>后数据分析：Spark（在线），MR，Hive（离线）</p>\n<p>result--&gt;hbase,RDBMS</p>\n<p>Flume不擅长处理单个大文件channel.capacity（几十G蓝光电影…），而擅长处理大量小文件。</p>\n<h2 id=\"二、Flume-角色\"><a href=\"#二、Flume-角色\" class=\"headerlink\" title=\"二、Flume 角色 \"></a><strong>二、</strong>Flume <strong>角色</strong> </h2><p><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image37.png\">{width&#x3D;”4.311321084864392in”<br>height&#x3D;”1.6793886701662293in”}</p>\n<p>一个agent是一个flume job的实例化，一个JVM进程。</p>\n<h3 id=\"2-1、Source\"><a href=\"#2-1、Source\" class=\"headerlink\" title=\"2.1、Source\"></a>2.1<strong>、</strong>Source</h3><p>用于采集数据，Source 是产生数据流的地方，同时 Source<br>会将产生的数据流传输到 Channel，</p>\n<p>这个有点类似于 Java IO 部分的 Channel。</p>\n<h3 id=\"2-2、Channel\"><a href=\"#2-2、Channel\" class=\"headerlink\" title=\"2.2、Channel\"></a>2.2<strong>、</strong>Channel</h3><p>用于桥接 Sources 和 Sinks，类似于一个队列。 Memory 快，大点（会GC）&#x2F;File</p>\n<h3 id=\"2-3、Sink\"><a href=\"#2-3、Sink\" class=\"headerlink\" title=\"2.3、Sink\"></a>2.3<strong>、</strong>Sink</h3><p>从 Channel 收集数据，将数据写到目标源(可以是下一个 Source，也可以是 HDFS<br>或者 HBase)。 复制+分发+LB（1--&gt; 多）</p>\n<h3 id=\"2-4、Event\"><a href=\"#2-4、Event\" class=\"headerlink\" title=\"2.4、Event\"></a>2.4<strong>、</strong>Event</h3><p>传输单元，Flume 数据传输的基本单元，以事件的形式将数据从源头送至目的地。</p>\n<h2 id=\"业务模型：\"><a href=\"#业务模型：\" class=\"headerlink\" title=\"业务模型：\"></a>业务模型：</h2><p>Setting multi-agent flow</p>\n<p>Consolidation</p>\n<p><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image38.png\">{width&#x3D;”6.5in”<br>height&#x3D;”4.465972222222222in”}</p>\n<p>场景：适合同一业务不同机器，同样的数据结构的文件</p>\n<p>Multiplexing the flow</p>\n<p><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image39.png\">{width&#x3D;”5.632075678040245in”<br>height&#x3D;”3.4598753280839896in”}</p>\n<p>Channel:Sink&#x3D;1:1</p>\n<p>场景：data实时运算，存到HDFS备份ori，+（Flume）+Kafka+Spark只存结果。之后离线校验ori。</p>\n<h2 id=\"三、Flume-传输过程\"><a href=\"#三、Flume-传输过程\" class=\"headerlink\" title=\"三、Flume 传输过程 \"></a><strong>三、</strong>Flume <strong>传输过程</strong> </h2><p>source<br>监控某个文件或数据流，数据源产生新的数据，拿到该数据后，将数据封装在一个Event<br>中，并 put 到 channel 后 commit 提交，channel 队列先进先出，sink 去<br>channel 队列中拉取数据，然后写入到 HDFS 中。</p>\n<p><strong>4.2.2</strong>、案例二：实时读取本地文件到 <strong>HDFS</strong></p>\n<p><strong>4.2.4</strong>、案例四：<strong>Flume</strong> 与 <strong>Flume</strong> 之间数据传递：单 <strong>Flume</strong> 多<br><strong>Channel</strong>、<strong>Sink</strong>，</p>\n<p><strong>4.2.5</strong>、案例五：<strong>Flume</strong> 与 <strong>Flume</strong> 之间数据传递，多 <strong>Flume</strong><br>汇总数据<strong>到单</strong> Flume</p>\n<h2 id=\"Flume-监控之-Ganglia\"><a href=\"#Flume-监控之-Ganglia\" class=\"headerlink\" title=\"Flume 监控之 Ganglia \"></a>Flume <strong>监控之</strong> Ganglia </h2><h1 id=\"Kafka\"><a href=\"#Kafka\" class=\"headerlink\" title=\"Kafka\"></a>Kafka</h1><h2 id=\"一-Kafka概述\"><a href=\"#一-Kafka概述\" class=\"headerlink\" title=\"一 Kafka概述\"></a>一 Kafka概述</h2><h3 id=\"1-1-Kafka是什么\"><a href=\"#1-1-Kafka是什么\" class=\"headerlink\" title=\"1.1 Kafka是什么\"></a>1.1 Kafka是什么</h3><p>在流式计算中，Kafka一般用来缓存数据，Storm通过消费Kafka的数据进行计算。</p>\n<p>1）Apache<br>Kafka是一个开源<strong>消息</strong>系统，由Scala写成。是由Apache软件基金会开发的一个开源消息系统项目。</p>\n<p>2）Kafka最初是由LinkedIn公司开发，并于 2011年初开源。2012年10月从Apache<br>Incubator毕业。该项目的目标是为处理实时数据提供一个统一、高通量、低等待的平台。</p>\n<p>3）<strong>Kafka是一个分布式消息队列。</strong>Kafka对消息保存时[根据Topic进行归类]{.underline}，发送消息者称为Producer，消息接受者称为Consumer，此外kafka集群由多个kafka实例组成，每个实例(server)称为broker。</p>\n<p>4）无论是kafka集群，还是producer和consumer都依赖于[<strong>zookeeper</strong>集群(3~5台，统一化目录结构&#x3D;&#x3D;百度网盘，大量网络IO，need开网络监控)]{.underline}保存一些[meta信息]{.underline}，来保证系统可用性。</p>\n<h3 id=\"1-2-消息队列内部实现原理\"><a href=\"#1-2-消息队列内部实现原理\" class=\"headerlink\" title=\"1.2 消息队列内部实现原理\"></a>1.2 消息队列内部实现原理</h3><p>（1）点对点模式（一对一，消费者主动拉取数据，消息收到后消息清除）</p>\n<p>点对点模型通常是一个基于pull[拉取或者轮询poll]{.underline}的消息传送模型，这种模型从队列中请求信息，而不是将消息推送到客户端。这个模型的特点是发送到队列的消息被一个且只有一个接收者接收处理，即使有多个消息监听者也是如此。</p>\n<p>（2）发布&#x2F;订阅模式（一对多，数据生产后，推送给所有订阅者）</p>\n<p>发布订阅模型则是一个基于推送push的消息传送模型。发布订阅模型可以有[多种不同<strong>topic</strong>]{.underline}的订阅者，<strong>临时</strong>订阅者只在主动<strong>监听</strong>主题时才接收消息，而<strong>持久</strong>订阅者则监听主题的所有消息，即使当前订阅者不可用，处于离线状态。</p>\n<h3 id=\"1-3-为什么需要消息队列\"><a href=\"#1-3-为什么需要消息队列\" class=\"headerlink\" title=\"1.3 为什么需要消息队列\"></a>1.3 为什么需要消息队列</h3><p>1）解耦：</p>\n<p>　　允许你独立的扩展或修改定制两边的处理过程，只要确保它们遵守同样的接口约束。</p>\n<p>2）冗余：</p>\n<p>消息队列把数据进行持久化直到它们已经被完全处理，通过这一方式[规避了数据丢失风险]{.underline}。许多消息队列所采用的&quot;插入-获取-删除&quot;范式中，在把一个消息从队列中删除之前，需要你的处理系统明确的指出该消息已经被处理完毕，从而确保你的数据被安全的保存直到你使用完毕。</p>\n<p>3）扩展性：</p>\n<p>因为消息队列解耦了你的处理过程，所以增大消息入队和处理的频率是很容易的，只要另外增加处理过程即可。</p>\n<p>4）灵活性 &amp; 峰值处理能力：</p>\n<p>在访问量剧增的情况下，应用仍然需要继续发挥作用，但是[这样的突发流量并不常见。如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费]{.underline}。使用消息队列能够[使关键组件顶住突发的访问压力]{.underline}，而[不会因为突发的超负荷的请求而完全崩溃]{.underline}。Buffer</p>\n<p>5）可恢复性：</p>\n<p>系统的一部分组件失效时，[不会影响到整个系统]{.underline}。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。</p>\n<p>6）顺序保证：</p>\n<p>在大多使用场景下，数据处理的顺序都很重要。大部分消息队列本来就是排序的，并且能保证数据会按照特定的顺序来处理。（Kafka保证一个Partition内的消息的有序性）</p>\n<p>7）缓冲：</p>\n<p>有助于控制和优化数据流经过系统的速度，解决生产消息和消费消息的处理速度不一致的情况。</p>\n<p>8）异步通信：</p>\n<p>很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并[不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。]{.underline}</p>\n<h3 id=\"1-4-Kafka架构\"><a href=\"#1-4-Kafka架构\" class=\"headerlink\" title=\"1.4 Kafka架构\"></a>1.4 Kafka架构</h3><p>1）Producer ：消息生产者，就是向kafka broker发消息的客户端。</p>\n<p>2）Consumer ：消息消费者，向kafka broker取消息的客户端</p>\n<p>3）Topic ：可以理解为一个队列。</p>\n<p>4） Consumer Group<br>（CG）：这是kafka用来实现一个topic消息的广播（发给所有的consumer）和单播（发给<strong>任意一个（不重复消费）</strong>consumer）的手段。一个topic可以有多个CG。topic的消息会复制-给consumer。如果需要实现[<strong>广播</strong>，只要每个consumer有一个<strong>独立的</strong>CG]{.underline}就可以了。要实现[<strong>单播</strong>只要所有的consumer在<strong>同一个</strong>CG]{.underline}。用CG还可以将consumer进行自由的分组而不需要多次发送消息到不同的topic。</p>\n<p>同一个CG里同时只有一个Consumer消费；不重复消费独立广播；一个分区数据只交给一个consumer</p>\n<p>Follower不暴露，只用于备份，高可用</p>\n<p><strong>ZK 一致性: followerLeader</strong>（保存Kafka broker<br>status心跳），（保存consumer消费信息：offset）</p>\n<p>5）Broker<br>：一台kafka服务器就是一个broker。一个集群由多个broker组成。[一个broker可以容纳多个topic。]{.underline}</p>\n<p>6）Partition：为了实现扩展性，一个非常大的topic可以分布到多个broker（即服务器）上，一个topic可以分为多个partition，每个partition是一个有序的队列。partition中的每条消息都会被分配一个有序的id（offset）。kafka[只保证按一个partition中的顺序将消息发给consumer，不保证一个topic的整体（多个partition间）的顺序]{.underline}。</p>\n<p>7）Offset（紫线）：kafka的存储文件都是按照offset.kafka来命名，用offset做名字的好处是方便查找。例如你想找位于2049的位置，只要找到2048.kafka的文件即可。当然the<br>first offset就是00000000000.kafka</p>\n<p>流式计算，默认缓存7天<br>实际**[数据是存在logs&#x2F;【offsetNum】.log文件]{.underline}**里的</p>\n<h3 id=\"1-5-分布式模型\"><a href=\"#1-5-分布式模型\" class=\"headerlink\" title=\"1.5 分布式模型\"></a>1.5 分布式模型</h3><p>分布式共有：</p>\n<p>同一个Kafka集群</p>\n<p>拥有同一个Topic里多分区</p>\n<p>不同的数据不同的分区</p>\n<p>Kafka每个主题的多个分区日志分布式地存储在Kafka集群上，同时为了故障容错，每个分区都会以副本的方式复制到多个消息代理节点上。其中一个节点会作为主副本（Leader），其他节点作为备份副本（Follower，也叫作从副本）。主副本会负责所有的客户端读写操作，备份副本仅仅从主副本同步数据。当主副本出现故障时，备份副本中的一个副本会被选择为新的主副本。因为每个分区的副本中只有主副本接受读写，所以每个服务器端都会作为某些分区的主副本，以及另外一些分区的备份副本，这样Kafka集群的所有服务端整体上对客户端是负载均衡的。</p>\n<p>Kafka的生产者和消费者相对于服务器端而言都是客户端。</p>\n<p>Kafka生产者客户端发布消息到服务端的指定主题，会指定消息所属的分区。生产者发布消息时根据消息是否有键，采用不同的分区策略。[消息没有键时，通过<strong>轮询</strong>方式进行客户端负载均衡；消息有键时，根据<strong>分区语义（例如hash</strong>）确保<strong>相同键</strong>的消息总是发送到<strong>同一分区</strong>。]{.underline}</p>\n<p>Kafka的消费者通过订阅主题来消费消息，并且每个消费者都会设置一个消费组名称。因为生产者发布到主题的每一条消息都只会发送给消费者组的一个消费者。所以，如果要实现传统消息系统的”队列”模型，可以让每个消费者都拥有相同的消费组名称，这样消息就会负责均衡到所有的消费者同组顺序单播；如果要实现”发布-订阅”模型，则每个消费者的消费者组名称都不相同，这样每条消息就会广播给所有的消费者。</p>\n<p>分区是消费者现场模型的最小并行单位。如下图（图1）所示，生产者发布消息到一台服务器的3个分区时，只有一个消费者消费所有的3个分区。在下图（图2）中，3个分区分布在3台服务器上，同时有3个消费者分别消费不同的分区。假设每个服务器的吞吐量是300MB，在下图（图1）中分摊到每个分区只有100MB，而在下图（图2）中，集群整体的吞吐量有900MB。可以看到，[增加服务器节点会提升集群的性能（吞吐量），增加消费者数量会提升处理性能。]{.underline}</p>\n<p>同一个消费组下多个消费者互相协调消费工作，Kafka会将所有的分区平均地分配给所有的消费者实例，这样每个消费者都可以分配到数量均等的分区。Kafka的[消费组管理协议会动态地维护消费组的成员列表，当一个新消费者加入消费者组，或者有消费者离开消费组，都会触发再平衡操作。]{.underline}</p>\n<p><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image42.png\">{width&#x3D;”3.3854166666666665in”<br>height&#x3D;”3.7395833333333335in”}</p>\n<p>图12:LB网络与磁盘IO，提高吞吐量（横向扩展），独立CG广播：同topic不同用途</p>\n<p>Kafka的消费者消费消息时，[只保证在一个分区内的消息的完全有序性，并不保证同一个主题汇总多个分区的消息顺序]{.underline}。而且，消费者读取一个分区消息的顺序和生产者写入到这个分区的顺序是一致的。比如，生产者写入”hello”和”Kafka”两条消息到分区P1，则消费者读取到的顺序也一定是”hello”和”Kafka”。如果业务上需要保证所有消息完全一致，只能通过设置一个分区完成，但这种做法的缺点是最多只能有一个消费者进行消费。一般来说，只需要保证每个分区的有序性，再对消息假设键来保证相同键的所有消息落入同一分区，就可以满足绝大多数的应用。</p>\n<p>设计代码：自定义分区规则；设计key；暴力指定分区号</p>\n<h2 id=\"三-Kafka工作流程分析\"><a href=\"#三-Kafka工作流程分析\" class=\"headerlink\" title=\"三 Kafka工作流程分析\"></a>三 Kafka工作流程分析</h2><h3 id=\"3-1-Kafka生产过程分析\"><a href=\"#3-1-Kafka生产过程分析\" class=\"headerlink\" title=\"3.1 Kafka生产过程分析\"></a>3.1 Kafka生产过程分析</h3><h4 id=\"3-1-1-写入方式\"><a href=\"#3-1-1-写入方式\" class=\"headerlink\" title=\"3.1.1 写入方式\"></a>3.1.1 写入方式</h4><p>**集群最低要求：Disk转速&gt;&#x3D;7200转&#x2F;s，400~500M&#x2F;s RW效率 **</p>\n<p>producer采用推（push）模式将消息发布到broker，每条消息都被追加（append）到分区（patition）中，属于顺序写磁盘（顺序写磁盘效率比随机写内存要高，保障kafka吞吐率）。</p>\n<p>Kafka&#x2F;logs&#x2F;topic-012partition，1个partition1个folder</p>\n<p>.log序列化文件</p>\n<p>Kafka内嵌编解码器（反）序列化器：SerializerEncoder SerializerDecoder</p>\n<h4 id=\"3-1-2-分区（Partition）！！！！！！！！！！！\"><a href=\"#3-1-2-分区（Partition）！！！！！！！！！！！\" class=\"headerlink\" title=\"3.1.2 分区（Partition）！！！！！！！！！！！\"></a>3.1.2 分区（Partition）！！！！！！！！！！！</h4><p>Kafka集群有多个消息代理服务器（broker-server）组成，发布到Kafka集群的每条消息都有一个类别，用主题（topic）来表示。通常，不同应用产生不同类型的数据，可以设置不同的主题。一个主题一般会有多个消息的订阅者，当生产者发布消息到某个主题时，订阅了这个主题的消费者都可以接收到生成者写入的新消息。</p>\n<p>Kafka集群为每个主题维护了分布式的分区（partition）日志文件，物理意义上可以把主题（topic）看作进行了分区的日志文件（partition<br>log）offset.log。主题的每个分区都是一个有序的、不可变的记录序列，新的消息会不断追加到日志中。分区中的每条消息都会按照时间顺序分配到一个单调递增的顺序编号，叫做偏移量（offset），这个偏移量能够唯一地定位当前分区中的每一条消息。</p>\n<p>消息发送时都被发送到一个topic，其本质就是一个目录，而topic是由一些Partition<br>Logs(分区日志)组成，其组织结构如下图所示：</p>\n<p>下图中的topic有3个分区，每个分区的偏移量都从0开始，不同分区之间的偏移量都是独立的，不会相互影响。</p>\n<p><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image44.png\"></p>\n<p><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image45.png\"></p>\n<p>不标记data为已消费，消费完删除，activeMQ会mark</p>\n<p>Reach time&#x2F;space清理阈值，即使没consume，也删除：加快内部data管理效率</p>\n<p>offset由ZK、consumer自己管理</p>\n<p>4个方法重载，params：</p>\n<p>Key 默认”a”.hash%partition LB,</p>\n<p>partition未指定：轮询auto-LB 0开始，一旦指定key就没意义了,</p>\n<p>value</p>\n<p>我们可以看到，每个Partition中的消息都是有序的，生产的消息被不断追加到Partition<br>log上，其中的每一个消息都被赋予了一个唯一的offset值。Offset.log</p>\n<p>发布到Kafka主题的每条[消息包括键值和时间戳]{.underline}。消息到达服务器端的指定分区后，都会[分配]{.underline}到一个[自增的偏移量]{.underline}。原始的[消息内容和分配的偏移量以及其他一些元数据信息]{.underline}最后**[都会]{.underline}**存储到[分区日志文件中]{.underline}。消息的键也可以不用设置，这种情况下消息会均衡地分布到不同的分区。</p>\n<ol>\n<li>分区的原因</li>\n</ol>\n<p>（1）方便在集群中扩展，每个Partition可以通过调整以适应它所在的机器，而一个topic又可以有多个Partition组成，因此整个集群就可以适应任意大小的数据了；</p>\n<p>（2）可以提高并发，因为可以以Partition为单位读写了。</p>\n<p>传统消息系统在服务端保持消息的顺序，如果有多个消费者消费同一个消息队列，服务端会以消费存储的顺序依次发送给消费者。但由于消息是异步发送给消费者的，消息到达消费者的顺序可能是无序的，这就意味着在并行消费时，传统消息系统无法很好地保证消息被顺序处理。虽然我们可以设置一个专用的消费者只消费一个队列，以此来解决消息顺序的问题，但是这就使得消费处理无法真正执行。</p>\n<p>Kafka比传统消息系统有更强的顺序性保证，它使用主题的分区作为消息处理的并行单元。Kafka以分区作为最小的粒度，将每个分区分配给消费者组中不同的而且是唯一的消费者，并确保一个分区只属于一个消费者，即这个消费者就是这个分区的唯一读取线程。那么，只要分区的消息是有序的，消费者处理的消息顺序就有保证。每个主题有多个分区，不同的消费者处理不同的分区，所以Kafka不仅保证了消息的有序性，也做到了消费者的负载均衡。</p>\n<p>2）分区的原则</p>\n<p>（1）指定了patition，则直接使用；</p>\n<p>（2）未指定patition但指定key，通过对key的value进行hash出一个patition</p>\n<p>（3）patition和key都未指定，使用轮询选出一个patition。</p>\n<p>+———————————————————————–+<br>| <strong>DefaultPartitioner类 kafka.0.11版本</strong>                               |<br>|                                                                       |<br>| <strong>public</strong> <strong>int</strong> partition(String topic, Object key, <strong>byte</strong>[]   |<br>| keyBytes, Object value, <strong>byte</strong>[] valueBytes, Cluster cluster) {   |<br>|                                                                       |<br>| List&lt;PartitionInfo&gt; partitions &#x3D; cluster.partitionsForTopic(topic); |<br>|                                                                       |<br>| <strong>int</strong> numPartitions &#x3D; partitions.size();                            |<br>|                                                                       |<br>| <strong>if</strong> (keyBytes &#x3D;&#x3D; <strong>null</strong>) {                                       |<br>|                                                                       |<br>| <strong>int</strong> nextValue &#x3D; nextValue(topic);                                 |<br>|                                                                       |<br>| List&lt;PartitionInfo&gt; availablePartitions &#x3D;                           |<br>| cluster.availablePartitionsForTopic(topic);                           |<br>|                                                                       |<br>| <strong>if</strong> (availablePartitions.size() &gt; 0) {                            |<br>|                                                                       |<br>| <strong>int</strong> part &#x3D; Utils.<em>toPositive</em>(nextValue) %                        |<br>| availablePartitions.size();                                           |<br>|                                                                       |<br>| <strong>return</strong> availablePartitions.get(part).partition();                 |<br>|                                                                       |<br>| } <strong>else</strong> { &#x2F;&#x2F;(3)                                                    |<br>|                                                                       |<br>| &#x2F;&#x2F; no partitions are available, give a non-available partition        |<br>|                                                                       |<br>| <strong>return</strong> Utils.<em>toPositive</em>(nextValue) % numPartitions;             |<br>|                                                                       |<br>| }                                                                     |<br>|                                                                       |<br>| } <strong>else</strong> { &#x2F;&#x2F;(2)                                                    |<br>|                                                                       |<br>| &#x2F;&#x2F; hash the keyBytes to choose a partition                            |<br>|                                                                       |<br>| <strong>return</strong> Utils.<em>toPositive</em>(Utils.<em>murmur2</em>(keyBytes)) %            |<br>| numPartitions;                                                        |<br>|                                                                       |<br>| }                                                                     |<br>|                                                                       |<br>| }&#x2F;&#x2F;？？？？？？？？???????????????????????????????????????????????    |<br>+———————————————————————–+</p>\n<h4 id=\"3-1-3-副本（Replication）\"><a href=\"#3-1-3-副本（Replication）\" class=\"headerlink\" title=\"3.1.3 副本（Replication）\"></a>3.1.3 副本（Replication）</h4><p>同一个partition可能会有多个replication（对应 server.properties 配置中的<br>default.replication.factor&#x3D;N）。没有replication的情况下，一旦broker<br>宕机，其上所有 partition<br>的数据都不可被消费，同时producer也不能再将数据存于其上的patition。引入replication之后，同一个partition可能会有多个replication，而这时需要在这些replication之间选出一个leader，producer和consumer只与这个leader交互，其它replication作为follower从leader<br>中复制数据。</p>\n<h4 id=\"3-1-4-写入流程\"><a href=\"#3-1-4-写入流程\" class=\"headerlink\" title=\"3.1.4 写入流程\"></a>3.1.4 写入流程</h4><p> producer写入消息流程如下：</p>\n<p>1）producer先从zookeeper的<br>&quot;&#x2F;brokers&#x2F;...&#x2F;state&quot;节点找到该partition的leader</p>\n<p>2）producer将消息发送给该leader</p>\n<p>3）leader将消息写入本地log</p>\n<p>4）followers从leader pull消息，写入本地log后向leader发送ACK</p>\n<p>5）leader[收到所有ISR中的replication的ACK后(对consumer才可见)]{.underline}，**[增加HW（high<br>watermark，最后commit 的offset）]{.underline}**并向producer发送ACK</p>\n<h3 id=\"3-3-Kafka消费过程分析\"><a href=\"#3-3-Kafka消费过程分析\" class=\"headerlink\" title=\"3.3 Kafka消费过程分析\"></a>3.3 Kafka消费过程分析</h3><p>kafka提供了两套consumer API：高级Consumer API和低级API。</p>\n<h4 id=\"3-3-1-消费模型\"><a href=\"#3-3-1-消费模型\" class=\"headerlink\" title=\"3.3.1 消费模型\"></a>3.3.1 消费模型</h4><p>消息由生产者发布到Kafka集群后，会被消费者消费。消息的消费模型有两种：推送模型（push）和拉取模型（pull）。</p>\n<p>基于推送模型（push）的消息系统，由消息代理记录消费者的消费状态。消息代理在将消息推送到消费者后，标记这条消息为已消费，但这种方式无法很好地保证消息被处理。比如，消息代理把消息发送出去后，当消费进程挂掉或者由于网络原因没有收到这条消息时，就有可能造成消息丢失（因为消息代理已经把这条消息标记为已消费了，但实际上这条消息并没有被实际处理）。如果要保证消息被处理，消息代理发送完消息后，要设置状态为”已发送”，只有[收到消费者的确认请求后才更新为”已消费”]{.underline}，这就需要[消息代理中记录所有的消费状态]{.underline}，这种做法显然是[不可取]{.underline}的。<br>[填鸭式教育，速度不一致：data易丢失]{.underline}</p>\n<p>Kafka采用拉取模型，由消费者自己记录消费状态，每个消费者互相独立地顺序读取每个分区的消息。如下图所示，有两个消费者（不同消费者组）拉取同一个主题的消息，消费者A的消费进度是3，消费者B的消费进度是6。[消费者拉取的最大上限通过最高水位（watermark）控制wait，生产者最新写入的消息如果还没有达到备份数量，对消费者是不可见的。]{.underline}这种由消费者控制偏移量的优点是：消费者可以按照任意的顺序消费消息。比如，消费者可以重置到旧的偏移量，重新处理之前已经消费过的消息；或者直接跳到最近的位置，从当前的时刻开始消费。<br>[按需消费，主动获取]{.underline}</p>\n<p><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image47.png\">{width&#x3D;”4.854166666666667in”<br>height&#x3D;”1.5416666666666667in”}</p>\n<p>在一些消息系统中，消息代理会在消息[被消费之后立即删除消息]{.underline}。如果有不同类型的消费者订阅同一个主题，消息代理可能需要[冗余地存储同一消息；或者等所有消费者都消费完才删除]{.underline}，这就需要消息代理[跟踪每个消费者的消费状态]{.underline}，这种设计很大程度上[限制]{.underline}了消息系统的[整体吞吐量和处理延迟]{.underline}。Kafka的做法是生产者发布的所有消息会一致保存在Kafka集群中，不管消息有没有被消费。用户可以通过[设置保留时间来清理过期的数据]{.underline}，比如，设置保留策略为两天。那么，在消息发布之后，它可以被不同的消费者消费，在两天之后，过期的消息就会自动清理掉。</p>\n<h4 id=\"3-3-2-高级API\"><a href=\"#3-3-2-高级API\" class=\"headerlink\" title=\"3.3.2 高级API\"></a>3.3.2 高级API</h4><p>1）高级API优点</p>\n<p>高级API 写起来简单</p>\n<p>不需要自行去管理[offset，系统通过zookeeper自行管理。]{.underline}</p>\n<p>不需要管理分区，副本等情况，.系统自动管理。</p>\n<p>消费者断线会自动根据上一次记录在zookeeper中的offset去接着获取数据（默认设置1分钟更新一下zookeeper中存的offset）</p>\n<p>可以使用group来区分对同一个topic<br>的不同程序访问分离开来（不同的group记录不同的offset，这样不同程序读取同一个topic才不会因为offset互相影响）</p>\n<p>2）高级API缺点</p>\n<p>不能自行控制[offset]{.underline}（对于某些特殊需求来说）</p>\n<p>不能细化控制如[分区、副本、zk等]{.underline}</p>\n<h4 id=\"3-3-3-低级API\"><a href=\"#3-3-3-低级API\" class=\"headerlink\" title=\"3.3.3 低级API\"></a>3.3.3 低级API</h4><p>1）低级 API 优点</p>\n<p>能够让开发者自己控制offset，想从哪里读取就从哪里读取。</p>\n<p>自行[控制连接分区，对分区自定义进行负载均衡]{.underline}</p>\n<p>对zookeeper的依赖性降低（如：[offset不一定非要靠zk存储，自行存储offset]{.underline}即可，比如[存在文件或者内存中]{.underline}）</p>\n<p>2）低级API缺点</p>\n<p>太过复杂，需要自行控制offset，连接哪个分区，找到分区leader 等。</p>\n<h4 id=\"3-3-4-消费者组\"><a href=\"#3-3-4-消费者组\" class=\"headerlink\" title=\"3.3.4 消费者组\"></a>3.3.4 消费者组</h4><p>一个Consumer可订阅多个主题，Kafka streaming对bad topic做数据清洗</p>\n<p>消费者是以consumer<br>group消费者组的方式工作，由一个或者多个消费者组成一个组，共同消费一个topic。[每个分区在同一时间只能由group中的一个消费者读取]{.underline}，但是多个group可以同时消费这个partition。在图中，有一个由三个消费者组成的group，有一个消费者读取主题中的两个分区，另外两个分别读取一个分区。某个消费者[读取]{.underline}某个分区，也可以叫做某个消费者[是某个分区的拥有者]{.underline}。</p>\n<p>在这种情况下，消费者可以通过水平扩展的方式同时读取大量的消息。另外，如果一个消费者[失败]{.underline}了，那么[其他的group成员会自动负载均衡]{.underline}读取之前失败的消费者读取的分区。</p>\n<h4 id=\"3-3-5-消费方式\"><a href=\"#3-3-5-消费方式\" class=\"headerlink\" title=\"3.3.5 消费方式\"></a>3.3.5 消费方式</h4><p>consumer采用pull（拉）模式从broker中读取数据。</p>\n<p>push（推）模式很难适应消费速率不同的消费者，因为消息发送速率是由broker决定的。它的目标是尽可能以最快速度传递消息，但是这样很容易造成consumer来不及处理消息，典型的表现就是[拒绝服务以及网络拥塞。而pull模式则可以根据consumer的消费能力以适当的速率消费]{.underline}消息。</p>\n<p>对于Kafka而言，pull模式更合适，它可简化broker的设计，consumer可自主控制消费消息的[速率]{.underline}，同时consumer可以自己控制消费[方式]{.underline}——即[可批量消费也可逐条消费]{.underline}，同时还能[选择不同的提交方式从而实现不同的传输语义]{.underline}。</p>\n<p>pull模式不足之处是，如果kafka[没有数据，消费者可能会陷入循环中，一直等待数据到达]{.underline}。为了避免这种情况，我们在我们的[拉请求中有参数，允许消费者请求在等待数据到达的”长轮询”中进行阻塞]{.underline}（并且[可选地等待到给定的字节数，以确保大的传输大小]{.underline}）。</p>\n<p>4.2.3 创建生产者带回调函数（新API）</p>\n<h2 id=\"五-Kafka-producer拦截器-interceptor\"><a href=\"#五-Kafka-producer拦截器-interceptor\" class=\"headerlink\" title=\"五 Kafka producer拦截器(interceptor)\"></a>五 <a href=\"http://www.cnblogs.com/huxi2b/p/7072447.html\">Kafka producer拦截器(interceptor)</a></h2><h3 id=\"5-1-拦截器原理\"><a href=\"#5-1-拦截器原理\" class=\"headerlink\" title=\"5.1 拦截器原理\"></a>5.1 拦截器原理</h3><p>Producer拦截器(interceptor)是在Kafka<br>0.10版本被引入的，主要用于实现clients端的定制化控制逻辑。</p>\n<p>对于producer而言，interceptor使得用户在消息发送前以及producer回调逻辑前有机会对消息做一些定制化需求，比如修改消息等。同时，producer允许用户指定多个interceptor按序作用于同一条消息从而形成一个（强依赖）拦截链(interceptor<br>chain)。Intercetpor的实现接口是org.apache.kafka.clients.producer.ProducerInterceptor，其定义的方法包括：</p>\n<p>（1）configure(configs)</p>\n<p>获取配置信息和初始化数据时调用。</p>\n<p>（2）onSend(ProducerRecord)：</p>\n<p>该方法封装进KafkaProducer.send方法中，即它运行在用户主线程中。Producer确保在消息[被序列化以及计算分区前调用]{.underline}该方法。用户可以在该方法中对消息做任何操作，但最好保证不要修改消息所属的topic和分区，否则会影响目标分区的计算</p>\n<p>（3）onAcknowledgement(RecordMetadata, Exception)：</p>\n<p>该方法会在消息被应答或消息发送失败时调用，并且通常都是[在producer回调逻辑触发之前]{.underline}。onAcknowledgement运行在[producer的IO线程中，因此不要在该方法中放入很重的逻辑，否则会拖慢producer的消息发送效率]{.underline}</p>\n<p>（4）close：</p>\n<p>关闭interceptor，主要用于执行一些资源清理工作</p>\n<p>如前所述，interceptor可能被运行在多个线程中，因此在具体实现时用户需要自行确保线程安全。另外倘若指定了多个interceptor，则producer将按照指定顺序调用它们，并仅仅是捕获每个interceptor可能抛出的异常记录到错误日志中而[非再向上传递]{.underline}。这在使用过程中要特别留意。</p>\n<h3 id=\"5-2-拦截器案例\"><a href=\"#5-2-拦截器案例\" class=\"headerlink\" title=\"5.2 拦截器案例\"></a>5.2 拦截器案例</h3><p>1）需求：</p>\n<p>实现一个简单的双interceptor组成的拦截链。第一个interceptor会在消息[发送前将时间戳信息加到消息value的最前部]{.underline}；第二个interceptor会在消息[发送后更新成功发送消息数或失败发送消息数]{.underline}。</p>\n<h2 id=\"六-kafka-Streams\"><a href=\"#六-kafka-Streams\" class=\"headerlink\" title=\"六 kafka Streams\"></a>六 kafka Streams</h2><h3 id=\"6-1-概述\"><a href=\"#6-1-概述\" class=\"headerlink\" title=\"6.1 概述\"></a>6.1 概述</h3><h4 id=\"6-1-1-Kafka-Streams\"><a href=\"#6-1-1-Kafka-Streams\" class=\"headerlink\" title=\"6.1.1 Kafka Streams\"></a>6.1.1 Kafka Streams</h4><p>Kafka Streams。Apache<br>Kafka开源项目的一个组成部分。是一个功能强大，易于使用的库。用于在Kafka上构建高可分布式、拓展性，容错的应用程序。</p>\n<h4 id=\"6-1-2-Kafka-Streams特点\"><a href=\"#6-1-2-Kafka-Streams特点\" class=\"headerlink\" title=\"6.1.2 Kafka Streams特点\"></a>6.1.2 Kafka Streams特点</h4><p>1）功能强大 </p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>高扩展性，弹性，容错 </p></blockquote>\n<p>2）轻量级 </p>\n<p>无需专门的集群 </p>\n<p>一个库，而不是框架</p>\n<p>3）完全集成 </p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>100%的Kafka 0.10.0版本兼容</p>\n<p>易于集成到现有的应用程序 </p></blockquote>\n<p>4）实时性</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>毫秒级延迟 </p>\n<p>并非微批处理 </p>\n<p>窗口允许乱序数据 </p>\n<p>允许迟到数据</p></blockquote>\n<h4 id=\"6-1-3-为什么要有Kafka-Stream\"><a href=\"#6-1-3-为什么要有Kafka-Stream\" class=\"headerlink\" title=\"6.1.3 为什么要有Kafka Stream\"></a>6.1.3 为什么要有Kafka Stream</h4><p>当前已经有非常多的流式处理系统，最知名且应用最多的[开源流式处理系统有Spark<br>Streaming和Apache Storm。]{.underline}Apache<br>Storm发展多年，应用广泛，提供记录级别的处理能力，当前也支持SQL on<br>Stream。而Spark Streaming基于Apache<br>Spark，可以非常方便与图计算，SQL处理等集成，功能强大，对于熟悉其它Spark应用开发的用户而言使用门槛低。另外，目前主流的Hadoop发行版，如Cloudera和Hortonworks，都集成了Apache<br>Storm和Apache Spark，使得部署更容易。</p>\n<p>既然Apache Spark与Apache Storm拥有如此多的优势，那为何还需要Kafka<br>Stream呢？主要有如下原因。分担框架压力</p>\n<p>第一，Spark和Storm都是流式处理框架，而Kafka<br>Stream提供的是一个基于Kafka的流式处理类库。[框架要求开发者按照特定的方式去开发逻辑部分，供框架调用。开发者很难了解框架的具体运行方式，从而使得调试成本高，并且使用受限]{.underline}。而Kafka<br>Stream作为流式处理类库，直接[提供具体的类]{.underline}给开发者调用，整个应用的运行方式主要由开发者控制，方便使用和调试。</p>\n<p><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image49.png\"></p>\n<p>第二，虽然Cloudera与Hortonworks方便了Storm和Spark的部署，但是这些框架的部署仍然相对复杂。而Kafka<br>Stream作为类库，可以非常方便的嵌入应用程序中，它对应用的打包和部署基本没有任何要求。</p>\n<p>第三，就流式处理系统而言，基本都支持Kafka作为数据源。例如Storm具有专门的kafka-spout，而Spark也提供专门的spark-streaming-kafka模块。事实上，[Kafka基本上是主流的流式处理系统的标准数据源]{.underline}。换言之，大部分流式系统中都已部署了Kafka，此时使用Kafka<br>Stream的成本非常低。</p>\n<p>第四，使用Storm或Spark<br>Streaming时，需要[为框架本身的进程预留资源]{.underline}，如Storm的supervisor和Spark<br>on YARN的node<br>manager。即使对于应用实例而言，框架本身也会占用部分资源，如Spark<br>Streaming需要为shuffle和storage预留内存。但是[Kafka作为类库不占用系统资源。]{.underline}</p>\n<p>第五，由于Kafka本身提供数据持久化，因此Kafka<br>Stream提供[滚动部署和滚动升级以及重新计算]{.underline}的能力。</p>\n<p>第六，由于Kafka [Consumer Rebalance机制]{.underline}，Kafka<br>Stream可以在线动态调整并行度。</p>\n<h3 id=\"6-2-Kafka-Stream数据清洗案例\"><a href=\"#6-2-Kafka-Stream数据清洗案例\" class=\"headerlink\" title=\"6.2 Kafka Stream数据清洗案例\"></a>6.2 Kafka Stream数据清洗案例</h3><h1 id=\"HBase\"><a href=\"#HBase\" class=\"headerlink\" title=\"HBase\"></a>HBase</h1><h2 id=\"一、HBase-介绍\"><a href=\"#一、HBase-介绍\" class=\"headerlink\" title=\"一、HBase 介绍 \"></a><strong>一、</strong>HBase <strong>介绍</strong> </h2><h3 id=\"1-1、HBase-的起源\"><a href=\"#1-1、HBase-的起源\" class=\"headerlink\" title=\"1.1、HBase 的起源\"></a>1.1<strong>、</strong>HBase <strong>的起源</strong></h3><p>HBase 的原型是 Google 的 BigTable 论文，受到了该论文思想的启发，目前作为<br>Hadoop 的子项目来开发维护，用于支持结构化的数据存储。</p>\n<p>官方网站：<a href=\"http://hbase.apache.org/\">http://hbase.apache.org</a></p>\n<p>-- 2006 年 Google 发表 BigTable 白皮书</p>\n<p>-- 2006 年开始开发 HBase</p>\n<p>-- 2008 年北京成功开奥运会，程序员默默地将 HBase 弄成了 Hadoop 的子项目</p>\n<p>-- 2010 年 HBase 成为 Apache 顶级项目</p>\n<p>-- 现在很多公司二次开发出了很多发行版本，你也开始使用了。</p>\n<h3 id=\"1-2、HBase-的角色\"><a href=\"#1-2、HBase-的角色\" class=\"headerlink\" title=\"1.2、HBase 的角色\"></a>1.2<strong>、</strong>HBase <strong>的角色</strong></h3><h4 id=\"1-2-1、HMaster\"><a href=\"#1-2-1、HMaster\" class=\"headerlink\" title=\"1.2.1、HMaster\"></a>1.2.1<strong>、</strong>HMaster</h4><p>功能：</p>\n<p>1) 监控 RegionServer</p>\n<p>2) 处理 RegionServer 故障转移</p>\n<p>3) 处理元数据的变更</p>\n<p>4) 处理 region 的分配或移除</p>\n<p>5) 在空闲时间进行数据的负载均衡</p>\n<p>6) 通过 Zookeeper 发布自己的位置给客户端</p>\n<h4 id=\"1-2-2、RegionServer\"><a href=\"#1-2-2、RegionServer\" class=\"headerlink\" title=\"1.2.2、RegionServer\"></a>1.2.2<strong>、</strong>RegionServer</h4><p>功能：</p>\n<p>1) 负责存储 HBase 的实际数据</p>\n<p>2) 处理分配给它的 Region</p>\n<p>3) 刷新缓存（二级缓存：内存+disk缓存）到 HDFS</p>\n<p>4) 维护 HLog (学oracle)</p>\n<p>5) 执行压缩</p>\n<p>6) 负责处理 Region 分片</p>\n<p>组件：</p>\n<p>1) Write-Ahead logs （HLog）</p>\n<p>HBase 的修改记录，当对 HBase<br>读写数据的时候，数据不是直接写进磁盘，它会在内存中保留一段时间（时间以及数据量阈值可以设定）。但[把数据保存在内存中可能有更高的概率引起数据丢失，为了解决这个问题，数据会先写在一个叫做<br>Write-Ahead logfile<br>的文件中，然后再写入内存中。]{.underline}所以在系统出现故障的时候，数据可以通过这个日志文件重建。</p>\n<p>2) HFile</p>\n<p>这是在磁盘上保存原始数据的实际的物理文件，是实际的存储文件。</p>\n<p>3) Store</p>\n<p>HFile 存储在 Store 中，一个 Store 对应 HBase 表中的一个列族。</p>\n<p>4) MemStore</p>\n<p>顾名思义，就是内存存储，位于内存中，用来保存当前的数据操作，所以当数据保存在WAL（HLog）中之后，RegionServer<br>会在内存中存储键值对。</p>\n<p>5) Region</p>\n<p>Hbase 表的分片，</p>\n<p>HBase 表会根据 RowKey 值被切分成不同的 region 存储在 RegionServer 中，</p>\n<p>在一个 RegionServer 中可以有多个不同的 region。</p>\n<h3 id=\"1-3、HBase-的架构\"><a href=\"#1-3、HBase-的架构\" class=\"headerlink\" title=\"1.3、HBase 的架构\"></a>1.3<strong>、</strong>HBase <strong>的架构</strong></h3><p>HBase 一种是[作为存储的分布式文件系统，另一种是作为数据处理模型的 MR<br>框架]{.underline}。因为日常开发人员比较熟练的是结构化的数据进行处理，但是在<br>HDFS 直接存储的文件往往不具有结构化，所以催生出了 HBase 在 HDFS<br>上的操作。如果需要查询数据，只需要通过键值便可以成功访问。</p>\n<p><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image50.png\">{width&#x3D;”6.170138888888889in”<br>height&#x3D;”3.5909722222222222in”}架构图如下图所示：</p>\n<p>即时通信维持长连接：发心跳包 （2min30s<br>2min50s刷服务器socket链接，无data就kill掉） 重启，HMaster重新负载</p>\n<p>HBase 内 置 有 Zookeeper ， 但 一 般 我 们 会 有 其 他 的 Zookeeper 集<br>群 来 监 管 master 和regionserver，Zookeeper<br>通过选举，保证任何时候，集群中只有一个活跃的 HMaster，HMaster与<br>HRegionServer 启动时会向 ZooKeeper 注册，存储所有<br>HRegion的寻址入口，实时监控[Hregionserver（服务，维护HRegion）的上线和下线]{.underline}信息。并实时通知给<br>HMaster，存储 HBase 的 schema 和 table元数据，默认情况下，HBase 管理<br>ZooKeeper 实例，Zookeeper 的引入使得 HMaster<br>不再是单点故障。一般情况下会启动两个 HMaster，非 Active 的 HMaster<br>会定期的和 Active<br>HMaster通信以获取其最新状态，从而保证它是实时更新的，因而如果启动了多个<br>HMaster 反而增加了 Active HMaster 的负担。</p>\n<p>一个 RegionServer 可以包含多个 HRegion，每个 RegionServer 维护一个<br>Hlog(合并，溢写)，和多个 HFiles 以及其对应的<br>MemStore（Store）。**[RegionServer 运行于 DataNode<br>上]{.underline}**，数量可以与 DataNode 数量一致，</p>\n<p><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image51.jpeg\">{width&#x3D;”6.8519925634295715in”<br>height&#x3D;”3.9569630358705163in”}请参考如下架构图：</p>\n<p>MemStore 内存缓存 LRUCache算法：用双链表维护对应访问关系</p>\n<p>region&#x3D;&#x3D;table</p>\n<p>rowkey&#x3D;&#x3D;id</p>\n<p>store&#x3D;列族</p>\n<p>写入MemStore+HLog 即成功 达到阈值到HFile（local<br>disk）--&gt;HDFS（HBase调HDFSClient API）</p>\n<p>保留HFile的metadata（哪个DataNode）</p>\n<p>HDFS支持随机读写的错觉</p>\n<p>等 批处理效率高</p>\n<p>HBase有多个Clients，一个集群。多region&#x3D;多业务tables</p>\n<p><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image52.png\" alt=\"D:\\\\BaiduNetdiskDownload\\\\学编程\\\\【大数据项目视频】视频+源码+PPT教程\\\\09\\_大数据技术之HBase\\\\2.资料\\\\NN设计.PNG\">{width&#x3D;”6.5in”<br>height&#x3D;”4.587664041994751in”}</p>\n<h3 id=\"2-2-2、表的操作\"><a href=\"#2-2-2、表的操作\" class=\"headerlink\" title=\"2.2.2、表的操作\"></a><strong>2.2.2</strong>、表的操作</h3><p>1) <strong>创建表</strong> create ‘表名’，’列族(column family)名’</p>\n<p>hbase(main)&gt; create &#39;student&#39;,&#39;info&#39;</p>\n<p><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image53.png\">{width&#x3D;”6.5in”<br>height&#x3D;”3.629166666666667in”}</p>\n<p>hbase.put(rowkey[类似主键ID]:info[column family]:name[column<br>quality],nick[cell])</p>\n<p>可以没字段，动态创建字段。适合存储稀疏的非结构化数据（不适合数据分析，适合数据挖掘：logistic回归）</p>\n<p>Hive：结构化数据</p>\n<p>time<br>stamp自带时间戳，维护不同版本（覆盖，默认对外展示latest，备份保留历史版&#x2F;副本）</p>\n<p>列族需要已存在！！！！！！if无，alter 加列族。</p>\n<p><strong>2)</strong> 插入数据到表</p>\n<p>hbase(main) &gt; put &#39;student&#39;,&#39;1001&#39;,&#39;info:name&#39;,&#39;Thomas&#39;</p>\n<p>table rowkey 列族:动态创建列 value</p>\n<p>hbase(main) &gt; put &#39;student&#39;,&#39;1001&#39;,&#39;info:sex&#39;,&#39;male&#39;</p>\n<p>hbase(main) &gt; put &#39;student&#39;,&#39;1001&#39;,&#39;info:age&#39;,&#39;18&#39;</p>\n<p>hbase(main) &gt; put &#39;student&#39;,&#39;1002&#39;,&#39;info:name&#39;,&#39;Janna&#39;</p>\n<p>hbase(main) &gt; put &#39;student&#39;,&#39;1002&#39;,&#39;info:sex&#39;,&#39;female&#39;</p>\n<p>hbase(main) &gt; put &#39;student&#39;,&#39;1002&#39;,&#39;info:age&#39;,&#39;20&#39;</p>\n<p><strong>3)</strong> 扫描查看表数据</p>\n<p>hbase(main) &gt; scan &#39;student&#39;</p>\n<p>hbase(main) &gt; scan &#39;student&#39;,{STARTROW &#x3D;&gt; &#39;1001&#39;, STOPROW &#x3D;&gt;<br>&#39;1001&#39;}</p>\n<p>字符按位比较 ac：ac e (有比没有大)</p>\n<p>hbase(main) &gt; scan &#39;student&#39;,{STARTROW &#x3D;&gt; &#39;1001&#39;}</p>\n<p>column(qualify全列名)&#x3D;info:name</p>\n<p><strong>4)</strong> 查看表结构</p>\n<p>hbase(main):012:0&gt; describe ‘student’</p>\n<p><strong>5)</strong> 更新指定字段的数据</p>\n<p>hbase(main) &gt; put &#39;student&#39;,&#39;1001&#39;,&#39;info:name&#39;,&#39;Nick&#39;</p>\n<p>hbase(main) &gt; put &#39;student&#39;,&#39;1001&#39;,&#39;info:age&#39;,&#39;100&#39;</p>\n<p><strong>6)</strong> 查看”指定行”或”指定列族**:**列”的数据</p>\n<p>hbase(main) &gt; get &#39;student&#39;,&#39;1001&#39;</p>\n<p>hbase(main) &gt; get &#39;student&#39;,&#39;1001&#39;,&#39;info:name&#39;</p>\n<p><strong>7)</strong> 删除数据</p>\n<p>删除某 <strong>rowkey</strong> 的全部数据：</p>\n<p>hbase(main) &gt; deleteall &#39;student&#39;,&#39;1001&#39;</p>\n<p>删除某 <strong>rowkey</strong> 的某一列数据：</p>\n<p>hbase(main) &gt; delete &#39;student&#39;,&#39;1002&#39;,&#39;info:sex&#39;</p>\n<p><strong>8)</strong> 清空表数据</p>\n<p>hbase(main) &gt; truncate &#39;student&#39;</p>\n<p>尖叫提示：清空表的操作顺序为先 disable，然后再 truncating。</p>\n<p>9) <strong>删除表</strong></p>\n<p>首先需要先让该表为 <strong>disable</strong> 状态：</p>\n<p>hbase(main) &gt; disable &#39;student&#39;</p>\n<p>然后才能 <strong>drop</strong> 这个表：</p>\n<p>hbase(main) &gt; drop &#39;student&#39;</p>\n<p>尖叫提示：如果直接 drop 表，会报错：Drop the named table. Table must<br>first be disabled ERROR: Table student is enabled. Disable it first.</p>\n<p><strong>10)</strong> 统计表数据行数(rowkey)(hbase按列存储)</p>\n<p>hbase(main) &gt; count &#39;student&#39;</p>\n<p><strong>11)</strong> 变更表信息</p>\n<p>将 info 列族中的数据存放 3 个版本：</p>\n<p>hbase(main) &gt; alter &#39;student&#39;,{NAME&#x3D;&gt;&#39;info&#39;,VERSIONS&#x3D;&gt;3}</p>\n<p>&#x3D;&gt;映射符</p>\n<p>-&gt;lambda</p>\n<p>MySQL：一个user对应一个schema（类似package，~：DB：tables）</p>\n<p><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image54.png\">{width&#x3D;”4.583333333333333in”<br>height&#x3D;”0.6979166666666666in”}</p>\n<p>1 table：n regions 大表切分</p>\n<p>HMaster主节点：负载低 可与NN等高消耗App开在一起</p>\n<p>NN不能同开：耗内存Spark</p>\n<h2 id=\"2-3、读写流程\"><a href=\"#2-3、读写流程\" class=\"headerlink\" title=\"2.3、读写流程 \"></a><strong>2.3</strong>、读写流程 </h2><p>Client-&gt;ZK：(-ROOT- 不切分，对应一个region) -&gt;<br>RegionServer(.META.可切分)-&gt;region 【元数据信息location】-&gt;Client</p>\n<p>Client-&gt;region:业务data scan table</p>\n<p>memstore:存用户最近写入的数据</p>\n<p>blockcache：最近读取data LRUCache 读写分离</p>\n<p>HFile（从HDFS）读取完数据，缓存入blockcache</p>\n<p>HBase能存最多region个数：2^35</p>\n<p>location+ Index(range)</p>\n<p><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image55.png\">{width&#x3D;”6.5in”<br>height&#x3D;”2.8965277777777776in”}</p>\n<p>RW同时进行，冲突Compact</p>\n<p>n级索引：page_size^n</p>\n<p>HMaster：RegionServer故障转移（init时持有 -ROOT-<br>、.META.表元数据信息(DataNode）），状态管理-&gt;ZK</p>\n<h3 id=\"2-3-1、HBase-读数据流程\"><a href=\"#2-3-1、HBase-读数据流程\" class=\"headerlink\" title=\"2.3.1、HBase 读数据流程\"></a>2.3.1<strong>、</strong>HBase <strong>读数据流程</strong></h3><p><strong>1)</strong> HRegionServer 保存着 meta 表以及表数据，要访问表数据，首先 Client<br>先去访问</p>\n<p>zookeeper，从 zookeeper 里面获取 meta 表所在的位置信息，即找到这个 meta<br>表在哪个HRegionServer 上保存着。</p>\n<p><strong>2)</strong> 接着 Client 通过刚才获取到的 HRegionServer 的 IP 来访问 Meta<br>表所在的</p>\n<p>HRegionServer，从而读取到 Meta，进而获取到 Meta 表中存放的元数据。</p>\n<p><strong>3)</strong> Client 通过元数据中存储的信息，访问对应的<br>HRegionServer，然后扫描所在</p>\n<p>HRegionServer 的 Memstore 和 Storefile 来查询数据。</p>\n<p><strong>4)</strong> 最后 HRegionServer 把查询到的数据响应给 Client。</p>\n<h3 id=\"2-3-2、HBase-写数据流程\"><a href=\"#2-3-2、HBase-写数据流程\" class=\"headerlink\" title=\"2.3.2、HBase 写数据流程\"></a>2.3.2<strong>、</strong>HBase <strong>写数据流程</strong></h3><p><strong>1)</strong> Client 也是先访问 zookeeper，找到 Meta 表，并获取 Meta 表信息。</p>\n<p><strong>2)</strong> 确定当前将要写入的数据所对应的 RegionServer 服务器和 Region。</p>\n<p><strong>3)</strong> Client 向该 RegionServer 服务器发起写入数据请求，然后<br>RegionServer 收到请求并响应。</p>\n<p><strong>4)</strong> Client 先把数据写入到 Hlog（MySQL：binlog），以防止数据丢失。</p>\n<p><strong>5)</strong> 然后将数据写入到 Memstore。</p>\n<p><strong>6)</strong> 如果 Hlog 和 Memstore<br>均写入成功，则这条数据写入成功。在此过程中，[如果<br>Memstore达到阈值16KB，会把 Memstore 中的数据 flush 到 StoreFile 中。<br>]{.underline}</p>\n<p><strong>[flush:16KB满-&gt;BufferQueue缓存队列-&gt;HFile]{.underline}</strong></p>\n<p>（NN环形缓冲区80%）保证写入和溢写同时进行。</p>\n<p><strong>7)</strong> 当 Storefile 越来越多，会触发 Compact 合并操作，把过多的<br>Storefile 合并成一个大的Storefile。当 Storefile 越来越大，Region<br>也会越来越大，达到阈值后，会触发 Split 操作，将 Region 一分为二。</p>\n<p>表划分region：-∞~~+∞</p>\n<p>HDFS不能随机读写，只能：复制合并</p>\n<p>RegionServer-&gt;n threads:调用HDFS API（HFile）</p>\n<p>环境数组太小</p>\n<p>MemStore（Write）单例 memstore:HFile&#x3D;1:n，溢写完释放资源</p>\n<p>尖叫提示：因为内存空间是有限的，所以说溢写过程必定伴随着大量的小文件产生。</p>\n<h3 id=\"2-6-1、HBase-与-Hive-的对比\"><a href=\"#2-6-1、HBase-与-Hive-的对比\" class=\"headerlink\" title=\"2.6.1、HBase 与 Hive 的对比\"></a>2.6.1<strong>、</strong>HBase <strong>与</strong> Hive <strong>的对比</strong></h3><p>1) Hive</p>\n<p>(1) <strong>数据仓库</strong></p>\n<p>Hive 的本质其实就相当于将 HDFS 中已经存储的文件在 Mysql<br>中做了一个双射关系，以方</p>\n<p>便使用 HQL 去管理查询。</p>\n<p><strong>(2)</strong> 用于数据分析、清洗</p>\n<p>Hive 适用于离线的数据分析和清洗，延迟较高。</p>\n<p>(3) <strong>基于</strong> HDFS<strong>、</strong>MapReduce</p>\n<p>Hive 存储的数据依旧在 DataNode 上，</p>\n<p>编写的 HQL 语句终将是转换为 MapReduce 代码执行。</p>\n<p>2) HBase</p>\n<p>(1) <strong>数据库</strong></p>\n<p>是一种面向列存储的非关系型数据库。</p>\n<p><strong>(2)</strong> 用于存储结构化和非结构话的数据</p>\n<p>适用于单表非关系型数据的存储，不适合做关联查询，类似 JOIN 等操作。</p>\n<p>(3) <strong>基于</strong> HDFS</p>\n<p>数据持久化存储的体现形式是 Hfile，存放于 DataNode 中，被 ResionServer 以<br>region 的形式进行管理。</p>\n<p><strong>(4)</strong> 延迟较低，接入在线业务使用</p>\n<p>面对大量的企业数据，HBase<br>可以直线单表大量数据的存储，同时提供了高效的数据访问速度。</p>\n<h1 id=\"HBase-的优化\"><a href=\"#HBase-的优化\" class=\"headerlink\" title=\"HBase 的优化 \"></a>HBase <strong>的优化</strong> </h1><h2 id=\"3-1、高可用\"><a href=\"#3-1、高可用\" class=\"headerlink\" title=\"3.1、高可用 \"></a><strong>3.1</strong>、高可用 </h2><p>在 HBase 中 Hmaster 负责监控 RegionServer 的生命周期，均衡 RegionServer<br>的负载，如果Hmaster 挂掉了，那么整个 HBase<br>集群将陷入不健康的状态，并且此时的工作状态并不会维持太久。所以 HBase<br>支持对 Hmaster 的高可用配置。</p>\n<p><strong>1)</strong> 关闭 <strong>HBase</strong> 集群（如果没有开启则跳过此步）</p>\n<p>$ bin&#x2F;stop-hbase.sh</p>\n<p>2) <strong>在</strong> conf <strong>目录下创建</strong> backup-masters <strong>文件</strong></p>\n<p>$ touch conf&#x2F;backup-masters</p>\n<p>3) <strong>在</strong> backup-masters <strong>文件中配置高可用</strong> HMaster <strong>节点</strong></p>\n<p>$ echo linux02 &gt; conf&#x2F;backup-masters</p>\n<p>4) <strong>将整个</strong> conf <strong>目录</strong> scp <strong>到其他节点</strong></p>\n<p>$ scp -r conf&#x2F; linux02:&#x2F;opt&#x2F;modules&#x2F;cdh&#x2F;hbase-0.98.6-cdh5.3.6&#x2F;</p>\n<p>$ scp -r conf&#x2F; linux03:&#x2F;opt&#x2F;modules&#x2F;cdh&#x2F;hbase-0.98.6-cdh5.3.6&#x2F;</p>\n<p><strong>5)</strong> 打开页面测试查看</p>\n<p>0.98 版本之<a href=\"http://linux01:60010/\">前：http://linux01:60010 </a></p>\n<p>0.98 版本之<a href=\"http://linux01:16010/\">后：http://linux01:16010</a></p>\n<h2 id=\"3-2、Hadoop-的通用性优化\"><a href=\"#3-2、Hadoop-的通用性优化\" class=\"headerlink\" title=\"3.2、Hadoop 的通用性优化 \"></a>3.2<strong>、</strong>Hadoop <strong>的通用性优化</strong> </h2><p>1) NameNode <strong>元数据备份使用</strong> SSD</p>\n<p>2) <strong>定时备份</strong> NameNode <strong>上的元数据</strong></p>\n<p>每小时或者每天备份，如果数据极其重要，可以 5~10<br>分钟备份一次。备份可以通过定时任务复制元数据目录即可。</p>\n<p>3) <strong>为</strong> NameNode <strong>指定多个元数据目录</strong></p>\n<p>使用 dfs.name.dir 或者 dfs.namenode.name.dir<br>指定。这样可以提供元数据的冗余和健壮性，以免发生故障。</p>\n<p>4) NameNode <strong>的</strong> dir <strong>自恢复</strong></p>\n<p>设置 dfs.namenode.name.dir.restore 为 true，允许尝试恢复之前失败的<br>dfs.namenode.name.dir 目录，在创建 checkpoint<br>时做此尝试，如果设置了多个磁盘，建议允许。</p>\n<p><strong>5) HDFS</strong> 保证 <strong>RPC</strong> 调用会有较多的线程数</p>\n<p>hdfs-site.xml</p>\n<p>属性：dfs.namenode.handler.count</p>\n<p>解释：该属性是 NameNode 服务默认线程数，的默认值是<br>10，根据机器的可用内存可以调整为 50~100</p>\n<p>属性：dfs.datanode.handler.count</p>\n<p>解释：该属性默认值为 10，是 DataNode 的处理线程数，如果 HDFS<br>客户端程序读写请求比较多，可以调高到<br>15~20，设置的值越大，内存消耗越多，不要调整的过高，一般业务中，5~10<br>即可。</p>\n<p>6) HDFS <strong>副本数的调整</strong></p>\n<p>hdfs-site.xml</p>\n<p>属性：dfs.replication</p>\n<p>解释：如果数据量巨大，且不是非常之重要，可以调整为<br>2~3，如果数据非常之重要，可以调整为 3~5。</p>\n<p>7) HDFS <strong>文件块大小的调整</strong></p>\n<p><strong>hdfs-site.xml</strong></p>\n<p>属性：dfs.blocksize</p>\n<p>解释：块大小定义，该属性应该根据存储的大量的单个文件大小来设置，如果大量的单个文件都小于<br>100M，建议设置成 64M 块大小，对于大于 100M 或者达到 GB<br>的这种情况，建议设置成 256M，一般设置范围波动在 64M~256M 之间。</p>\n<p>8) MapReduce Job <strong>任务服务线程数调整</strong></p>\n<p>mapred-site.xml</p>\n<p>属性：mapreduce.jobtracker.handler.count</p>\n<p>解释：该属性是 Job 任务线程数，默认值是 10，根据机器的可用内存可以调整为<br>50~100</p>\n<p>9) Http <strong>服务器工作线程数</strong></p>\n<p>mapred-site.xml</p>\n<p>属性：mapreduce.tasktracker.http.threads</p>\n<p>解释：定义 HTTP 服务器工作线程数，默认值为 40，对于大集群可以调整到<br>80~100</p>\n<p><strong>10)</strong> 文件排序合并优化</p>\n<p>mapred-site.xml</p>\n<p>属性：mapreduce.task.io.sort.factor</p>\n<p>解释：文件排序时同时合并的数据流的数量，这也定义了同时打开文件的个数，默认值为10，如果调高该参数，可以明显减少磁盘<br>IO，即减少文件读取的次数。</p>\n<p><strong>11)</strong> 设置任务并发</p>\n<p><strong>mapred-site.xml</strong></p>\n<p>属性：mapreduce.map.speculative</p>\n<p>解释：该属性可以设置任务是否可以并发执行，如果任务多而小，该属性设置为<br>true 可以明显加快任务执行效率，但是对于延迟非常高的任务，建议改为<br>false，这就类似于迅雷下载。</p>\n<p>12) MR <strong>输出数据的压缩</strong></p>\n<p><strong>mapred-site.xml</strong></p>\n<p>属性：mapreduce.map.output.compress、mapreduce.output.fileoutputformat.compress<br>解释：对于大集群而言，建议设置 Map-Reduce<br>的输出为压缩的数据，而对于小集群，则不需要。</p>\n<p>13) <strong>优化</strong> Mapper <strong>和</strong> Reducer <strong>的个数</strong></p>\n<p>mapred-site.xml</p>\n<p>属性：</p>\n<p>mapreduce.tasktracker.map.tasks.maximum</p>\n<p>mapreduce.tasktracker.reduce.tasks.maximum</p>\n<p>解释：以上两个属性分别为一个单独的 Job 任务可以同时运行的 Map 和 Reduce<br>的数量。设置上面两个参数时，需要考虑 CPU 核数、磁盘和内存容量。假设一个<br>8 核的 CPU，业务内容非常消耗 CPU，那么可以设置 map 数量为<br>4，如果该业务不是特别消耗 CPU 类型的，那么可以设置 map 数量为 40，reduce<br>数量为<br>20。这些参数的值修改完成之后，一定要观察是否有较长等待的任务，如果有的话，可以减少数量以加快任务执行，如果设置一个很大的值，会引起大量的上下文切换，以及内存与磁盘之间的数据交换，这里没有标准的配置数值，需要根据业务和硬件配置以及经验来做出选择。在同一时刻，不要同时运行太多的<br>MapReduce，这样会消耗过多的内存，任务会执行的非常缓慢，我们需要根据 CPU<br>核数，内存容量设置一个 MR<br>任务并发的最大值，使固定数据量的任务完全加载到内存中，避免频繁的内存和磁盘数据交换，从而降低磁盘<br>IO，提高性能。</p>\n<p>大概估算公式：</p>\n<p>map &#x3D; 2 + ⅔cpu_core</p>\n<p>reduce &#x3D; 2 + ⅓cpu_core</p>\n<h2 id=\"3-3、Linux-优化\"><a href=\"#3-3、Linux-优化\" class=\"headerlink\" title=\"3.3、Linux 优化 \"></a>3.3<strong>、</strong>Linux <strong>优化</strong> </h2><p><strong>1)</strong> 开启文件系统的预读缓存可以提高读取速度</p>\n<p>$ sudo blockdev --setra 32768 &#x2F;dev&#x2F;sda</p>\n<p>尖叫提示：ra 是 readahead 的缩写</p>\n<p><strong>2)</strong> 关闭进程睡眠池</p>\n<p>即不允许后台进程进入睡眠状态，如果进程空闲，则直接 kill 掉释放资源</p>\n<p>$ sudo sysctl -w vm.swappiness&#x3D;0</p>\n<p><strong>3)</strong> 调整 <strong>ulimit</strong> 上限，默认值为比较小的数字</p>\n<p>$ ulimit -n 查看允许最大进程数</p>\n<p>$ ulimit -u 查看允许打开最大文件数</p>\n<p>优化修改：</p>\n<p>$ sudo vi &#x2F;etc&#x2F;security&#x2F;limits.conf 修改打开文件数限制</p>\n<p>末尾添加：</p>\n<p>* soft nofile 1024000</p>\n<p>* hard nofile 1024000</p>\n<p>Hive - nofile 1024000</p>\n<p>hive - nproc 1024000</p>\n<p>$ sudo vi &#x2F;etc&#x2F;security&#x2F;limits.d&#x2F;20-nproc.conf 修改用户打开进程数限制</p>\n<p>修改为：</p>\n<p>#* soft nproc 4096</p>\n<p>#root soft nproc unlimited</p>\n<p>* soft nproc 40960</p>\n<p>root soft nproc unlimited</p>\n<p><strong>4)</strong> 开启集群的时间同步 **NTP **</p>\n<p>集群中某台机器同步网络时间服务器的时间，集群中其他机器则同步这台机器的时间。</p>\n<p><strong>5)</strong> 更新系统补丁</p>\n<p>更新补丁前，请先测试新版本补丁对集群节点的兼容性。</p>\n<h2 id=\"3-4、Zookeeper-优化\"><a href=\"#3-4、Zookeeper-优化\" class=\"headerlink\" title=\"3.4、Zookeeper 优化 \"></a>3.4<strong>、</strong>Zookeeper <strong>优化</strong> </h2><p>1) <strong>优化</strong> Zookeeper <strong>会话超时时间</strong></p>\n<p>hbase-site.xml</p>\n<p>参数：zookeeper.session.timeout</p>\n<p>解释：In hbase-site.xml, set zookeeper.session.timeout to 30 seconds or<br>less to bound failure detection (20-30 seconds is a good<br>start).该值会直接关系到 master 发现服务器宕机的最大周期，默认值为 30<br>秒，如果该值过小，会在 HBase 在写入大量数据发生而 GC<br>时，导致RegionServer 短暂的不可用，从而没有向 ZK<br>发送心跳包，最终导致认为从节shutdown。一般 20 台左右的集群需要配置 5 台<br>zookeeper。</p>\n<h2 id=\"3-5、HBase-优化\"><a href=\"#3-5、HBase-优化\" class=\"headerlink\" title=\"3.5、HBase 优化 \"></a>3.5<strong>、</strong>HBase <strong>优化</strong> </h2><h3 id=\"3-5-1、预分区\"><a href=\"#3-5-1、预分区\" class=\"headerlink\" title=\"3.5.1、预分区\"></a><strong>3.5.1</strong>、预分区</h3><p>每一个 region 维护着 startRow 与 endRowKey，如果加入的数据符合某个<br>region 维护的 rowKey范围，则该数据交给这个 region<br>维护。那么依照这个原则，我们可以将数据索要投放的分区提前大致的规划好，以提高<br>HBase 性能。</p>\n<p><strong>1)</strong> 手动设定预分区</p>\n<p>hbase&gt; create &#39;staff&#39;,&#39;info&#39;,&#39;partition1&#39;,SPLITS &#x3D;&gt;<br>[&#39;1000&#39;,&#39;2000&#39;,&#39;3000&#39;,&#39;4000&#39;]</p>\n<p><strong>2)</strong> 生成 <strong>16</strong> 进制序列预分区</p>\n<p>create &#39;staff2&#39;,&#39;info&#39;,&#39;partition2&#39;,{NUMREGIONS &#x3D;&gt; 15, SPLITALGO<br>&#x3D;&gt; &#39;HexStringSplit&#39;}</p>\n<p><strong>3)</strong> 按照文件中设置的规则预分区</p>\n<p>创建 splits.txt 文件内容如下：</p>\n<p>aaaa</p>\n<p>bbbb</p>\n<p>cccc</p>\n<p>dddd</p>\n<p>然后执行：</p>\n<p>create &#39;staff3&#39;,&#39;partition3&#39;,SPLITS_FILE &#x3D;&gt; &#39;splits.txt&#39;</p>\n<p>4) <strong>使用</strong> JavaAPI <strong>创建预分区</strong></p>\n<p>&#x2F;&#x2F;自定义算法，产生一系列 Hash 散列值存储在二维数组中</p>\n<p>byte[][] splitKeys &#x3D; 某个散列值函数</p>\n<p>&#x2F;&#x2F;创建 HBaseAdmin 实例</p>\n<p>HBaseAdmin hAdmin &#x3D; new HBaseAdmin(HBaseConfiguration.create());</p>\n<p>&#x2F;&#x2F;创建 HTableDescriptor 实例</p>\n<p>HTableDescriptor tableDesc &#x3D; new HTableDescriptor(tableName);</p>\n<p>&#x2F;&#x2F;通过 HTableDescriptor 实例和散列值二维数组创建带有预分区的 HBase 表</p>\n<p>hAdmin.createTable(tableDesc, splitKeys);</p>\n<h3 id=\"3-5-2、RowKey-设计\"><a href=\"#3-5-2、RowKey-设计\" class=\"headerlink\" title=\"3.5.2、RowKey 设计\"></a>3.5.2<strong>、</strong>RowKey <strong>设计</strong></h3><p>一条数据的唯一标识就是 rowkey，那么这条数据存储于哪个分区，取决于 rowkey<br>处于哪个预分区的区间内，设计 rowkey 的主要目的<br>，就是让数据均匀的分布于所有的<br>region中，在一定程度上防止数据倾斜。接下来我们就谈一谈 rowkey<br>常用的设计方案。</p>\n<p><strong>1)</strong> 生成随机数、<strong>hash</strong>、散列值</p>\n<p>比如：</p>\n<p>原本 rowKey 为 1001 的，SHA1<br>后变成：dd01903921ea24941c26a48f2cec24e0bb0e8cc7 原本 rowKey 为 3001<br>的，SHA1 后变成：49042c54de64a1e9bf0b33e00245660ef92dc7bd 原本 rowKey 为<br>5001 的，SHA1 后变成：7b61dec07e02c188790670af43e717f0f46e8913</p>\n<p>在做此操作之前，一般我们会选择从数据集中抽取样本，来决定什么样的 rowKey<br>来 Hash后作为每个分区的临界值。</p>\n<p><strong>2)</strong> 字符串反转</p>\n<p>20170524000001 转成 10000042507102</p>\n<p>20170524000002 转成 20000042507102</p>\n<p>这样也可以在一定程度上散列逐步 put 进来的数据。</p>\n<p><strong>3)</strong> 字符串拼接</p>\n<p>20170524000001_a12e</p>\n<p><strong>20170524000001_93i7</strong></p>\n<h3 id=\"3-5-3、内存优化\"><a href=\"#3-5-3、内存优化\" class=\"headerlink\" title=\"3.5.3、内存优化\"></a><strong>3.5.3</strong>、内存优化</h3><p>HBase 操作过程中需要大量的内存开销，毕竟 Table<br>是可以缓存在内存中的，一般会分配整个可用内存的 70%给 HBase 的 Java<br>堆。但是不建议分配非常大的堆内存，因为 GC 过程持续太久会导致<br>RegionServer 处于长期不可用状态，一般 16~48G<br>内存就可以了，如果因为框架占用内存过高导致系统内存不足，框架一样会被系统服务拖死。</p>\n<h3 id=\"3-5-4、基础优化\"><a href=\"#3-5-4、基础优化\" class=\"headerlink\" title=\"3.5.4、基础优化\"></a><strong>3.5.4</strong>、基础优化</h3><p><strong>1)</strong> 允许在 <strong>HDFS</strong> 的文件中追加内容</p>\n<p>不是不允许追加内容么？没错，请看背景故事：</p>\n<p><a href=\"http://blog.cloudera.com/blog/2009/07/file-appends-in-hdfs/\">http://blog.cloudera.com/blog/2009/07/file-appends-in-hdfs/</a></p>\n<p>hdfs-site.xml<strong>、</strong>hbase-site.xml</p>\n<p>属性：dfs.support.append</p>\n<p>解释：开启 HDFS 追加同步，可以优秀的配合 HBase<br>的数据同步和持久化。默认值为 true。</p>\n<p><strong>2)</strong> 优化 <strong>DataNode</strong> 允许的最大文件打开数</p>\n<p>hdfs-site.xml</p>\n<p>属性：dfs.datanode.max.transfer.threads</p>\n<p>解释：HBase<br>一般都会同一时间操作大量的文件，根据集群的数量和规模以及数据动作，设置为<br>4096 或者更高。默认值：4096</p>\n<p><strong>3)</strong> 优化延迟高的数据操作的等待时间</p>\n<p>hdfs-site.xml</p>\n<p>属性：dfs.image.transfer.timeout</p>\n<p>解释：如果对于某一次数据操作来讲，延迟非常高，socket<br>需要等待更长的时间，建议把该值设置为更大的值（默认 60000 毫秒），以确保<br>socket 不会被 timeout 掉。</p>\n<p><strong>4)</strong> 优化数据的写入效率</p>\n<p>mapred-site.xml</p>\n<p>属性：</p>\n<p>mapreduce.map.output.compress</p>\n<p>mapreduce.map.output.compress.codec</p>\n<p>解释：开启这两个数据可以大大提高文件的写入效率，减少写入时间。第一个属性值修改为true，第二个属性值修改为：org.apache.hadoop.io.compress.GzipCodec<br>或者其他压缩方式。</p>\n<p>5) <strong>优化</strong> DataNode <strong>存储</strong></p>\n<p>属性：dfs.datanode.failed.volumes.tolerated</p>\n<p>解释： 默认为 0，意思是当 DataNode 中有一个磁盘出现故障，则会认为该<br>DataNode shutdown了。如果修改为<br>1，则一个磁盘出现故障时，数据会被复制到其他正常的 DataNode 上，当前的<br>DataNode 继续工作。</p>\n<p>6) <strong>设置</strong> RPC <strong>监听数量</strong></p>\n<p>hbase-site.xml</p>\n<p>属性：hbase.regionserver.handler.count</p>\n<p>解释：默认值为 30，用于指定 RPC<br>监听的数量，可以根据客户端的请求数进行调整，读写请求较多时，增加此值。</p>\n<p>7) <strong>优化</strong> HStore <strong>文件大小</strong></p>\n<p>hbase-site.xml</p>\n<p>属性：hbase.hregion.max.filesize</p>\n<p>解释：默认值 10737418240（10GB），如果需要运行 HBase 的 MR<br>任务，可以减小此值，因为一个 region 对应一个 map 任务，如果单个 region<br>过大，会导致 map 任务执行时间过长。该值的意思就是，如果 HFile<br>的大小达到这个数值，则这个 region 会被切分为两个 Hfile。</p>\n<p>8) <strong>优化</strong> hbase <strong>客户端缓存</strong></p>\n<p>hbase-site.xml</p>\n<p>属性：hbase.client.write.buffer</p>\n<p>解释：用于指定 HBase 客户端缓存，增大该值可以减少 RPC<br>调用次数，但是会消耗更多内存，反之则反之。一般我们需要设定一定的缓存大小，以达到减少<br>RPC 次数的目的。</p>\n<p>9) <strong>指定</strong> scan.next <strong>扫描</strong> HBase <strong>所获取的行数</strong></p>\n<p>hbase-site.xml</p>\n<p>属性：hbase.client.scanner.caching</p>\n<p>解释：用于指定 scan.next 方法获取的默认行数，值越大，消耗内存越大。</p>\n<p>10) flush<strong>、</strong>compact<strong>、</strong>split <strong>机制</strong></p>\n<p>当 MemStore 达到阈值，将 Memstore 中的数据 Flush 进 Storefile；compact<br>机制则是把 flush 出来的小文件合并成大的 Storefile 文件。split 则是当<br>Region 达到阈值，会把过大的 Region一分为二。</p>\n<p>涉及属性：</p>\n<p>即：128M 就是 Memstore 的默认阈值</p>\n<p><img src=\"http://cache.itzy8.top/Hadoop%E7%BB%84%E4%BB%B6%E5%9F%BA%E7%A1%80/image56.png\">{width&#x3D;”5.569444444444445in”<br>height&#x3D;”1.8888888888888888in”}</p>\n<p>hbase.hregion.memstore.flush.size：134217728</p>\n<p>即：这个参数的作用是当单个 HRegion 内所有的 Memstore<br>大小总和超过指定值时，flush该 HRegion 的所有 memstore。RegionServer 的<br>flush<br>是通过将请求添加一个队列，模拟生产消费模型来异步处理的。那这里就有一个问题，当队列来不及消费，产生大量积压请求时，可能会导致内存陡增，最坏的情况是触发<br>OOM。</p>\n<p>hbase.regionserver.global.memstore.upperLimit：0.4</p>\n<p>hbase.regionserver.global.memstore.lowerLimit：0.38</p>\n<p>即：当 MemStore 使用内存总量达到<br>hbase.regionserver.global.memstore.upperLimit 指定值时，将会有多个<br>MemStores flush 到文件中，MemStore flush<br>顺序是按照大小降序执行的，直到刷新到 MemStore 使用内存略小于 lowerLimit</p>\n","feature":true,"text":"Vi命令{width&#x3D;”6.809942038495188in”height&#x3D;”4.260115923009624in”} HDFS{width&#x3D;”5.768055555555556in”height&#x3D;”2.9347222222222222...","link":"","photos":[],"count_time":{"symbolsCount":"91k","symbolsTime":"1:22"},"categories":[{"name":"大数据","slug":"大数据","count":2,"path":"api/categories/大数据.json"}],"tags":[{"name":"大数据","slug":"大数据","count":2,"path":"api/tags/大数据.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#Vi%E5%91%BD%E4%BB%A4\"><span class=\"toc-text\">Vi命令</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#HDFS\"><span class=\"toc-text\">HDFS</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#Hadoop\"><span class=\"toc-text\">Hadoop</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#MapReduce%E4%BC%98%E7%BC%BA%E7%82%B9\"><span class=\"toc-text\">MapReduce优缺点</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#MapReduce%E5%BC%80%E5%8F%91%E6%80%BB%E7%BB%93\"><span class=\"toc-text\">MapReduce开发总结</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#Hadoop%E6%95%B0%E6%8D%AE%E5%8E%8B%E7%BC%A9\"><span class=\"toc-text\">Hadoop数据压缩</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#Yarn\"><span class=\"toc-text\">Yarn</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#Scheduler\"><span class=\"toc-text\">Scheduler</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E4%BB%BB%E5%8A%A1%E7%9A%84%E6%8E%A8%E6%B5%8B%E6%89%A7%E8%A1%8C\"><span class=\"toc-text\">任务的推测执行</span></a></li></ol></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#Hadoop-%E4%BC%81%E4%B8%9A%E4%BC%98%E5%8C%96\"><span class=\"toc-text\">Hadoop 企业优化 </span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#6-1-MapReduce-%E8%B7%91%E7%9A%84%E6%85%A2%E7%9A%84%E5%8E%9F%E5%9B%A0\"><span class=\"toc-text\">6.1 MapReduce 跑的慢的原因</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#6-2-MapReduce%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95\"><span class=\"toc-text\">6.2 MapReduce优化方法</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#6-2-1-%E6%95%B0%E6%8D%AE%E8%BE%93%E5%85%A5\"><span class=\"toc-text\">6.2.1 数据输入</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#6-2-2-Map%E9%98%B6%E6%AE%B5\"><span class=\"toc-text\">6.2.2 Map阶段</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#6-2-3-Reduce%E9%98%B6%E6%AE%B5\"><span class=\"toc-text\">6.2.3 Reduce阶段</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#6-2-4-IO%E4%BC%A0%E8%BE%93\"><span class=\"toc-text\">6.2.4 IO传输</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#6-2-5-%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%E9%97%AE%E9%A2%98\"><span class=\"toc-text\">6.2.5 数据倾斜问题</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#6-2-6-%E5%B8%B8%E7%94%A8%E7%9A%84%E8%B0%83%E4%BC%98%E5%8F%82%E6%95%B0\"><span class=\"toc-text\">6.2.6 常用的调优参数</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#6-3-HDFS%E5%B0%8F%E6%96%87%E4%BB%B6%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95\"><span class=\"toc-text\">6.3 HDFS小文件优化方法</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#6-3-2-%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88\"><span class=\"toc-text\">6.3.2 解决方案</span></a></li></ol></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#Zookeeper\"><span class=\"toc-text\">Zookeeper</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0%E8%A7%A3%E8%AF%BB\"><span class=\"toc-text\">配置参数解读</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2\"><span class=\"toc-text\">分布式安装部署</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#Zookeeper%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86\"><span class=\"toc-text\">Zookeeper内部原理 </span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#3-1-%E9%80%89%E4%B8%BE%E6%9C%BA%E5%88%B6\"><span class=\"toc-text\">3.1 选举机制</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#3-2-%E8%8A%82%E7%82%B9%E7%B1%BB%E5%9E%8B\"><span class=\"toc-text\">3.2 节点类型</span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#Hive\"><span class=\"toc-text\">Hive</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%B8%80-Hive-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5\"><span class=\"toc-text\">一 Hive 基本概念</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#1-1-%E4%BB%80%E4%B9%88%E6%98%AF-Hive\"><span class=\"toc-text\">1.1 什么是 Hive</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#1-2-Hive-%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9\"><span class=\"toc-text\">1.2 Hive 的优缺点</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#1-3-Hive-%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86\"><span class=\"toc-text\">1.3 Hive 架构原理</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#1-4-Hive-%E5%92%8C%E6%95%B0%E6%8D%AE%E5%BA%93%E6%AF%94%E8%BE%83\"><span class=\"toc-text\">1.4 Hive 和数据库比较</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#6-5-%E6%8E%92%E5%BA%8F\"><span class=\"toc-text\">6.5 排序 </span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#6-5-1-%E5%85%A8%E5%B1%80%E6%8E%92%E5%BA%8F%EF%BC%88Order-By%EF%BC%89\"><span class=\"toc-text\">6.5.1 全局排序（Order By）</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#6-5-4-%E6%AF%8F%E4%B8%AA-MapReduce-%E5%86%85%E9%83%A8%E6%8E%92%E5%BA%8F%EF%BC%88Sort-By%EF%BC%89\"><span class=\"toc-text\">6.5.4 每个 MapReduce 内部排序（Sort By）</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#6-5-5-%E5%88%86%E5%8C%BA%E6%8E%92%E5%BA%8F%EF%BC%88Distribute-By%E2%80%A6sort-by%E2%80%A6%EF%BC%89\"><span class=\"toc-text\">6.5.5 分区排序（Distribute By…sort by…）</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#6-5-6-Cluster-By\"><span class=\"toc-text\">6.5.6 Cluster By</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#6-6-%E5%88%86%E6%A1%B6%E5%8F%8A%E6%8A%BD%E6%A0%B7%E6%9F%A5%E8%AF%A2\"><span class=\"toc-text\">6.6 分桶及抽样查询 </span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#6-6-1-%E5%88%86%E6%A1%B6%E8%A1%A8%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8\"><span class=\"toc-text\">6.6.1 分桶表数据存储</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#6-6-2-%E5%88%86%E6%A1%B6%E6%8A%BD%E6%A0%B7%E6%9F%A5%E8%AF%A2\"><span class=\"toc-text\">6.6.2 分桶抽样查询</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#6-6-3-%E6%95%B0%E6%8D%AE%E5%9D%97%E6%8A%BD%E6%A0%B7\"><span class=\"toc-text\">6.6.3 数据块抽样</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#8-5-%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E6%A0%BC%E5%BC%8F\"><span class=\"toc-text\">8.5 文件存储格式 </span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#width-x3D-%E2%80%9D7-146527777777778in%E2%80%9D-height-x3D-%E2%80%9D2-6375in%E2%80%9D-8-5-1-%E5%88%97%E5%BC%8F%E5%AD%98%E5%82%A8%E5%92%8C%E8%A1%8C%E5%BC%8F%E5%AD%98%E5%82%A8\"><span class=\"toc-text\">{width&#x3D;”7.146527777777778in” height&#x3D;”2.6375in”}8.5.1 列式存储和行式存储</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#8-5-2-TextFile-%E6%A0%BC%E5%BC%8F\"><span class=\"toc-text\">8.5.2 TextFile 格式</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#8-5-3-Orc-%E6%A0%BC%E5%BC%8F\"><span class=\"toc-text\">8.5.3 Orc 格式</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#8-5-4-Parquet-%E6%A0%BC%E5%BC%8F\"><span class=\"toc-text\">8.5.4 Parquet 格式</span></a></li></ol></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E4%B9%9D-Hive%E4%BC%81%E4%B8%9A%E7%BA%A7%E8%B0%83%E4%BC%98\"><span class=\"toc-text\">九 Hive企业级调优 </span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#9-1-Fetch-%E6%8A%93%E5%8F%96\"><span class=\"toc-text\">9.1 Fetch 抓取 </span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#9-2-%E6%9C%AC%E5%9C%B0%E6%A8%A1%E5%BC%8F\"><span class=\"toc-text\">9.2 本地模式 </span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#9-3-%E8%A1%A8%E7%9A%84%E4%BC%98%E5%8C%96\"><span class=\"toc-text\">9.3 表的优化 </span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#9-3-1-%E5%B0%8F%E8%A1%A8%E3%80%81%E5%A4%A7%E8%A1%A8-Join\"><span class=\"toc-text\">9.3.1 小表、大表 Join</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#9-3-2-%E5%A4%A7%E8%A1%A8-Join-%E5%A4%A7%E8%A1%A8\"><span class=\"toc-text\">9.3.2 大表 Join 大表</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#9-3-3-MapJoin\"><span class=\"toc-text\">9.3.3 MapJoin</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#9-3-4-Group-By\"><span class=\"toc-text\">9.3.4 Group By</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#9-3-5-Count-Distinct-%E5%8E%BB%E9%87%8D%E7%BB%9F%E8%AE%A1\"><span class=\"toc-text\">9.3.5 Count(Distinct) 去重统计</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#9-3-6-%E7%AC%9B%E5%8D%A1%E5%B0%94%E7%A7%AF\"><span class=\"toc-text\">9.3.6 笛卡尔积</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#9-3-7-%E8%A1%8C%E5%88%97%E8%BF%87%E6%BB%A4\"><span class=\"toc-text\">9.3.7 行列过滤</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#9-3-8-%E5%8A%A8%E6%80%81%E5%88%86%E5%8C%BA%E8%B0%83%E6%95%B4\"><span class=\"toc-text\">9.3.8 动态分区调整</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#9-3-9-%E5%88%86%E6%A1%B6\"><span class=\"toc-text\">9.3.9 分桶</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#9-3-10-%E5%88%86%E5%8C%BA\"><span class=\"toc-text\">9.3.10 分区</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#9-4-%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C\"><span class=\"toc-text\">9.4 数据倾斜 </span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#9-4-1-%E5%90%88%E7%90%86%E8%AE%BE%E7%BD%AE-Map-%E6%95%B0\"><span class=\"toc-text\">9.4.1 合理设置 Map 数</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#9-4-2-%E5%B0%8F%E6%96%87%E4%BB%B6%E8%BF%9B%E8%A1%8C%E5%90%88%E5%B9%B6\"><span class=\"toc-text\">9.4.2 小文件进行合并</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#9-4-3-%E5%A4%8D%E6%9D%82%E6%96%87%E4%BB%B6%E5%A2%9E%E5%8A%A0-Map-%E6%95%B0\"><span class=\"toc-text\">9.4.3 复杂文件增加 Map 数</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#9-4-4-%E5%90%88%E7%90%86%E8%AE%BE%E7%BD%AE-Reduce-%E6%95%B0\"><span class=\"toc-text\">9.4.4 合理设置 Reduce 数</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#9-5-%E5%B9%B6%E8%A1%8C%E6%89%A7%E8%A1%8C\"><span class=\"toc-text\">9.5 并行执行 </span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#9-6-%E4%B8%A5%E6%A0%BC%E6%A8%A1%E5%BC%8F\"><span class=\"toc-text\">9.6 严格模式 </span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#9-7-JVM-%E9%87%8D%E7%94%A8\"><span class=\"toc-text\">9.7 JVM 重用 </span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#9-8-%E6%8E%A8%E6%B5%8B%E6%89%A7%E8%A1%8C\"><span class=\"toc-text\">9.8 推测执行 </span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#9-9-%E5%8E%8B%E7%BC%A9\"><span class=\"toc-text\">9.9 压缩 </span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#9-10-%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92%EF%BC%88Explain%EF%BC%89\"><span class=\"toc-text\">9.10 执行计划（Explain） </span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93\"><span class=\"toc-text\">数据仓库 </span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#11-1-%E4%BB%80%E4%B9%88%E6%98%AF%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93\"><span class=\"toc-text\">11.1 什么是数据仓库 </span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#11-2-%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E8%83%BD%E5%B9%B2%E4%BB%80%E4%B9%88%EF%BC%9F\"><span class=\"toc-text\">11.2 数据仓库能干什么？ </span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#11-3-%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E7%9A%84%E7%89%B9%E7%82%B9\"><span class=\"toc-text\">11.3 数据仓库的特点 </span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#11-4-%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E5%8F%91%E5%B1%95%E5%8E%86%E7%A8%8B\"><span class=\"toc-text\">11.4 数据仓库发展历程 </span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#11-5-%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E7%9A%84%E5%8C%BA%E5%88%AB\"><span class=\"toc-text\">11.5 数据库与数据仓库的区别 </span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#11-6-%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%9E%B6%E6%9E%84%E5%88%86%E5%B1%82\"><span class=\"toc-text\">11.6 数据仓库架构分层 </span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#11-6-1-%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%9E%B6%E6%9E%84\"><span class=\"toc-text\">11.6.1 数据仓库架构</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#11-6-2-%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%AF%B9%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E5%88%86%E5%B1%82%EF%BC%9F\"><span class=\"toc-text\">11.6.2 为什么要对数据仓库分层？</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#11-7-%E5%85%83%E6%95%B0%E6%8D%AE%E4%BB%8B%E7%BB%8D\"><span class=\"toc-text\">11.7 元数据介绍 </span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#11-8-%E6%98%9F%E5%9E%8B%E6%A8%A1%E5%9E%8B%E5%92%8C%E9%9B%AA%E8%8A%B1%E6%A8%A1%E5%9E%8B\"><span class=\"toc-text\">11.8 星型模型和雪花模型 </span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#11-8-1-%E6%98%9F%E5%9E%8B%E6%A8%A1%E5%9E%8B\"><span class=\"toc-text\">11.8.1 星型模型</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#11-8-2-%E9%9B%AA%E8%8A%B1%E6%A8%A1%E5%9E%8B\"><span class=\"toc-text\">11.8.2 雪花模型</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#11-8-3-%E6%98%9F%E5%9E%8B%E6%A8%A1%E5%9E%8B%E5%92%8C%E9%9B%AA%E8%8A%B1%E6%A8%A1%E5%9E%8B%E5%AF%B9%E6%AF%94\"><span class=\"toc-text\">11.8.3 星型模型和雪花模型对比</span></a></li></ol></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#Hive%E9%A1%B9%E7%9B%AE-Youtube-TopN%E6%9F%A5%E8%AF%A2\"><span class=\"toc-text\">Hive项目: Youtube_TopN查询</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%B8%80%E3%80%81%E9%9C%80%E6%B1%82%E6%8F%8F%E8%BF%B0\"><span class=\"toc-text\">一、需求描述 </span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%BA%8C%E3%80%81%E7%9F%A5%E8%AF%86%E5%82%A8%E5%A4%87%E6%A2%B3%E7%90%86\"><span class=\"toc-text\">二、知识储备梳理</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#2-1-UDAF%E8%A1%8C%E8%BD%AC%E5%88%97\"><span class=\"toc-text\">2.1 UDAF行转列</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E8%A7%81Hive7-2%EF%BC%9A\"><span class=\"toc-text\">见Hive7.2：</span></a></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#2-2-UDTF%E5%88%97%E8%BD%AC%E8%A1%8C\"><span class=\"toc-text\">2.2 UDTF列转行</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#2-3%E3%80%81%E6%95%B0%E7%BB%84%E6%93%8D%E4%BD%9C\"><span class=\"toc-text\">2.3、数组操作</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#2-5%E3%80%81Hive%E5%88%86%E6%A1%B6\"><span class=\"toc-text\">2.5、Hive分桶</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#2-5-1%E3%80%81%E7%9B%B4%E6%8E%A5%E5%88%86%E6%A1%B6\"><span class=\"toc-text\">2.5.1、直接分桶</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#2-5-2%E3%80%81%E5%9C%A8%E5%88%86%E5%8C%BA%E4%B8%AD%E5%88%86%E6%A1%B6\"><span class=\"toc-text\">2.5.2、在分区中分桶</span></a></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#3-6%E3%80%81%E4%B8%9A%E5%8A%A1%E5%88%86%E6%9E%90\"><span class=\"toc-text\">3.6、业务分析</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#3-6-4%E3%80%81%E7%BB%9F%E8%AE%A1%E8%A7%86%E9%A2%91%E8%A7%82%E7%9C%8B%E6%95%B0-Top50-%E6%89%80%E5%85%B3%E8%81%94%E8%A7%86%E9%A2%91%E7%9A%84%E6%89%80%E5%B1%9E%E7%B1%BB%E5%88%AB%E7%9A%84%E7%83%AD%E5%BA%A6%E6%8E%92%E5%90%8D%EF%BC%88%E6%9C%80%E9%9A%BE%EF%BC%89\"><span class=\"toc-text\">3.6.4、统计视频观看数 Top50 所关联视频的所属类别的热度排名（最难）</span></a></li></ol></li></ol></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#Sqoop\"><span class=\"toc-text\">Sqoop</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%B8%80%E3%80%81Sqoop-%E7%AE%80%E4%BB%8B\"><span class=\"toc-text\">一、Sqoop 简介 </span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%BA%8C%E3%80%81Sqoop-%E5%8E%9F%E7%90%86\"><span class=\"toc-text\">二、Sqoop 原理 </span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#Flume\"><span class=\"toc-text\">Flume</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%B8%80%E3%80%81Flume-%E7%AE%80%E4%BB%8B\"><span class=\"toc-text\">一、Flume 简介 </span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%BA%8C%E3%80%81Flume-%E8%A7%92%E8%89%B2\"><span class=\"toc-text\">二、Flume 角色 </span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#2-1%E3%80%81Source\"><span class=\"toc-text\">2.1、Source</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#2-2%E3%80%81Channel\"><span class=\"toc-text\">2.2、Channel</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#2-3%E3%80%81Sink\"><span class=\"toc-text\">2.3、Sink</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#2-4%E3%80%81Event\"><span class=\"toc-text\">2.4、Event</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%B8%9A%E5%8A%A1%E6%A8%A1%E5%9E%8B%EF%BC%9A\"><span class=\"toc-text\">业务模型：</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%B8%89%E3%80%81Flume-%E4%BC%A0%E8%BE%93%E8%BF%87%E7%A8%8B\"><span class=\"toc-text\">三、Flume 传输过程 </span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#Flume-%E7%9B%91%E6%8E%A7%E4%B9%8B-Ganglia\"><span class=\"toc-text\">Flume 监控之 Ganglia </span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#Kafka\"><span class=\"toc-text\">Kafka</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%B8%80-Kafka%E6%A6%82%E8%BF%B0\"><span class=\"toc-text\">一 Kafka概述</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#1-1-Kafka%E6%98%AF%E4%BB%80%E4%B9%88\"><span class=\"toc-text\">1.1 Kafka是什么</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#1-2-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86\"><span class=\"toc-text\">1.2 消息队列内部实现原理</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#1-3-%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97\"><span class=\"toc-text\">1.3 为什么需要消息队列</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#1-4-Kafka%E6%9E%B6%E6%9E%84\"><span class=\"toc-text\">1.4 Kafka架构</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#1-5-%E5%88%86%E5%B8%83%E5%BC%8F%E6%A8%A1%E5%9E%8B\"><span class=\"toc-text\">1.5 分布式模型</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%B8%89-Kafka%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90\"><span class=\"toc-text\">三 Kafka工作流程分析</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#3-1-Kafka%E7%94%9F%E4%BA%A7%E8%BF%87%E7%A8%8B%E5%88%86%E6%9E%90\"><span class=\"toc-text\">3.1 Kafka生产过程分析</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#3-1-1-%E5%86%99%E5%85%A5%E6%96%B9%E5%BC%8F\"><span class=\"toc-text\">3.1.1 写入方式</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#3-1-2-%E5%88%86%E5%8C%BA%EF%BC%88Partition%EF%BC%89%EF%BC%81%EF%BC%81%EF%BC%81%EF%BC%81%EF%BC%81%EF%BC%81%EF%BC%81%EF%BC%81%EF%BC%81%EF%BC%81%EF%BC%81\"><span class=\"toc-text\">3.1.2 分区（Partition）！！！！！！！！！！！</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#3-1-3-%E5%89%AF%E6%9C%AC%EF%BC%88Replication%EF%BC%89\"><span class=\"toc-text\">3.1.3 副本（Replication）</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#3-1-4-%E5%86%99%E5%85%A5%E6%B5%81%E7%A8%8B\"><span class=\"toc-text\">3.1.4 写入流程</span></a></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#3-3-Kafka%E6%B6%88%E8%B4%B9%E8%BF%87%E7%A8%8B%E5%88%86%E6%9E%90\"><span class=\"toc-text\">3.3 Kafka消费过程分析</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#3-3-1-%E6%B6%88%E8%B4%B9%E6%A8%A1%E5%9E%8B\"><span class=\"toc-text\">3.3.1 消费模型</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#3-3-2-%E9%AB%98%E7%BA%A7API\"><span class=\"toc-text\">3.3.2 高级API</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#3-3-3-%E4%BD%8E%E7%BA%A7API\"><span class=\"toc-text\">3.3.3 低级API</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#3-3-4-%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84\"><span class=\"toc-text\">3.3.4 消费者组</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#3-3-5-%E6%B6%88%E8%B4%B9%E6%96%B9%E5%BC%8F\"><span class=\"toc-text\">3.3.5 消费方式</span></a></li></ol></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%BA%94-Kafka-producer%E6%8B%A6%E6%88%AA%E5%99%A8-interceptor\"><span class=\"toc-text\">五 Kafka producer拦截器(interceptor)</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#5-1-%E6%8B%A6%E6%88%AA%E5%99%A8%E5%8E%9F%E7%90%86\"><span class=\"toc-text\">5.1 拦截器原理</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#5-2-%E6%8B%A6%E6%88%AA%E5%99%A8%E6%A1%88%E4%BE%8B\"><span class=\"toc-text\">5.2 拦截器案例</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%85%AD-kafka-Streams\"><span class=\"toc-text\">六 kafka Streams</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#6-1-%E6%A6%82%E8%BF%B0\"><span class=\"toc-text\">6.1 概述</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#6-1-1-Kafka-Streams\"><span class=\"toc-text\">6.1.1 Kafka Streams</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#6-1-2-Kafka-Streams%E7%89%B9%E7%82%B9\"><span class=\"toc-text\">6.1.2 Kafka Streams特点</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#6-1-3-%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E6%9C%89Kafka-Stream\"><span class=\"toc-text\">6.1.3 为什么要有Kafka Stream</span></a></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#6-2-Kafka-Stream%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97%E6%A1%88%E4%BE%8B\"><span class=\"toc-text\">6.2 Kafka Stream数据清洗案例</span></a></li></ol></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#HBase\"><span class=\"toc-text\">HBase</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%B8%80%E3%80%81HBase-%E4%BB%8B%E7%BB%8D\"><span class=\"toc-text\">一、HBase 介绍 </span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#1-1%E3%80%81HBase-%E7%9A%84%E8%B5%B7%E6%BA%90\"><span class=\"toc-text\">1.1、HBase 的起源</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#1-2%E3%80%81HBase-%E7%9A%84%E8%A7%92%E8%89%B2\"><span class=\"toc-text\">1.2、HBase 的角色</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#1-2-1%E3%80%81HMaster\"><span class=\"toc-text\">1.2.1、HMaster</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#1-2-2%E3%80%81RegionServer\"><span class=\"toc-text\">1.2.2、RegionServer</span></a></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#1-3%E3%80%81HBase-%E7%9A%84%E6%9E%B6%E6%9E%84\"><span class=\"toc-text\">1.3、HBase 的架构</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#2-2-2%E3%80%81%E8%A1%A8%E7%9A%84%E6%93%8D%E4%BD%9C\"><span class=\"toc-text\">2.2.2、表的操作</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#2-3%E3%80%81%E8%AF%BB%E5%86%99%E6%B5%81%E7%A8%8B\"><span class=\"toc-text\">2.3、读写流程 </span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#2-3-1%E3%80%81HBase-%E8%AF%BB%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B\"><span class=\"toc-text\">2.3.1、HBase 读数据流程</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#2-3-2%E3%80%81HBase-%E5%86%99%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B\"><span class=\"toc-text\">2.3.2、HBase 写数据流程</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#2-6-1%E3%80%81HBase-%E4%B8%8E-Hive-%E7%9A%84%E5%AF%B9%E6%AF%94\"><span class=\"toc-text\">2.6.1、HBase 与 Hive 的对比</span></a></li></ol></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#HBase-%E7%9A%84%E4%BC%98%E5%8C%96\"><span class=\"toc-text\">HBase 的优化 </span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#3-1%E3%80%81%E9%AB%98%E5%8F%AF%E7%94%A8\"><span class=\"toc-text\">3.1、高可用 </span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#3-2%E3%80%81Hadoop-%E7%9A%84%E9%80%9A%E7%94%A8%E6%80%A7%E4%BC%98%E5%8C%96\"><span class=\"toc-text\">3.2、Hadoop 的通用性优化 </span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#3-3%E3%80%81Linux-%E4%BC%98%E5%8C%96\"><span class=\"toc-text\">3.3、Linux 优化 </span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#3-4%E3%80%81Zookeeper-%E4%BC%98%E5%8C%96\"><span class=\"toc-text\">3.4、Zookeeper 优化 </span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#3-5%E3%80%81HBase-%E4%BC%98%E5%8C%96\"><span class=\"toc-text\">3.5、HBase 优化 </span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#3-5-1%E3%80%81%E9%A2%84%E5%88%86%E5%8C%BA\"><span class=\"toc-text\">3.5.1、预分区</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#3-5-2%E3%80%81RowKey-%E8%AE%BE%E8%AE%A1\"><span class=\"toc-text\">3.5.2、RowKey 设计</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#3-5-3%E3%80%81%E5%86%85%E5%AD%98%E4%BC%98%E5%8C%96\"><span class=\"toc-text\">3.5.3、内存优化</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#3-5-4%E3%80%81%E5%9F%BA%E7%A1%80%E4%BC%98%E5%8C%96\"><span class=\"toc-text\">3.5.4、基础优化</span></a></li></ol></li></ol></li></ol>","author":{"name":"CodingSeed","slug":"blog-author","avatar":"http://cache.itzy8.top/img/a.jpg","link":"/","description":"","socials":{"github":"https://github.com/codingseed","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"算法竞赛进阶指南yyds","uid":"fdecd5d933e92063c33253528b945c35","slug":"算法竞赛进阶指南yyds","date":"2020-06-08T14:31:57.000Z","updated":"2022-08-22T08:37:30.254Z","comments":true,"path":"api/articles/算法竞赛进阶指南yyds.json","keywords":null,"cover":"http://browser9.qhimg.com/bdm/960_593_0/t018d8dbbf84fd9beef.jpg","text":"0x00基本算法&#x2F;&#x2F;a^b %p #include&lt;iostream&gt; #include&lt;cstdio&gt; #include&lt;cstring&gt; #include&lt;algorithm&gt; using namespace...","link":"","photos":[],"count_time":{"symbolsCount":"413k","symbolsTime":"6:15"},"categories":[{"name":"算法","slug":"算法","count":3,"path":"api/categories/算法.json"}],"tags":[{"name":"算法","slug":"算法","count":3,"path":"api/tags/算法.json"}],"author":{"name":"CodingSeed","slug":"blog-author","avatar":"http://cache.itzy8.top/img/a.jpg","link":"/","description":"","socials":{"github":"https://github.com/codingseed","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true},"next_post":{"title":"Hello World","uid":"b9663f58f18133b35bfe243f3e916a80","slug":"hello-world","date":"2022-08-18T15:39:21.726Z","updated":"2022-08-22T08:06:14.544Z","comments":true,"path":"api/articles/hello-world.json","keywords":null,"cover":"http://p1.qhimg.com/bdm/480_296_0/t01f3d12d8647407337.jpg","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the ...","link":"","photos":[],"count_time":{"symbolsCount":440,"symbolsTime":"1 mins."},"categories":[],"tags":[],"author":{"name":"CodingSeed","slug":"blog-author","avatar":"http://cache.itzy8.top/img/a.jpg","link":"/","description":"","socials":{"github":"https://github.com/codingseed","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}}}